<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>许嘉华的笔记</title>
    <link>https://xujiahua.github.io/</link>
    <description>Recent content on 许嘉华的笔记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 16 Sep 2020 10:48:11 +0800</lastBuildDate>
    
        <atom:link href="https://xujiahua.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>Metabase Impala Driver</title>
        <link>https://xujiahua.github.io/posts/20200527-metabase-impala-driver/</link>
        <pubDate>Wed, 27 May 2020 12:16:36 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200527-metabase-impala-driver/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200527-metabase-impala-driver/ -&lt;p&gt;更新日志&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://xujiahua.github.io/posts/20200528-metabase-impala-type/&#34;&gt;Metabase Impala Driver 0528更新日志&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://xujiahua.github.io/posts/20200710-metabase-impala-driver/&#34;&gt;Metabase Impala Driver 0710更新日志&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;我们的数据仓库是 Hadoop/Hive 体系的。Hadoop 版本采用的是 CDH 发行版。在这个背景下 SQL on Hadoop 的方案有 Hive/Impala/(SparkSQL)。作为 BI 数据库，Impala 在我们的场景下比较合适。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hive：太慢了。做 ETL 可以，BI 非常不适。&lt;/li&gt;
&lt;li&gt;SparkSQL：CDH 官方 Spark 不含 Thrift Server。为了能够使用 Metabase ，独立于 CDH 启了个 Thrift Server，用着还不错。问题就在于缺乏统一管理，比如 Kerberos 的管理就得自己写脚本处理、进程 OOM 挂掉了 CDH Manager 也监测不到。&lt;/li&gt;
&lt;li&gt;Impala：CDH 官方出品，为 BI 而设计，由 CDH Manager 管理。根据这份报告，见下参考链接，Impala 好于 SparkSQL。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;出于尽可能复用已有基础设施的目的，选择 Impala。而 Metabase 官方、社区并不提供 Impala 驱动。本文就是为了探索并解决这个问题。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开源OLAP引擎测评报告(SparkSql、Presto、Impala、HAWQ、ClickHouse、GreenPlum) &lt;a href=&#34;http://www.clickhouse.com.cn/topic/5c453371389ad55f127768ea&#34;&gt;http://www.clickhouse.com.cn/topic/5c453371389ad55f127768ea&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;现有驱动探索&#34;&gt;现有驱动探索&lt;/h2&gt;
&lt;h3 id=&#34;搭建-impala-开发环境&#34;&gt;搭建 Impala 开发环境&lt;/h3&gt;
&lt;p&gt;使用 Cloudera Quickstart Docker 镜像（官方已经下架 quickstart vm ）。其中，Impala版本 2.5.0。（我们的生产环境：CDH 6.3.2 Impala 3.2.0 Hive 2.1.1）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run --name cloudera_quickstart --hostname&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;quickstart.cloudera &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--privileged&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true -t -i -d -p 8888:8888 -p 80:80 -p 10000:10000 -p 7180:7180 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-p 21050:21050 -p 50070:50070 -p 50075:50075 -p 50010:50010 -p 50020:50020 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-p 8020:8020 cloudera/quickstart /usr/bin/docker-quickstart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一些端口使用的说明：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Port&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;td&gt;Tutorial&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8888&lt;/td&gt;
&lt;td&gt;HUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21050&lt;/td&gt;
&lt;td&gt;Impala&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10000&lt;/td&gt;
&lt;td&gt;Hive&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;注意：关闭再启动容器，Impala进程并没有重启。重启 Impala 最直接的方法就是重建容器。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;quickstart docker image &lt;a href=&#34;https://hub.docker.com/r/cloudera/quickstart&#34;&gt;https://hub.docker.com/r/cloudera/quickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;15分钟——在Docker启动Cloudera并开始体验 &lt;a href=&#34;https://xieshaohu.wordpress.com/2019/02/26/15%E5%88%86%E9%92%9F-%E5%9C%A8docker%E5%90%AF%E5%8A%A8cloudera%E5%B9%B6%E5%BC%80%E5%A7%8B%E4%BD%93%E9%AA%8C/&#34;&gt;https://xieshaohu.wordpress.com/2019/02/26/15%E5%88%86%E9%92%9F-%E5%9C%A8docker%E5%90%AF%E5%8A%A8cloudera%E5%B9%B6%E5%BC%80%E5%A7%8B%E4%BD%93%E9%AA%8C/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;尝试-mwullinkmetabase&#34;&gt;尝试 mwullink/metabase&lt;/h3&gt;
&lt;p&gt;在 metabase issue 里看到一个关掉的关于Impala的PR，这方面的资料真的很少。如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Support Apache Impala database #3002 #3749 &lt;a href=&#34;https://github.com/metabase/metabase/pull/3749&#34;&gt;https://github.com/metabase/metabase/pull/3749&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support Apache Impala database #3002 &lt;a href=&#34;https://github.com/metabase/metabase/issues/3002&#34;&gt;https://github.com/metabase/metabase/issues/3002&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可惜，并没有被合并到官方库。尝试编译作者mwullink的metabase版本。 &lt;a href=&#34;https://github.com/mwullink/metabase&#34;&gt;https://github.com/mwullink/metabase&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/mwullink/metabase.git metabase-mwullink
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个metabase版本太老了，前端依赖还是node 4.4.7（warning You are using Node &amp;ldquo;4.4.7&amp;rdquo; which is not supported and may encounter bugs or unexpected behavior. Yarn supports the following semver range: &amp;ldquo;^4.8.0 || ^5.7.0 || ^6.2.2 || &amp;gt;=8.0.0&amp;rdquo;），另外yarn对node4.x也有兼容问题（ &lt;a href=&#34;https://github.com/yarnpkg/yarn/issues/6900&#34;&gt;https://github.com/yarnpkg/yarn/issues/6900&lt;/a&gt; ）。&lt;/p&gt;
&lt;p&gt;特殊处理逻辑：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# nvm 安装 node 4.x 版本&lt;/span&gt;
nvm install lts/argon

&lt;span style=&#34;color:#75715e&#34;&gt;# 修改 node 版本&lt;/span&gt;
vim package.json
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;engines&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;node&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;4.9.1&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;npm&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.15.11&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 安装老版本的yarn&lt;/span&gt;
npm --global install yarn@1.12.3

&lt;span style=&#34;color:#75715e&#34;&gt;# 这样就可以了&lt;/span&gt;
./bin/build
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# jar目录&lt;/span&gt;
cd ./target/uberjar

&lt;span style=&#34;color:#75715e&#34;&gt;# 将impala驱动放这里。下载和安装参考 https://github.com/metabase/metabase/pull/3749/files&lt;/span&gt;
mkdir plugins

&lt;span style=&#34;color:#75715e&#34;&gt;# 换个端口号，本地还有其他版本metabase运行&lt;/span&gt;
java -DMB_JETTY_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12345&lt;/span&gt; -jar metabase.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;效果：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可以直接写SQL查询，基于查询结果也能做 chart/dashboard。&lt;/li&gt;
&lt;li&gt;但是metadata（比如表结构）并没有同步。SQL查询的右边表结构也不会显示，filter功能受影响。&lt;/li&gt;
&lt;li&gt;metadata没有同步，也没有报错信息。（作为对比，连mysql是有metadata同步的。）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;使用官方-sparksql-驱动&#34;&gt;使用官方 sparksql 驱动&lt;/h3&gt;
&lt;p&gt;Metabase 版本：v0.35.3&lt;/p&gt;
&lt;p&gt;尝试使用 sparksql 驱动来连接 Impala 数据库。&lt;/p&gt;
&lt;p&gt;因为 SparkSQL 的 thrift server 复用的是 HiveServer2 的实现，架构如下图。而 Impala 可以使用 Hive 的JDBC Driver （ &lt;a href=&#34;https://impala.apache.org/docs/build/html/topics/impala_jdbc.html&#34;&gt;https://impala.apache.org/docs/build/html/topics/impala_jdbc.html&lt;/a&gt; &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_jdbc.html#jdbc_driver_choice&#34;&gt;https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_jdbc.html#jdbc_driver_choice&lt;/a&gt; ）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200520093534168.png&#34; alt=&#34;image-20200520093534168&#34;&gt;&lt;/p&gt;
&lt;p&gt;效果：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可以直接写SQL查询，基于查询结果也能做chart/dashboard。&lt;/li&gt;
&lt;li&gt;但是表结构并没有同步。SQL查询的右边表结构也不会显示，filter功能受影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步有报错信息。终于有线索了&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;db-metadata-同步出错&#34;&gt;db-metadata 同步出错&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200525102147780.png&#34; alt=&#34;image-20200525102147780&#34;&gt;&lt;/p&gt;
&lt;p&gt;第10行的这个方法崩了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200525162346701.png&#34; alt=&#34;image-20200525162346701&#34;&gt;&lt;/p&gt;
&lt;p&gt;方法 &lt;code&gt;driver/describe-database&lt;/code&gt; 的作用是获取db的所有表。方法 &lt;code&gt;driver/describe-table&lt;/code&gt;的作用是获取table的字段信息 。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-clojure&#34; data-lang=&#34;clojure&#34;&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmulti &lt;/span&gt;describe-database
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Return a map containing information that describes all of the tables in a `database`, an instance of the `Database`
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  model. It is expected that this function will be peformant and avoid draining meaningful resources of the database.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  Results should match the `metabase.sync.interface/DatabaseMetadata` schema.&amp;#34;&lt;/span&gt;
  {&lt;span style=&#34;color:#e6db74&#34;&gt;:arglists&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#39;&lt;/span&gt;([driver database])}
  dispatch-on-initialized-driver
  &lt;span style=&#34;color:#e6db74&#34;&gt;:hierarchy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hierarchy&lt;/span&gt;)

(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmulti &lt;/span&gt;describe-table
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Return a map containing information that describes the physical schema of `table` (i.e. the fields contained
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  therein). `database` will be an instance of the `Database` model; and `table`, an instance of the `Table` model. It is
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  expected that this function will be peformant and avoid draining meaningful resources of the database. Results
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  should match the `metabase.sync.interface/TableMetadata` schema.&amp;#34;&lt;/span&gt;
  {&lt;span style=&#34;color:#e6db74&#34;&gt;:arglists&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#39;&lt;/span&gt;([driver database table])}
  dispatch-on-initialized-driver
  &lt;span style=&#34;color:#e6db74&#34;&gt;:hierarchy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hierarchy&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这（两）个方法调用失败，Metabase 上自然就没有表结构信息了。&lt;/p&gt;
&lt;p&gt;sparksql驱动“重载”了这两个方法。初步怀疑与重载有关，sparksql 的父驱动 jdbc-sql 是有默认实现的，尝试注释掉重载。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200525163902594.png&#34; alt=&#34;image-20200525163902594&#34;&gt;&lt;/p&gt;
&lt;p&gt;神奇地发现，注释掉这两个方法，可以直接通过sparksql驱动连接impala服务器了。&lt;/p&gt;
&lt;p&gt;猜想，SparkSQL的Thrift Server和Impala  Server实现有差异，SparkSQL Thrift Server可能因为有设计缺陷，需要在驱动上打上补丁。&lt;/p&gt;
&lt;h2 id=&#34;自己写驱动&#34;&gt;自己写驱动&lt;/h2&gt;
&lt;p&gt;基于最新版 Metabase 0.35.3 开发。（尝试编译 master 分支，发现打包结果 &lt;code&gt;java -jar metabase.jar&lt;/code&gt; 报错。）&lt;/p&gt;
&lt;p&gt;自己写驱动，目前来看有两条路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过分析 sparksql 驱动的报错信息，貌似找到了连接 Impala 数据库的方式。为了兼容现有的 sparksql 实现，在 sparksql 包中新增一个 impala 文件（复用hive-like父类实现，与sparksql 平行）。&lt;/li&gt;
&lt;li&gt;新增一个驱动包 impala。基于Impala官方的JDBC驱动实现。需要系统理解下 Metabase 驱动开发逻辑。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然，都需要对 Metabase 有一定熟悉程度，先看下文档。&lt;/p&gt;
&lt;h3 id=&#34;sparksql-包中新增一个-impala-driver&#34;&gt;sparksql 包中新增一个 impala driver&lt;/h3&gt;
&lt;p&gt;按照上述思路，代码提交在这里。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql/modules/drivers/sparksql&#34;&gt;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql/modules/drivers/sparksql&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本地测试。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200526165539889.png&#34; alt=&#34;image-20200526165539889&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200526165644979.png&#34; alt=&#34;image-20200526165644979&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200526165735569.png&#34; alt=&#34;image-20200526165735569&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;sparksql-包的依赖问题-存量bug&#34;&gt;sparksql 包的依赖问题 （存量bug）&lt;/h4&gt;
&lt;p&gt;如果服务端启用了 Kerberos 认证，会有这个问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200527105225274.png&#34; alt=&#34;image-20200527105225274&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;05-27 10:39:39 ERROR driver.util :: Database connection error
java.lang.IllegalArgumentException: Unrecognized Hadoop major version number: 3.1.1
	at org.apache.hadoop.hive.shims.ShimLoader.getMajorVersion(ShimLoader.java:174)
	at org.apache.hadoop.hive.shims.ShimLoader.loadShims(ShimLoader.java:139)
	at org.apache.hadoop.hive.shims.ShimLoader.getHadoopThriftAuthBridge(ShimLoader.java:125)
	at org.apache.hive.service.auth.KerberosSaslHelper.getKerberosTransport(KerberosSaslHelper.java:54)
	at org.apache.hive.jdbc.HiveConnection.createBinaryTransport(HiveConnection.java:445)
	at org.apache.hive.jdbc.HiveConnection.openTransport(HiveConnection.java:201)
	at org.apache.hive.jdbc.HiveConnection.&amp;lt;init&amp;gt;(HiveConnection.java:176)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;sparksql jar 包依赖：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 作为 hadoop 基础包，含 Kerberos 认证逻辑代码
org.apache.hadoop/hadoop-common &amp;quot;3.1.1&amp;quot;

# 1.x 系列最后一个版本
org.apache.hive/hive-jdbc &amp;quot;1.2.1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据报错信息找到了Hive的源代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200527110418542.png&#34; alt=&#34;image-20200527110418542&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/apache/hive/blob/release-1.2.1/shims/common/src/main/java/org/apache/hadoop/hive/shims/ShimLoader.java#L159&#34;&gt;https://github.com/apache/hive/blob/release-1.2.1/shims/common/src/main/java/org/apache/hadoop/hive/shims/ShimLoader.java#L159&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;所以 org.apache.hive/hive-jdbc &amp;ldquo;1.2.1&amp;rdquo; 压根就不兼容 org.apache.hadoop/hadoop-common &amp;ldquo;3.x&amp;rdquo; 版本的。人写代码的时候没测到这个case。&lt;/p&gt;
&lt;p&gt;解决方式，引用hadoop-common 2.x最后一个版本：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;org.apache.hadoop/hadoop-common &amp;quot;2.10.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重新编译打包后效果OK。&lt;/p&gt;
&lt;h4 id=&#34;uberjar-的弊端&#34;&gt;uberjar 的弊端&lt;/h4&gt;
&lt;p&gt;Metabase为了方便包的分发，整个项目、驱动都是uberjar的打包思路。弊端其实也挺明显。JDBC 驱动与数据库的兼容性问题，一般是适配数据库，JDBC 驱动被 uberjar 后，想换驱动就得重新编译源码。&lt;/p&gt;
&lt;p&gt;比如 Hive Server 1.1.0，Hive JDBC 1.2.1 就连不上。开源产品的兼容性问题让人头秃。&lt;/p&gt;
&lt;p&gt;&lt;del&gt;TODO：驱动不再uberjar，可以使用自己需要的依赖版本，比如我们使用 CDH 6.x 的 hadoop/hive jar包。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;编译&lt;code&gt;Metabase&lt;/code&gt;时，&lt;code&gt;plugin driver&lt;/code&gt;不要打包到&lt;code&gt;metabase.jar&lt;/code&gt;即可。独立处理&lt;code&gt;plugin driver&lt;/code&gt;的打包和安装。&lt;/p&gt;
&lt;h4 id=&#34;题外话-sparksql-deps&#34;&gt;题外话 sparksql-deps&lt;/h4&gt;
&lt;p&gt;网上有个老版本的sparksql 驱动包 &lt;a href=&#34;https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar&#34;&gt;https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar&lt;/a&gt; 。之前解决这个问题，就是将其放到plugins目录。究其原因，其引用的hadoop-common版本是2.x的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200527111551416.png&#34; alt=&#34;image-20200527111551416&#34;&gt;&lt;/p&gt;
&lt;p&gt;而其源码包括历史记录（ &lt;a href=&#34;https://github.com/metabase/sparksql-deps&#34;&gt;https://github.com/metabase/sparksql-deps&lt;/a&gt; ）的hadoop-common版本是3.1.0。不要被误导了。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;通过摸索，改进 Metabase sparksql 包后，我们可以使用 Impala 了。至于有多少坑，还得等我深度使用后才知道。&lt;/p&gt;
&lt;p&gt;代码 &lt;a href=&#34;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql&#34;&gt;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql&lt;/a&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/20200527-metabase-impala-driver/ - </description>
        </item>
    
    
    
        <item>
        <title>微信用户授权头像内容带随机干扰的问题</title>
        <link>https://xujiahua.github.io/posts/20200514-wx-avatar/</link>
        <pubDate>Thu, 14 May 2020 13:38:12 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200514-wx-avatar/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200514-wx-avatar/ -&lt;p&gt;项目需要基于头像、昵称对不同实体账号下的微信用户进行匹配。基于这个思路，打算先下载微信头像的图像，后计算其MD5，“单元测试”了下这个简单方法，结果惊人。&lt;/p&gt;
&lt;p&gt;同一个人的同一个头像链接返回的图像内容都不一样。内容不一样，MD5值也就不一样。&lt;/p&gt;
&lt;p&gt;看来微信对我们这些拙劣的手段早有防备。&lt;/p&gt;
&lt;h2 id=&#34;微信头像内容分析&#34;&gt;微信头像内容分析&lt;/h2&gt;
&lt;p&gt;同一个头像链接下载两次。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ wget -O 1.png https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoc614h6RfCUnwQTblG9y2dq4g5PKVicVZd5CQO9JNdPCWCovl8cmsvxQcWDemcLYGW6pSt97uUW5A/132
$ wget -O 2.png https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoc614h6RfCUnwQTblG9y2dq4g5PKVicVZd5CQO9JNdPCWCovl8cmsvxQcWDemcLYGW6pSt97uUW5A/132

$ md5 1.png
MD5 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1.png&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dd6aa938cbec381a3e83702776be88a3
$ md5 2.png
MD5 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;2.png&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 83668a6ad7eeee8fa8e5e0db339233d1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;肉眼比较&#34;&gt;肉眼比较&lt;/h3&gt;
&lt;p&gt;肉眼完全无法区分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514134445598.png&#34; alt=&#34;image-20200514134445598&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;字节级比较&#34;&gt;字节级比较&lt;/h3&gt;
&lt;p&gt;两张图，可以看出差异很大。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514134712953.png&#34; alt=&#34;image-20200514134712953&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;像素级比较&#34;&gt;像素级比较&lt;/h3&gt;
&lt;p&gt;为了方便对比，图先灰度化（一个像素点的RGB三值改为1个值）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514184021629.png&#34; alt=&#34;image-20200514184021629&#34;&gt;&lt;/p&gt;
&lt;p&gt;两张灰度图差值的数据分布。x轴为差值，y轴为出现次数。&lt;/p&gt;
&lt;p&gt;0代表相同位置的像素点相同，非0代表相同位置像素点有差异及其差异幅度。&lt;/p&gt;
&lt;p&gt;0出现次数最多，可见两张图的大部分像素点的值是相同的。差异主要分为两部分，1-10 闭区间。（试了几张图）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200515094333720.png&#34; alt=&#34;image-20200515094333720&#34;&gt;&lt;/p&gt;
&lt;p&gt;另一种可视化，白色代表两图相同位置像素点不同。可见，图片污染非常严重。&lt;/p&gt;
&lt;p&gt;上图生成脚本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_to_2d_array&lt;/span&gt;(filename):
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(filename)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(img)

data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.png&amp;#34;&lt;/span&gt;)
data2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.png&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# NOTE: np.uint8(3) - np.uint8(4) = 255 引起的误差让我绝望了&lt;/span&gt;
diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data1) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data2)))

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique(diff, return_counts&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{e}&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(x)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(y)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(x, y)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;count of non-zero point&amp;#34;&lt;/span&gt;, (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum())

diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(diff, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;diff12.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;目标消除白点&#34;&gt;目标：消除白点&lt;/h2&gt;
&lt;p&gt;要达到多份干扰图生成相同的哈希值的效果，就是要消除白点，也就是降采样图像，主要两个方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;降低灰度级别。比如 8bit（256级灰度）图像压缩到6bit（64级灰度）图像，原像素点0、1、2、3归为一个像素点0，以此类推。&lt;/li&gt;
&lt;li&gt;降低图像尺寸。比如尺寸同比缩小一倍。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在有限数据量下测试，32级灰度，10x10 尺寸下，白点消失了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_to_2d_array&lt;/span&gt;(filename, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;):
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(filename)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
        img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(size)
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(img)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bit &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;:
        data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;bit)) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;bit))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; data

size_options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
]

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; bit &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; size_options:
        data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.png&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;size, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bit)
        data2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.png&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;size, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bit)
        diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data1) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data2)))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(data1)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{bit}_{size}_1.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
            Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(data2)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{bit}_{size}_2.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
        ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bit: {0}, size: {1}, 脏点率：{2}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(bit, size, ratio))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相似图片搜索的原理 &lt;a href=&#34;http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html&#34;&gt;http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;微信为了保护用户隐私，防止通过头像昵称进行用户匹配，对每次通过头像链接获取的头像内容加入了随机的扰动，像素点扰动幅度范围在 [-10, 10]，大概15%的像素点（两份干扰图的差异）受干扰，图像的差异肉眼难以察觉。&lt;/p&gt;
&lt;p&gt;最终图像哈希用于 SQL JOIN，需要将有些许差异的图像映射成一个值。不考虑相似度算法。&lt;/p&gt;
&lt;p&gt;通过在图像色彩、尺寸上降维，初步解决了这个问题。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200514-wx-avatar/ - </description>
        </item>
    
    
    
        <item>
        <title>NUC8i5BEH Hackintosh</title>
        <link>https://xujiahua.github.io/posts/20200504-hackintosh/</link>
        <pubDate>Mon, 04 May 2020 13:11:09 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200504-hackintosh/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200504-hackintosh/ -&lt;p&gt;买了个 NUC8i5BEH 当玩具，不怎么折腾的方式体验下黑苹果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504145011481.png&#34; alt=&#34;image-20200504145011481&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;效果&#34;&gt;效果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504132303349.png&#34; alt=&#34;image-20200504132303349&#34;&gt;&lt;/p&gt;
&lt;p&gt;与我的 2018 MBP 13.3 做对比。处理器、显卡是一样的。用很少的钱提升内存，16GB 2133 DDR3 -&amp;gt; 32GB 2400 DDR4。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504132417310.png&#34; alt=&#34;image-20200504132417310&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;成本&#34;&gt;成本&lt;/h3&gt;
&lt;p&gt;大概 ￥4000。2018年买的MacBook近￥15000。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NUC8i5BEH ￥2379&lt;/li&gt;
&lt;li&gt;DDR4 2400 16 GB X 2 笔记本内存条 ￥978&lt;/li&gt;
&lt;li&gt;500GB M.2 SSD 大约￥600（不在这次消费计划里，从现有机器抠出来的）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;不足&#34;&gt;不足&lt;/h3&gt;
&lt;p&gt;WiFi、蓝牙，以及之上的AirDrop等功能缺失。&lt;/p&gt;
&lt;p&gt;网上有解决方案，主要是网卡使用Macbook的配件替代。感觉配件也不便宜，应该是炒热了。用网线，不折腾了。&lt;/p&gt;
&lt;h2 id=&#34;why-nuc8i5beh&#34;&gt;WHY NUC8i5BEH&lt;/h2&gt;
&lt;p&gt;豆子峡谷 NUC8i5BEH 机箱真的小！性能也不差。可以说，是最具性价比的了。&lt;/p&gt;
&lt;p&gt;能做这么小，机箱与电源分离的设计功不可没。- -!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/v2-80ec6cb9eb82fa2c5e0e16cbda516f41_720w.jpg&#34; alt=&#34;v2-80ec6cb9eb82fa2c5e0e16cbda516f41_720w&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i5bek&#34;&gt;NUC8i5BEH vs NUC8i5BEK&lt;/h3&gt;
&lt;p&gt;BEH 胖版，BEK 瘦版。瘦版差一个 2.5 寸盘位。硬盘只有一个M.2插槽。网卡魔改的方案使用M.2插槽，这样BEK就不能放硬盘了。BEH 虽然胖一点，还是很mini。&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i7beh&#34;&gt;NUC8i5BEH vs NUC8i7BEH&lt;/h3&gt;
&lt;p&gt;区别在CPU。差大约￥700。&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i7hvk&#34;&gt;NUC8i5BEH vs NUC8i7HVK&lt;/h3&gt;
&lt;p&gt;冥王峡谷 NUC8i7HVK 拥有 AMD 显卡。不玩电脑游戏，AMD卡又不方便做深度学习，另外小机身大功耗散热问题一定存在，就不考虑了。价格￥6000 起。那就非常没有必要了。&lt;/p&gt;
&lt;h2 id=&#34;安装教程&#34;&gt;安装教程&lt;/h2&gt;
&lt;h3 id=&#34;硬件安装&#34;&gt;硬件安装&lt;/h3&gt;
&lt;p&gt;插内存条和硬盘，看说明书就行。&lt;/p&gt;
&lt;h3 id=&#34;macos-安装&#34;&gt;MacOS 安装&lt;/h3&gt;
&lt;p&gt;MacOS是认硬件的，所以直接按照Apple官方制作MacOS启动盘的方式肯定不行。目前主要是用 Clover/OpenCore 等 BootLoader 骗过系统。安装过程中有两个阶段：U盘启动，硬盘启动，为了能够顺利进入系统，都要对它们的EFI分区进行修改。&lt;/p&gt;
&lt;p&gt;根据这个图文教程（NUC8i5BEH 黑果安装教程 &lt;a href=&#34;https://www.jianshu.com/p/ebd6054d4799&#34;&gt;https://www.jianshu.com/p/ebd6054d4799&lt;/a&gt; ），完成了 Mojave 的安装。图文教程对新人来说比较友好，对细节也有详细描述。（因为使用高手们封装好的镜像，U盘 EFI 分区在这个教程里就忽略了。）&lt;/p&gt;
&lt;p&gt;这个教程大差不差，但也是费了很长时间。&lt;/p&gt;
&lt;h4 id=&#34;意外情况&#34;&gt;意外情况&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;主要问题，引导很慢，一直是白苹果进度条的画面。睡了一觉起来还是这个状态，真的很气啊。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重启重试多几次。慢慢发现，要是2~3分钟进度条没走完，大概率是卡住了。多重启几次，总会有转机的。不明白到底发生了什么，所以这步操作运气成分很大。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;引导过程中遇到白苹果变成了禁止标志。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重启重试即可。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Mojave的镜像文件，内置的证书过期了。报错信息应用程序副本已损坏。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://blog.csdn.net/qq_41855420/article/details/102762647&#34;&gt;https://blog.csdn.net/qq_41855420/article/details/102762647&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;另外注意，MacOS 选择文件系统 APFS（教程中用的默认选项），适合SSD。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;bios-配置&#34;&gt;BIOS 配置&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;仅作记录&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boot -&amp;gt; Boot Configuration, disable &amp;ldquo;&lt;strong&gt;Network Boot&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Power -&amp;gt; Secondary Power Settings, &amp;ldquo;&lt;strong&gt;Wake on LAN from S4/S5&lt;/strong&gt;&amp;rdquo;, set to &amp;ldquo;&lt;strong&gt;Stay Off&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Boot -&amp;gt; Secure Boot, disable &amp;ldquo;&lt;strong&gt;Secure Boot&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Devices -&amp;gt; OnBoard Devices, disable &amp;ldquo;&lt;strong&gt;Bluetooth&lt;/strong&gt;&amp;rdquo; (macOS is not compatible well with Intel Wi-Fi/Bluetooth)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suggested:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boot -&amp;gt; Boot Priority -&amp;gt; Legacy Boot Priority, enable &amp;ldquo;&lt;strong&gt;Legacy Boot&lt;/strong&gt;&amp;rdquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&#34;&gt;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;apple-id--icloud--app-store&#34;&gt;Apple ID / iCloud / App Store&lt;/h4&gt;
&lt;p&gt;不考虑 iMessage / FaceTime，没使用场景。&lt;/p&gt;
&lt;p&gt;按照网上说法，只要生成随机三码（工具按照规则生成），使用 iCloud / App Store 没什么问题。&lt;/p&gt;
&lt;p&gt;怎么生成随机三码，参考：NUC8（豆子峡谷）在线安装macOS，这才是OpenCore正确的打开方式 &lt;a href=&#34;https://www.jianshu.com/p/78510cfa4a64&#34;&gt;https://www.jianshu.com/p/78510cfa4a64&lt;/a&gt; （最后一节）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200513100122246.png&#34; alt=&#34;image-20200513100122246&#34;&gt;&lt;/p&gt;
&lt;p&gt;关于什么是三码、AppleID的安全性，参考：NUC8（豆子峡谷）黑苹果新手指南Q&amp;amp;A &lt;a href=&#34;https://www.jianshu.com/p/b298da6afef3&#34;&gt;https://www.jianshu.com/p/b298da6afef3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200513100850310.png&#34; alt=&#34;image-20200513100850310&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;其他教程&#34;&gt;其他教程&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;[GUIDE] Building a Mac mini beast with NUC8i7BEH &lt;a href=&#34;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&#34;&gt;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;包含如何处理WiFi、蓝牙模块。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;NUC8I5BEH Hackintosh &lt;a href=&#34;https://github.com/csrutil/NUC8I5BEH&#34;&gt;https://github.com/csrutil/NUC8I5BEH&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;配置文件可以直接使用。不算是教程。描述得比较简略。不懂的还是不懂。&lt;/p&gt;
&lt;h2 id=&#34;使用后续&#34;&gt;使用后续&lt;/h2&gt;
&lt;h3 id=&#34;2020-05-29&#34;&gt;2020-05-29&lt;/h3&gt;
&lt;p&gt;NUC 差不多用了一个月，体验很不错，超预期。我是放在办公室使用的，下班锁屏，上班解锁，电脑工作状态一点没改变，上班来就进入状态了。因为价格便宜，猛跑程序，电脑呼呼响，情绪也很稳定。&lt;/p&gt;
&lt;p&gt;一开始还担心不稳定，还带着 Macbook 备用，发现是多余的担心。&lt;/p&gt;
&lt;p&gt;一个小问题：连三星显示器偶尔出现雪花屏，试验下来，是 HDMI 接口容易雪花。TYPEC 接口没这个问题。&lt;/p&gt;
&lt;p&gt;workaround：关闭显示器电源，拔掉HDMI线，重新打开显示器电源，插入HDMI线。NUC HDMI 接口是过热了么？&lt;/p&gt;
- https://xujiahua.github.io/posts/20200504-hackintosh/ - </description>
        </item>
    
    
    
        <item>
        <title>consul 小结</title>
        <link>https://xujiahua.github.io/posts/20200421-use-consul/</link>
        <pubDate>Tue, 21 Apr 2020 09:01:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200421-use-consul/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200421-use-consul/ -&lt;h2 id=&#34;简单介绍&#34;&gt;简单介绍&lt;/h2&gt;
&lt;p&gt;hashicorp 对 Consul 的定位是服务间网络方案。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Consul is a service networking solution to connect and secure services across any runtime platform and public or private cloud. &lt;a href=&#34;https://www.consul.io/&#34;&gt;https://www.consul.io/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方的两个 use case 就是 service discovery, service mesh。&lt;/p&gt;
&lt;h3 id=&#34;service-discovery&#34;&gt;service discovery&lt;/h3&gt;
&lt;p&gt;与 etcd 比起来，Consul 的服务发现是开箱即用的。优点如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First class 的服务注册和获取接口。不需要像 etcd 那样在 kv 存储基础上做包装。&lt;/li&gt;
&lt;li&gt;服务注册，可以是consul 命令，也可以是HTTP API。&lt;/li&gt;
&lt;li&gt;获取服务注册表，除了 HTTP 接口，还可以使用  DNS 查询接口。&lt;/li&gt;
&lt;li&gt;健康检查。服务注册的时候可以提供健康检查项。健康检查机制保证了拿到的服务注册表是“健康”的。健康检查也包括节点的检查。单纯利用 consul 健康检查这个功能，consul 就是一个分布式监控工具。&lt;/li&gt;
&lt;li&gt;Web 管理界面。节点、服务、健康与否一目了然。&lt;/li&gt;
&lt;li&gt;Watch 功能。通过 blocking queries/ long-polling HTTP API 的方式得到服务注册表的改变的通知。&lt;/li&gt;
&lt;li&gt;跨数据中心（取资源）。When a request is made for a resource in another datacenter, the local Consul servers forward an RPC request to the remote Consul servers for that resource and return the results. &lt;a href=&#34;https://learn.hashicorp.com/consul/security-networking/datacenters#data-replication&#34;&gt;https://learn.hashicorp.com/consul/security-networking/datacenters#data-replication&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;service-mesh&#34;&gt;service mesh&lt;/h3&gt;
&lt;p&gt;service discovery 只是微服务治理的初级阶段。作为服务请求方，通过 consul/ etcd 获取到服务注册表，下一步就是选择其中一个服务实例，发送请求。这个步骤叫做负载均衡。可以想象，客户端的代码会越来越重了。&lt;/p&gt;
&lt;p&gt;service mesh可以理解为 service discovery的升级版。为每个服务实例引入 sidecar proxy，接管服务实例的入、出流量。将 service discovery，load balancer 从 service 本身抽离出来，下沉到基础设施，也就是 sidecar proxy。&lt;/p&gt;
&lt;p&gt;sidecar proxy 上的功能还有更多扩展，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;蓝绿部署，A/B 测试。打个比方，一个服务存在两个版本v1, v2，给v1分配80%的流量，给v2分配20%的流量。&lt;/li&gt;
&lt;li&gt;流量加密。authentication and authorization。&lt;/li&gt;
&lt;li&gt;服务指标的收集。比如HTTP协议的返回状态码。&lt;/li&gt;
&lt;li&gt;调用链追踪。&lt;/li&gt;
&lt;li&gt;Intention。可以设置服务与服务之间是否允许连接。Intentions define service based access control for services in the Consul service mesh and are used to control which services are allowed or not allowed to establish connections.&lt;/li&gt;
&lt;li&gt;这一切服务本身是无感知的。这也简化了应用的开发。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这就是 Consul Connect 的功能。与之对应的竞品是 Istio。&lt;/p&gt;
&lt;p&gt;当然，一切都有代价。&lt;strong&gt;给每个服务实例创建一个sidecar proxy，这在部署上需要做好准备。使用 Kubernetes 可以提高效率，会帮助自动创建 sidecar proxy。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;key-value-store&#34;&gt;key value store&lt;/h3&gt;
&lt;p&gt;consul 也能当 kv store 使用，这是服务发现的底子。使用方式跟 etcd 差不多。&lt;/p&gt;
&lt;p&gt;etcd 官方与 consul 做了比较。consul 在存储扩展性上不够好。也缺少KEY多版本存储，不方便追溯历史。key value store 这个场景，etcd 是更合适的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/dbtester/tree/master/test-results/2018Q1-02-etcd-zookeeper-consul&#34;&gt;As it stands in Consul 1.0&lt;/a&gt;, the storage system does not scale as well as other systems like etcd or Zookeeper in key-value operations; systems requiring millions of keys will suffer from high latencies and memory pressure. The key value API is missing, most notably, multi-version keys, conditional transactions, and reliable streaming watches.&lt;/p&gt;
&lt;p&gt;etcd and Consul solve different problems. If looking for a distributed consistent key value store, etcd is a better choice over Consul. If looking for end-to-end cluster service discovery, etcd will not have enough features; choose Kubernetes, Consul, or SmartStack.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;consul client agent的主要工作是健康检查，所以如果只是key value store的使用场景，可以直接与 consul server agent 交互，就像使用 etcd 那样。&lt;/p&gt;
&lt;h3 id=&#34;distributed-system-coordinate&#34;&gt;distributed system coordinate&lt;/h3&gt;
&lt;p&gt;分布式锁，分布式系统的协调 &lt;a href=&#34;https://www.consul.io/docs/internals/sessions.html&#34;&gt;https://www.consul.io/docs/internals/sessions.html&lt;/a&gt; 。使用场景比如Hadoop系统的选主。不过大部分开源分布式系统基本上使用zookeeper和etcd。&lt;/p&gt;
&lt;h2 id=&#34;核心概念&#34;&gt;核心概念&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-arch-420ce04a.png&#34; alt=&#34;Consul Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;Consul 架构图&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node&lt;/td&gt;
&lt;td&gt;每个 node 安装并运行 consul agent。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consul server agent&lt;/td&gt;
&lt;td&gt;1）维护核心状态并基于共识算法 consensus protocol raft 参与leader选举。2）server节点一般建议3个或是5个。写压力大的集群，考虑升级服务器实例的配置和低延迟的存储。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consul client agent&lt;/td&gt;
&lt;td&gt;1）当前节点、当前节点上的服务的健康检查。2）RPC请求转发到 consul server agent。3）每个主机都有一个agent的好处是，只要与本地agent通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datacenter&lt;/td&gt;
&lt;td&gt;可以理解为一个 consul 集群。一个consul 集群至少有一个 consul server agent。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LAN gossip pool&lt;/td&gt;
&lt;td&gt;单个 Datacenter 内，由 consul server agent 和 consul client agent 组成。pool内成员通过 gossip protocol 通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WAN gossip pool&lt;/td&gt;
&lt;td&gt;跨 Datacenter，由所有 Datacenter 内的 consul server agent 组成。可以跨网络通信。pool内成员通过 gossip protocol 通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service&lt;/td&gt;
&lt;td&gt;一个service对应多个service实例，注册时使用相同的service_name，并使用不同的service_id区分实例。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.consul.io/docs/internals/architecture.html&#34;&gt;https://www.consul.io/docs/internals/architecture.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.consul.io/docs/glossary.html&#34;&gt;https://www.consul.io/docs/glossary.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;consul-connect-体验&#34;&gt;Consul Connect 体验&lt;/h2&gt;
&lt;h3 id=&#34;1-quickstart-consul-connect&#34;&gt;1. Quickstart: Consul Connect&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul_connect_demo_service_flow.png&#34; alt=&#34;Flow diagram showing end user traffic being sent to the Dashboard Service at port 9002. The dashboard service makes requests for the counting service to the local Connect Proxy at port 5000. This traffic then traverses the Connect mesh over dynamic ports. The traffic exits the Connect mesh from the counting service&amp;rsquo;s local proxy. The proxy sends this traffic to the counting service itself at port 9003.&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Secure Service-to-Service Communication &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-services&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code &lt;a href=&#34;https://github.com/hashicorp/demo-consul-101&#34;&gt;https://github.com/hashicorp/demo-consul-101&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;简单说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;consul agent -dev -config-dir=&amp;quot;./demo-config-localhost&amp;quot; -node=laptop&lt;/code&gt; 这里已经完成了service和proxy的注册。这个可以后续脚本化，按需服务注册。&lt;/li&gt;
&lt;li&gt;service本身都不做服务发现和负载均衡。这些事情交给了 sidecar proxy。以dashboard service为例，&lt;code&gt;countingServiceURL = getEnvOrDefault(&amp;quot;COUNTING_SERVICE_URL&amp;quot;, &amp;quot;http://localhost:9001&amp;quot;)&lt;/code&gt;，默认读的是本地的9001端口，也就是sidecar proxy的绑定端口。这就是劫持流量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consul connect proxy -sidecar-for counting-1&lt;/code&gt; 需要手动为service创建proxy。这个可以后续脚本化。&lt;/li&gt;
&lt;li&gt;能看出Consul Connect /Service Mesh的好处了：不再侵入业务代码。重复的事情已下沉到基础设施，sidecar proxy处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;2-use-envoy&#34;&gt;2. use Envoy&lt;/h3&gt;
&lt;p&gt;Use Envoy with Connect &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-envoy&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-envoy&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-canary-deployments-using-traffic-splitting-and-resolution&#34;&gt;3. Canary deployments using traffic splitting and resolution&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-splitting-architecture.png&#34; alt=&#34;Architecture diagram of the splitting demo. A web service directly connects to two different versions of the API service through proxies. Consul configures those proxies.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Traffic Splitting for Service Deployments &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/consul-splitting&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/consul-splitting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code &lt;a href=&#34;https://github.com/hashicorp/consul-demo-traffic-splitting&#34;&gt;https://github.com/hashicorp/consul-demo-traffic-splitting&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-zipkin-tracing&#34;&gt;4. Zipkin tracing&lt;/h3&gt;
&lt;p&gt;code &lt;a href=&#34;https://github.com/hashicorp/consul-demo-tracing/tree/master/jaeger&#34;&gt;https://github.com/hashicorp/consul-demo-tracing/tree/master/jaeger&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;基于-consul-微服务改造&#34;&gt;基于 Consul 微服务改造&lt;/h2&gt;
&lt;p&gt;暂不用 Kubernetes 和 Docker。&lt;/p&gt;
&lt;p&gt;目前基本上是这种架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200421163153922.png&#34; alt=&#34;image-20200421163153922&#34;&gt;&lt;/p&gt;
&lt;p&gt;预期架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200421164508506.png&#34; alt=&#34;image-20200421164508506&#34;&gt;&lt;/p&gt;
&lt;p&gt;预期好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减少硬编码。&lt;/li&gt;
&lt;li&gt;可动态新增服务实例。&lt;/li&gt;
&lt;li&gt;基于sidecar做更多服务治理工作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;服务间通信&#34;&gt;服务间通信&lt;/h3&gt;
&lt;p&gt;目的：应用对 consul 无感知，降低应用开发的复杂度。&lt;/p&gt;
&lt;p&gt;需要做如下准备：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;独立服务器安装 consul server agent 集群。负责维护集群状态。&lt;/li&gt;
&lt;li&gt;每台应用服务器都有 consul client agent 运行，并已经连入 consul server agent。负责健康检查，与请求转发。&lt;/li&gt;
&lt;li&gt;每台应用服务器上安装有 envoy 二进制文件。负责sidecar proxy的创建。&lt;/li&gt;
&lt;li&gt;服务注册、注销的工作交给应用的伙伴脚本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;伙伴脚本的工作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;启动应用。&lt;/li&gt;
&lt;li&gt;服务注册和健康检查。所需的信息，比如IP可以通过命令取、端口可以从应用启动信息取、服务名是固定的。&lt;/li&gt;
&lt;li&gt;启动 sidecar proxy 进程。&lt;/li&gt;
&lt;li&gt;伙伴脚本还需要监测应用的状态，应用不存在后，发起服务注销。&lt;/li&gt;
&lt;li&gt;consul的健康检查机制会自动把不健康的服务过滤掉，对伙伴脚本的要求没那么高了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;对外服务&#34;&gt;对外服务&lt;/h3&gt;
&lt;p&gt;目的：动态更新 nginx upstream。&lt;/p&gt;
&lt;p&gt;目前，我们使用nginx作为对外服务。使用 consul-template，动态生成 nginx 配置（upstreams）并 reload nginx。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-nginx-template-arch.png&#34; alt=&#34;NGINX and Consul template architecture&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;参考-1&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Load Balancing with NGINX and Consul Template &lt;a href=&#34;https://learn.hashicorp.com/consul/integrations/nginx-consul-template&#34;&gt;https://learn.hashicorp.com/consul/integrations/nginx-consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;consul-template &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-configuration/consul-template&#34;&gt;https://learn.hashicorp.com/consul/developer-configuration/consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Manage local application configuration files using templates and data from etcd or consul 与consul-template的思路是一样的 &lt;a href=&#34;https://github.com/kelseyhightower/confd&#34;&gt;https://github.com/kelseyhightower/conf&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;基于-consul-的配置中心&#34;&gt;基于 Consul 的配置中心&lt;/h2&gt;
&lt;p&gt;目前，应用读本地配置文件。&lt;/p&gt;
&lt;p&gt;目标，从 consul 读配置文件，并监听配置变化。&lt;/p&gt;
&lt;p&gt;基于 Viper 库和 consul 做了一个demo。 &lt;a href=&#34;https://github.com/XUJiahua/consul_config_demo&#34;&gt;https://github.com/XUJiahua/consul_config_demo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;viper&#34;&gt;viper&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中 Viper 的 remote config 支持的不够好：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;OnConfigChange 对 remote config 无效。&lt;/li&gt;
&lt;li&gt;WatchRemoteConfig()与ReadRemoteConfig() 完全没区别。&lt;/li&gt;
&lt;li&gt;WatchRemoteConfigOnChannel() 是真正有watch功能的方法，但是没有通知应用代码。默默就更新配置了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以基于 PR &lt;a href=&#34;https://github.com/spf13/viper/pull/456/files&#34;&gt;https://github.com/spf13/viper/pull/456/files&lt;/a&gt; 更新了下viper。&lt;/p&gt;
&lt;p&gt;还有个不足。viper remote config 只接收一个 consul/etcd 的地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200422113501760.png&#34; alt=&#34;image-20200422113501760&#34;&gt;&lt;/p&gt;
&lt;p&gt;viper 依赖的 crypt 库因为consul api 库只支持一个地址，也支持不了多地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200422113617179.png&#34; alt=&#34;image-20200422113617179&#34;&gt;&lt;/p&gt;
&lt;p&gt;有几个解决办法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;搭配 consul 服务发现使用，只连本地的 consul client agent，client 节点挂了，本机和其上的服务等会标记为失败了，不会影响其他服务。&lt;/li&gt;
&lt;li&gt;保证 consul 地址是高可用的，比如 nginx 代理多个consul 地址。&lt;/li&gt;
&lt;li&gt;更新库，让 consul api 库支持多个地址。参考下 etcd client 的写法。 &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&#34;&gt;https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;其他一些资料&#34;&gt;其他：一些资料&lt;/h2&gt;
&lt;p&gt;可能有帮助。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Getting Started &lt;a href=&#34;https://learn.hashicorp.com/consul?track=getting-started#getting-started&#34;&gt;https://learn.hashicorp.com/consul?track=getting-started#getting-started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;基于consul构建golang系统分布式服务发现机制（使用Consul HTTP API） &lt;a href=&#34;https://segmentfault.com/a/1190000008471221&#34;&gt;https://segmentfault.com/a/1190000008471221&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service registry bridge for Docker 监听Docker的Unix套接字来获取Docker容器启动和消亡时的事件，并且它会通过在事先配置好的一个可插拔的后端服务中创建新记录的形式自动完成容器的服务注册 &lt;a href=&#34;https://gliderlabs.github.io/registrator/latest/&#34;&gt;https://gliderlabs.github.io/registrator/latest/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200421-use-consul/ - </description>
        </item>
    
    
    
        <item>
        <title>etcd 小结</title>
        <link>https://xujiahua.github.io/posts/20200420-use_etcd/</link>
        <pubDate>Mon, 20 Apr 2020 14:12:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200420-use_etcd/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200420-use_etcd/ -&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;取名有意思。Linux下的/etc目录放的是配置文件。etcd，etc代表配置，d代表distributed，代表分布式配置。&lt;/p&gt;
&lt;p&gt;特点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;designed to reliably store infrequently updated data and provide reliable watch queries &lt;a href=&#34;https://etcd.io/docs/v3.4.0/learning/data_model/&#34;&gt;https://etcd.io/docs/v3.4.0/learning/data_model/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KV 核心用户接口&lt;/li&gt;
&lt;li&gt;MVCC Multi-version Concurrency Control 也确实能读历史版本&lt;/li&gt;
&lt;li&gt;Raft consensus algorithms 共识算法&lt;/li&gt;
&lt;li&gt;Watch 配置更新能及时&amp;quot;通知&amp;quot;应用&lt;/li&gt;
&lt;li&gt;RBAC 用户、角色、权限&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于 etcd 可以做哪些事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置中心。元数据存储。应用的配置集中存储在配置中心。&lt;/li&gt;
&lt;li&gt;服务发现。配置中心的一个特例。相比起来，consul的服务发现是开箱即用的。&lt;/li&gt;
&lt;li&gt;分布式锁。分布式系统协调。选主。像是Hadoop使用Zookeeper做Namenode的选主。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;vs. Consul。Consul 官方（https://www.consul.io/）定义的usecase是 service discovery和 service mesh。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;etcd and Consul solve different problems. If looking for a distributed consistent key value store, etcd is a better choice over Consul. If looking for end-to-end cluster service discovery, etcd will not have enough features; choose Kubernetes, Consul, or SmartStack. &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果是分布式配置中心，etcd是更好的选择。&lt;/p&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;etcd versus other key-value stores &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;etcd集群安装&#34;&gt;etcd集群安装&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/linux_scripts/tree/master/etcd&#34;&gt;https://github.com/XUJiahua/linux_scripts/tree/master/etcd&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;常用操作&#34;&gt;常用操作&lt;/h2&gt;
&lt;p&gt;etcdctl的命令主要是kv操作，以及集群管理，和RBAC用户权限管理。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://etcd.io/docs/v3.4.0/demo/&#34;&gt;https://etcd.io/docs/v3.4.0/demo/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;kv相关&#34;&gt;KV相关&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;put foo &amp;quot;Hello World&amp;quot;&lt;/code&gt;  KV写&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get foo&lt;/code&gt; KV读，还可以读历史版本的值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get web --prefix&lt;/code&gt; KV前缀读，适用于服务发现&lt;/li&gt;
&lt;li&gt;&lt;code&gt;del key&lt;/code&gt; KV删除&lt;/li&gt;
&lt;li&gt;&lt;code&gt;del k --prefix&lt;/code&gt; KV前缀删除&lt;/li&gt;
&lt;li&gt;&lt;code&gt;txn --interactive&lt;/code&gt; KV事务&lt;/li&gt;
&lt;li&gt;&lt;code&gt;watch stock1&lt;/code&gt; KV关注value变化，适用于服务发现，服务发生变动&lt;/li&gt;
&lt;li&gt;&lt;code&gt;watch stock --prefix&lt;/code&gt;  watch也支持前缀匹配&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;lease&#34;&gt;Lease&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lease grant 300&lt;/code&gt; 创建300s的lease&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put sample value --lease=2be7547fbc6a5afa&lt;/code&gt; 有效期300s的key。不设置 lease的put操作，值是永久存储的。&lt;/li&gt;
&lt;li&gt;keep-alive 刷新TTL, list, revoke。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;分布式锁&#34;&gt;分布式锁&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lock mutex1&lt;/code&gt; 获取锁后，其他请求被block&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;集群管理&#34;&gt;集群管理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;member list&lt;/code&gt; list etcd member，member命令还可以增加新node，node也包含不投票的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;endpoint status&lt;/code&gt; 集群状态，能看到leader server&lt;/li&gt;
&lt;li&gt;&lt;code&gt;endpoint health&lt;/code&gt; 健康检查&lt;/li&gt;
&lt;li&gt;&lt;code&gt;snapshot save my.db&lt;/code&gt; 数据快照存储到本地&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;用户权限role-based-access-control&#34;&gt;用户权限（role based access control）&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;role add root&lt;/code&gt; 创建role&lt;/li&gt;
&lt;li&gt;&lt;code&gt;role grant-permission root readwrite foo&lt;/code&gt; role上赋予权限，这里赋予foo的读写权限&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user add root&lt;/code&gt; 创建用户，并指定密码&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user grant-role root root&lt;/code&gt; 赋予用户role&lt;/li&gt;
&lt;li&gt;&lt;code&gt;auth enable&lt;/code&gt; 开启认证，disable 即关闭auth。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--user=root:root put foo bar&lt;/code&gt; 操作时指定用户密码&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200420-use_etcd/ - </description>
        </item>
    
    
    
        <item>
        <title>k8s configmap 与热更新</title>
        <link>https://xujiahua.github.io/posts/20200417-kubernetes-configmap/</link>
        <pubDate>Fri, 17 Apr 2020 16:09:28 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200417-kubernetes-configmap/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200417-kubernetes-configmap/ -&lt;h2 id=&#34;configmap-简介&#34;&gt;configmap 简介&lt;/h2&gt;
&lt;p&gt;官方介绍：使用 ConfigMap 配置 Pod  &lt;a href=&#34;https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;他人总结：ConfigMap &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/configmap.html&#34;&gt;https://jimmysong.io/kubernetes-handbook/concepts/configmap.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;稍微总结下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个configmap都有一个名字，名字全局唯一（命名空间内），重复创建会报错。&lt;/li&gt;
&lt;li&gt;每个configmap本身是键值对。&lt;/li&gt;
&lt;li&gt;configmap可以通过环境变量的方式让Pod内容器读取。&lt;/li&gt;
&lt;li&gt;configmap可以通过挂载文件的方式让Pod内容器读取。k8s每隔一段时间同步configmap，如果有更新的话。当然，应用本身是不知道的。这个定时更新感觉有点鸡肋。&lt;/li&gt;
&lt;li&gt;configmap更新，不会自动重启应用。只能人工方式，滚动重启应用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;把配置更新也当作一次应用变更看待，心情就好很多了。&lt;/p&gt;
&lt;p&gt;官方不支持热更新，所以有了各种技巧，提高效率。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create a new ConfigMap with the changes you want to make, and point your deployment at the new ConfigMap &lt;a href=&#34;https://stackoverflow.com/a/40624029/820682&#34;&gt;https://stackoverflow.com/a/40624029/820682&lt;/a&gt; 因为 deployment 文件变化了，触发滚动重启。&lt;/li&gt;
&lt;li&gt;还有deployment 文件中配置 configmap hash值的。配置变化，hash值变化，deployment变化，滚动重启，一级级联动。 &lt;a href=&#34;https://blog.questionable.services/article/kubernetes-deployments-configmap-change/&#34;&gt;https://blog.questionable.services/article/kubernetes-deployments-configmap-change/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;还有使用sidecar的方式做热更新的，太复杂了 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/57570231&#34;&gt;https://zhuanlan.zhihu.com/p/57570231&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;关于热更新&#34;&gt;关于热更新&lt;/h2&gt;
&lt;p&gt;configmap的更新，容器化应用是无感知的。configmap这种方式没有推送更新到应用内的机制，要实现热更新过于复杂。&lt;/p&gt;
&lt;p&gt;k8s最核心的功能还是自动部署、伸缩、容器管理以及资源分配。微服务架构还是得需要其他框架来辅助的。&lt;/p&gt;
&lt;p&gt;配置热更新应用，就选择 etcd, consul 吧，有 watch 功能。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200417-kubernetes-configmap/ - </description>
        </item>
    
    
    
        <item>
        <title>etcd api client 请求重试逻辑</title>
        <link>https://xujiahua.github.io/posts/20200417-etcd_client/</link>
        <pubDate>Fri, 17 Apr 2020 15:05:51 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200417-etcd_client/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200417-etcd_client/ -&lt;p&gt;使用 Consul 作为配置中心，按照官方的说法，没必要创建 &lt;code&gt;consul client&lt;/code&gt; 节点。那么直接连 &lt;code&gt;consul server&lt;/code&gt; 就好了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.consul.io/intro/index.html#basic-architecture-of-consul&#34;&gt;https://www.consul.io/intro/index.html#basic-architecture-of-consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Consul api client (&lt;a href=&#34;https://github.com/hashicorp/consul/tree/master/api&#34;&gt;https://github.com/hashicorp/consul/tree/master/api&lt;/a&gt;) 目前只能接收一个server地址。那么这个server地址得保证高可用才行啊。&lt;/p&gt;
&lt;p&gt;etcd api client (&lt;a href=&#34;https://github.com/etcd-io/etcd/tree/master/client&#34;&gt;https://github.com/etcd-io/etcd/tree/master/client&lt;/a&gt;) 倒是能接收多个server地址，看看 etcd 是怎么做的。&lt;/p&gt;
&lt;h3 id=&#34;etcd-api-client&#34;&gt;etcd api client&lt;/h3&gt;
&lt;p&gt;创建了 httpClusterClient。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200417151856806.png&#34; alt=&#34;image-20200417151856806&#34;&gt;&lt;/p&gt;
&lt;p&gt;多个 endpoint 的处理核心逻辑。https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200417152639174.png&#34; alt=&#34;image-20200417152639174&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pinned 用于记录好用的连接地址的index，优先使用这个地址。&lt;/li&gt;
&lt;li&gt;context 类错误，比如取消请求，直接退出。&lt;/li&gt;
&lt;li&gt;遇到 5xx 类错误，服务端错误。需要考虑是否重试了。&lt;/li&gt;
&lt;li&gt;isOneShot 标记，true 代表是 Set/Delete 操作，请求失败不再重试。应该跟请求是否幂等有关。&lt;/li&gt;
&lt;li&gt;可以重试的请求，重试直到成功或是循环结束。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200417-etcd_client/ - </description>
        </item>
    
    
    
        <item>
        <title>机器学习在线推理部署方案：Cortex</title>
        <link>https://xujiahua.github.io/posts/20200416-cortex/</link>
        <pubDate>Thu, 16 Apr 2020 11:33:18 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200416-cortex/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200416-cortex/ -&lt;h2 id=&#34;cortex-介绍&#34;&gt;Cortex 介绍&lt;/h2&gt;
&lt;p&gt;官方网站：Deploy machine learning models in production &lt;a href=&#34;https://www.cortex.dev/&#34;&gt;https://www.cortex.dev/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub &lt;a href=&#34;https://github.com/cortexlabs/cortex&#34;&gt;https://github.com/cortexlabs/cortex&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The CLI sends configuration and code to the cluster every time you run &lt;code&gt;cortex deploy&lt;/code&gt;. Each model is loaded into a Docker container, along with any Python packages and request handling code. The model is exposed as a web service using Elastic Load Balancing (ELB), TensorFlow Serving, and ONNX Runtime. The containers are orchestrated on Elastic Kubernetes Service (EKS) while logs and metrics are streamed to CloudWatch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CLI工具将配置文件和代码推送到集群。模型连同Python依赖包和请求处理的代码被Docker容器打包。使用AWS ELB等暴露出Web服务。容器使用AWS EKS编排，日志和指标会推送到AWS CloudWatch。&lt;/p&gt;
&lt;h3 id=&#34;key-features&#34;&gt;Key Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi framework:&lt;/strong&gt; Cortex supports TensorFlow, PyTorch, scikit-learn, XGBoost, and more. 支持主流的机器学习、深度学习框架&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autoscaling:&lt;/strong&gt; Cortex automatically scales APIs to handle production workloads. 依赖k8s的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU / GPU support:&lt;/strong&gt; Cortex can run inference on CPU or GPU infrastructure. CPU/GPU都支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spot instances:&lt;/strong&gt; Cortex supports EC2 spot instances.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rolling updates:&lt;/strong&gt; Cortex updates deployed APIs without any downtime. 依赖k8s的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log streaming:&lt;/strong&gt; Cortex streams logs from deployed models to your CLI. 依赖CloudWatch的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prediction monitoring:&lt;/strong&gt; Cortex monitors network metrics and tracks predictions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Minimal configuration:&lt;/strong&gt; Cortex deployments are defined in a single &lt;code&gt;cortex.yaml&lt;/code&gt; file.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;我的体验&#34;&gt;我的体验&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;与AWS深度绑定。对私有云、国内公有云不够友好了。&lt;/li&gt;
&lt;li&gt;依赖Kubernetes服务。&lt;/li&gt;
&lt;li&gt;依赖云存储服务，比如S3、OSS。cortex deploy的建议：cortex will zip files and upload them to the cluster; we recommend that you upload large files/directories (e.g. models) to s3 and download them in your api&amp;rsquo;s &lt;strong&gt;init&lt;/strong&gt; function,&lt;/li&gt;
&lt;li&gt;有一套Python API服务的模板，并使用Docker封装。比如 &lt;a href=&#34;https://github.com/cortexlabs/cortex/blob/master/images/python-serve/Dockerfile&#34;&gt;https://github.com/cortexlabs/cortex/blob/master/images/python-serve/Dockerfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推理Predictor类按照Cortex定义的接口规范实现，所在目录挂载到 /mnt/project 目录。&lt;/li&gt;
&lt;li&gt;启动容器，预置脚本会安装&lt;code&gt;requirement.txt&lt;/code&gt;，并动态加载Predictor类。&lt;/li&gt;
&lt;li&gt;使用者只需要处理模型训练和按照规范定义Predictor类。重复的API定义、部署、扩容，都已经被隐藏掉了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;代码结构&#34;&gt;代码结构&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;cli 目录：客户端。deploy操作，就是把本地的配置文件压缩成zip包上传。&lt;/li&gt;
&lt;li&gt;pkg/operator 目录：服务端。deploy接口在此：zip包会上传到S3，编程的方式申请k8s资源（deployment, service, virtualService），直接向k8s API server发送请求。&lt;/li&gt;
&lt;li&gt;pkg/lib 目录：比较核心的Go代码。&lt;/li&gt;
&lt;li&gt;pkg/workloads/cortex/downloader 目录：在k8s中作为InitContainer，用于下载配置文件到Pod中。&lt;/li&gt;
&lt;li&gt;pkg/workloads 目录：推理服务的代码，比较通用。pkg/workloads/cortex/serve/run.sh 留了个口子 &lt;code&gt;/mnt/project&lt;/code&gt;，每个服务个性化的部分留给开发者（遵从规范）。&lt;/li&gt;
&lt;li&gt;images 目录：镜像文件。包括 operator 的镜像文件，也包括推理服务的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;具体看看创建推理服务容器的过程。&lt;/p&gt;
&lt;p&gt;申请 K8s Deployment。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151230669.png&#34; alt=&#34;image-20200416151230669&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里分为三大类。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151318515.png&#34; alt=&#34;image-20200416151318515&#34;&gt;&lt;/p&gt;
&lt;p&gt;关注PythonPredictorType。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151537448.png&#34; alt=&#34;image-20200416151537448&#34;&gt;&lt;/p&gt;
&lt;p&gt;传入 InitContainer （代码见 pkg/workloads/cortex/downloader）的参数如下，将S3上存储的配置信息和predictor文件等下载到Pod中的 &lt;code&gt;/mnt/project&lt;/code&gt;目录（&lt;code&gt;_emptyDirMountPath = &amp;quot;/mnt&amp;quot;&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416152324873.png&#34; alt=&#34;image-20200416152324873&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为Pod内容器共享存储空间，这样推理服务容器就能读取到 &lt;code&gt;/mnt/project&lt;/code&gt;了。&lt;/p&gt;
&lt;h2 id=&#34;cortex-镜像体验&#34;&gt;cortex 镜像体验&lt;/h2&gt;
&lt;p&gt;下载地址 &lt;a href=&#34;https://hub.docker.com/r/cortexlabs/python-serve/tags&#34;&gt;https://hub.docker.com/r/cortexlabs/python-serve/tags&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;容器内代码也是依赖S3的，不修改还不能直接使用🤣。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416161622829.png&#34; alt=&#34;image-20200416161622829&#34;&gt;&lt;/p&gt;
&lt;p&gt;到此为止吧。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -e CORTEX_SERVING_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_WORKERS_PER_REPLICA&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_MAX_WORKER_CONCURRENCY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_THREADS_PER_WORKER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_SO_MAX_CONN&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_CACHE_DIR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/mnt/spec &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0.15.1 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -v &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;:/mnt/project &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -v &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;:/mnt/spec &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -p 5000:5000 cortexlabs/python-serve:0.15.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;- https://xujiahua.github.io/posts/20200416-cortex/ - </description>
        </item>
    
    
    
        <item>
        <title>k8s 应用日志收集</title>
        <link>https://xujiahua.github.io/posts/20200414-k8s-logging/</link>
        <pubDate>Tue, 14 Apr 2020 09:53:35 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200414-k8s-logging/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200414-k8s-logging/ -&lt;h2 id=&#34;k8s-日志收集架构&#34;&gt;k8s 日志收集架构&lt;/h2&gt;
&lt;p&gt;以下是比较一般、普适的架构。更多参考：Kubernetes 日志架构 &lt;a href=&#34;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&#34;&gt;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/logging-with-node-agent.png&#34; alt=&#34;使用节点日志记录代理&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;容器化应用将日志写入&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Docker容器引擎将&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;流重定向到日志驱动，比如默认的json-file。&lt;/li&gt;
&lt;li&gt;json-file日志驱动将日志写入到（宿主机上的）文件。&lt;/li&gt;
&lt;li&gt;日志收集工具以DaemonSet的形式安装在每个节点。&lt;/li&gt;
&lt;li&gt;日志收集工具监听文件变化，并将日志写入到日志中心服务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;k8s-日志收集细节&#34;&gt;k8s 日志收集细节&lt;/h2&gt;
&lt;h3 id=&#34;实战&#34;&gt;实战&lt;/h3&gt;
&lt;p&gt;可以直接参考以下教程：minikube创建了一个Kubernetes集群，Fluentd收集日志，存入ElasticSearch，使用Kibana查看日志。典型的EFK技术栈。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logging in Kubernetes with Elasticsearch, Kibana, and Fluentd &lt;a href=&#34;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&#34;&gt;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在Kibana上看收集到的日志。能看到日志收集工具也采集了容器、镜像、Pod有关的信息。这些上下文信息能让人定位到是哪个应用在生产日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414104511399.png&#34; alt=&#34;image-20200414104511399&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;fluentd-收集上下文信息&#34;&gt;fluentd 收集上下文信息&lt;/h3&gt;
&lt;p&gt;Docker &lt;code&gt;json-file&lt;/code&gt; 日志驱动写文件，并不记录上下文信息。 &lt;a href=&#34;https://docs.docker.com/config/containers/logging/json-file/&#34;&gt;https://docs.docker.com/config/containers/logging/json-file/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;log&amp;quot;:&amp;quot;Log line is here\n&amp;quot;,&amp;quot;stream&amp;quot;:&amp;quot;stdout&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2019-01-01T11:11:11.111111111Z&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上文中使用的日志收集镜像是 &lt;code&gt;fluent/fluentd-kubernetes-daemonset:v1.3-debian-elasticsearch&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;具体代码路径在此 &lt;a href=&#34;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&#34;&gt;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;收集容器目录下的日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105706563.png&#34; alt=&#34;image-20200414105706563&#34;&gt;&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;kubernetes_metadata&lt;/code&gt;这个第三方插件获取容器相关的上下文信息。这里是通过请求API server得到metadata的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105752287.png&#34; alt=&#34;image-20200414105752287&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubernetes_metadata&lt;/code&gt; 插件地址 &lt;a href=&#34;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&#34;&gt;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;插件中有缓存metadata的选项，不用担心每处理一条日志，就要向API server发送请求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414111028867.png&#34; alt=&#34;image-20200414111028867&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/20200414-k8s-logging/ - </description>
        </item>
    
    
    
        <item>
        <title>Metabase &#43; Spark SQL</title>
        <link>https://xujiahua.github.io/posts/20200410-metabase-spark-sql/</link>
        <pubDate>Fri, 10 Apr 2020 16:41:53 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200410-metabase-spark-sql/</guid>
        <description>许嘉华的笔记 https://xujiahua.github.io/posts/20200410-metabase-spark-sql/ -&lt;p&gt;这是大数据 BI 平台的第二步，BI 工具的搭建。假设已经配置好 Spark SQL JDBC Server，并启用了Kerberos。参考  &lt;a href=&#34;https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/&#34;&gt;https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里，我们选择了开源产品 Metabase。&lt;/p&gt;
&lt;p&gt;最终，大数据 BI 平台，是由 1) 以Metabase作为BI可视化，2) 由HDFS（分布式文件存储） + parquet（列式数据存储格式）+ Hive metastore（SQL表结构信息维护） + Spark SQL（批处理引擎）组合的OLAP数据库组成。&lt;/p&gt;
&lt;h2 id=&#34;metabase-简介&#34;&gt;Metabase 简介&lt;/h2&gt;
&lt;p&gt;Metabase is the easy, open source way for everyone in your company to ask questions and learn from data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.metabase.com/&#34;&gt;https://www.metabase.com/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据库支持&#34;&gt;数据库支持&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BigQuery&lt;/li&gt;
&lt;li&gt;Druid&lt;/li&gt;
&lt;li&gt;Google Analytics&lt;/li&gt;
&lt;li&gt;H2&lt;/li&gt;
&lt;li&gt;MongoDB&lt;/li&gt;
&lt;li&gt;MySQL/MariaDB&lt;/li&gt;
&lt;li&gt;PostgreSQL&lt;/li&gt;
&lt;li&gt;Presto&lt;/li&gt;
&lt;li&gt;Amazon Redshift&lt;/li&gt;
&lt;li&gt;Snowflake&lt;/li&gt;
&lt;li&gt;Spark SQL&lt;/li&gt;
&lt;li&gt;SQLite&lt;/li&gt;
&lt;li&gt;SQL Server&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.metabase.com/docs/latest/faq/setup/which-databases-does-metabase-support.html&#34;&gt;https://www.metabase.com/docs/latest/faq/setup/which-databases-does-metabase-support.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里有我们需要的Spark SQL，我们的大数据集群可以支持。比较遗憾的是没有Impala。&lt;/p&gt;
&lt;h2 id=&#34;metabase-安装&#34;&gt;Metabase 安装&lt;/h2&gt;
&lt;h3 id=&#34;mysql&#34;&gt;MySQL&lt;/h3&gt;
&lt;p&gt;使用MySQL作为元数据存储。复用之前CDH的MySQL实例。&lt;/p&gt;
&lt;p&gt;创建数据库、用户。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- 适合MySQL5.7及以上版本，支持更大的max key length。一个字符使用四个字节。
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; metabase CHARACTER &lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; utf8mb4 &lt;span style=&#34;color:#66d9ef&#34;&gt;COLLATE&lt;/span&gt; utf8mb4_unicode_ci;
&lt;span style=&#34;color:#75715e&#34;&gt;-- 适合MySQL5.6及以下版本。一个字符使用3个字节。
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; metabase CHARACTER &lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; utf8 &lt;span style=&#34;color:#66d9ef&#34;&gt;COLLATE&lt;/span&gt; utf8_unicode_ci;

&lt;span style=&#34;color:#75715e&#34;&gt;-- % 表示不限制host
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;USER&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt; IDENTIFIED &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;GRANT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ALL&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; metabase.&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TO&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;;

FLUSH &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIVILEGES&lt;/span&gt;;
&lt;span style=&#34;color:#75715e&#34;&gt;-- https://dev.mysql.com/doc/refman/5.7/en/grant.html
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;常见问题&#34;&gt;常见问题&lt;/h4&gt;
&lt;p&gt;mysql 5.7与5.6的区别。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;767 bytes is the &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.1/en/create-index.html&#34;&gt;stated prefix limitation&lt;/a&gt; for InnoDB tables in MySQL version 5.6 (and prior versions). It&amp;rsquo;s 1,000 bytes long for MyISAM tables. In MySQL version 5.7 and upwards this limit has been increased to 3072 bytes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Caused by: java.sql.SQLException: Specified key was too long; max key length is 767 bytes&lt;/p&gt;
&lt;p&gt;Caused by: liquibase.exception.DatabaseException: (conn=175553) Specified key was too long; max key length is 767 bytes [Failed SQL: CREATE TABLE &lt;code&gt;metabase&lt;/code&gt;.&lt;code&gt;core_organization&lt;/code&gt; (&lt;code&gt;id&lt;/code&gt; INT AUTO_INCREMENT NOT NULL, &lt;code&gt;slug&lt;/code&gt; VARCHAR(254) NOT NULL, &lt;code&gt;name&lt;/code&gt; VARCHAR(254) NOT NULL, &lt;code&gt;description&lt;/code&gt; TEXT NULL, &lt;code&gt;logo_url&lt;/code&gt; VARCHAR(254) NULL, &lt;code&gt;inherits&lt;/code&gt; BIT(1) NOT NULL, CONSTRAINT &lt;code&gt;PK_CORE_ORGANIZATION&lt;/code&gt; PRIMARY KEY (&lt;code&gt;id&lt;/code&gt;), UNIQUE (&lt;code&gt;slug&lt;/code&gt;))]&lt;/p&gt;
&lt;h3 id=&#34;metabase&#34;&gt;Metabase&lt;/h3&gt;
&lt;p&gt;下载metabase。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 以 /opt/metabase 为工作目录&lt;/span&gt;
mkdir /opt/metabase &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; cd /opt/metabase
&lt;span style=&#34;color:#75715e&#34;&gt;# 下载最新版本的metabase，参考 https://www.metabase.com/start/jar.html&lt;/span&gt;
wget https://downloads.metabase.com/v0.35.1/metabase.jar
&lt;span style=&#34;color:#75715e&#34;&gt;# 创建插件目录&lt;/span&gt; 
mkdir plugins
&lt;span style=&#34;color:#75715e&#34;&gt;# Spark SQL的驱动，jar包内置的有问题&lt;/span&gt;
wget https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar -O plugins/metabase-sparksql-deps-1.2.1.spark2-standalone.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动脚本 start.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
export MB_DB_TYPE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mysql
export MB_DB_DBNAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3306&lt;/span&gt;
export MB_DB_USER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_PASS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_HOST&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;172.31.0.100

kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING

mkdir -p logs

nohup java -Djavax.security.auth.useSubjectCredsOnly&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;false -jar metabase.jar  &amp;gt;&amp;gt; logs/metabase.log 2&amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &amp;amp;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;停止脚本 stop.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
ps -ef | grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase.jar&amp;#39;&lt;/span&gt; | grep -v &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;grep&amp;#39;&lt;/span&gt; | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt; | xargs kill -9

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;文件夹结构如下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 metabase&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ tree
├── hive.xh-hd2-peggy-dost000003.keytab
├── logs
│   └── metabase.log
├── metabase.jar
├── plugins
│   ├── metabase-sparksql-deps-1.2.1.spark2-standalone.jar
│   ├── sparksql.metabase-driver.jar
│   ├── ...
├── start.sh
└── stop.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Metabase搭建手册：使用SparkSQL连接Hive &lt;a href=&#34;https://webcache.googleusercontent.com/search?q=cache:DcmHXWOc9woJ:https://immm.in/archives/24.html+&amp;amp;cd=5&amp;amp;hl=zh-CN&amp;amp;ct=clnk&amp;amp;gl=hk&#34;&gt;https://webcache.googleusercontent.com/search?q=cache:DcmHXWOc9woJ:https://immm.in/archives/24.html+&amp;amp;cd=5&amp;amp;hl=zh-CN&amp;amp;ct=clnk&amp;amp;gl=hk&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;配置-spark-sql-连接&#34;&gt;配置 Spark SQL 连接&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410180255501.png&#34; alt=&#34;image-20200410180255501&#34;&gt;&lt;/p&gt;
&lt;p&gt;保存没有报错，就是成功了。&lt;/p&gt;
&lt;h4 id=&#34;常见问题-1&#34;&gt;常见问题&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;使用内置的驱动报错：Unrecognized Hadoop major version number: 3.1.1&lt;/li&gt;
&lt;li&gt;使用metabase-sparksql-deps-1.2.1.spark2-standalone.jar这个驱动报错，然而beeline连接是没问题的： transport.TSaslTransport :: SASL negotiation failure
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一个问题，暂时忽略，使用其他驱动。&lt;/p&gt;
&lt;p&gt;按理说，https://github.com/metabase/sparksql-deps 已经合并到 &lt;a href=&#34;https://github.com/metabase/metabase/tree/v0.35.1/modules/drivers/sparksql&#34;&gt;https://github.com/metabase/metabase/tree/v0.35.1/modules/drivers/sparksql&lt;/a&gt; 了。内置驱动就能用才对。&lt;/p&gt;
&lt;p&gt;能看到依赖hadoop-common包的版本差异。TODO: 还得细看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200411071918161.png&#34; alt=&#34;image-20200411071918161&#34;&gt;&lt;/p&gt;
&lt;p&gt;依赖的hadoop版本是3.1.0。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200411072135265.png&#34; alt=&#34;image-20200411072135265&#34;&gt;&lt;/p&gt;
&lt;p&gt;内置Driver依赖3.1.1。报错信息也是包含3.1.1，是否切到3.1.0，重新打包就可以了？&lt;/p&gt;
&lt;p&gt;第二个问题需要设置Java参数 &lt;code&gt;-Djavax.security.auth.useSubjectCredsOnly=false&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;通过底层机制获取凭证信息，而不是通过应用执行认证操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410173734177.png&#34; alt=&#34;image-20200410173734177&#34;&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to connnect sparksql in Kerberos enviroment &lt;a href=&#34;https://discourse.metabase.com/t/how-to-connnect-sparksql-in-kerberos-enviroment/8290/2&#34;&gt;https://discourse.metabase.com/t/how-to-connnect-sparksql-in-kerberos-enviroment/8290/2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided https://stackoverflow.com/questions/32205087/javax-security-sasl-saslexception-gss-initiate-failed-caused-by-gssexception&lt;/li&gt;
&lt;li&gt;Below are listed some problems that may occur when attempting a login, and suggestions for solving them. &lt;a href=&#34;https://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/Troubleshooting.html&#34;&gt;https://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/Troubleshooting.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;与-superset-比较&#34;&gt;与 Superset 比较&lt;/h2&gt;
&lt;p&gt;Superset是另外一个开源的BI工具。但是使用过程中体验不佳：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不支持多表JOIN。这个不能忍。&lt;/li&gt;
&lt;li&gt;直接写SQL，数据没法可视化。效率有点低下。&lt;/li&gt;
&lt;li&gt;外观丑陋。FlaskAppbuilder生成的前后端架子。&lt;/li&gt;
&lt;li&gt;Table源如果改了，建议删掉再添加，不然会有各种意外。&lt;/li&gt;
&lt;li&gt;交互体验差。自定义SELECT COUNT(cookie) as pv，死活搞不定。正确的使用方式是设置label，体验不直观。&lt;/li&gt;
&lt;li&gt;小bug多。用起来太容易烦躁了。对身心健康不好。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200410-metabase-spark-sql/ - </description>
        </item>
    
    
  </channel>
</rss> 