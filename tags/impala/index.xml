<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Impala on 许嘉华的博客</title>
    <link>https://xujiahua.github.io/tags/impala/</link>
    <description>Recent content in Impala on 许嘉华的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 13 Jul 2020 16:16:27 +0800</lastBuildDate>
    
	<atom:link href="https://xujiahua.github.io/tags/impala/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Impala TIMESTAMP 时区处理</title>
      <link>https://xujiahua.github.io/posts/20200713-impala-timezone/</link>
      <pubDate>Mon, 13 Jul 2020 16:16:27 +0800</pubDate>
      
      <guid>https://xujiahua.github.io/posts/20200713-impala-timezone/</guid>
      <description>现象 Hive 以Parquet数据存储格式写入的 TIMESTAMP字段内容，Impala读取，时间差8小时。
Hive写入
Impala读取差8小时，北京时间与UTC差8小时。
原因 Hive写Parquet数据文件，TIMESTAMP先规范化到UTC格式再存储。而Impala直接读取数据文件中的内容，不会进行TIMEZONE的调整。
 When Hive writes to Parquet data files, the TIMESTAMP values are normalized to UTC from the local time zone of the host where the data was written. On the other hand, Impala does not make any time zone adjustment when it writes or reads INT96 TIMESTAMP values to Parquet files. This difference in time zone handling can cause potentially inconsistent results when Impala processes TIMESTAMP values in the Parquet files written by Hive.</description>
    </item>
    
    <item>
      <title>Metabase Impala Driver 0710更新日志</title>
      <link>https://xujiahua.github.io/posts/20200710-metabase-impala-driver/</link>
      <pubDate>Fri, 10 Jul 2020 10:35:08 +0800</pubDate>
      
      <guid>https://xujiahua.github.io/posts/20200710-metabase-impala-driver/</guid>
      <description>基于 Metabase 0.35.4 版本和Cloudera的Impala JDBC驱动，重构了一份独立的 Metabase Impala Driver。
整体思路参考 Writing A Driver ，更多时间是参考其他驱动的代码和根据实际用例调试。还有不少待完善的地方：
 单元测试缺乏。 去除没有必要的方法（首先得理解方法的含义）。  </description>
    </item>
    
    <item>
      <title>Metabase 日期筛选控件实践</title>
      <link>https://xujiahua.github.io/posts/20200605-metabase-field-filter/</link>
      <pubDate>Fri, 05 Jun 2020 14:41:44 +0800</pubDate>
      
      <guid>https://xujiahua.github.io/posts/20200605-metabase-field-filter/</guid>
      <description>Metabase Dashboard 可以是动态的，常用的是指定时间范围筛选，查看这个时间段的指标。
简单示范 使用 SAMPLE DATASET 数据库。定义一个Question：在某一时间段，订单数是多少。使用以下 SQL模板。
select count(1) FROM ORDERS WHERE 1=1 [[AND {{CREATED_AT}} ]] 在Variables侧栏选择如下：
 Variable type：Field Filter。（其他选项，Text/Number/Date 都是单值，没有范围。） Field to map to：选择对应的数据表字段，这里使用ORDERS表的CREATED_AT字段。 Filter widget type：Date Range。注意，只有日期类型（date/ timestamp）有这些选择。（其他选项，大同小异，都会生成对应SQL语句。）  在日期控件中选择时间范围，实际执行的SQL语句如下。
select count(1) FROM ORDERS WHERE 1=1 AND CAST(&amp;#34;PUBLIC&amp;#34;.&amp;#34;ORDERS&amp;#34;.&amp;#34;CREATED_AT&amp;#34; AS date) BETWEEN date &amp;#39;2020-06-03&amp;#39; AND date &amp;#39;2020-06-04&amp;#39; 打开浏览器开发者工具就能看到。
可以看到，生成了这个过滤条件：CAST(&amp;quot;PUBLIC&amp;quot;.&amp;quot;ORDERS&amp;quot;.&amp;quot;CREATED_AT&amp;quot; AS date) BETWEEN date &#39;2020-06-03&#39; AND date &#39;2020-06-04&#39;替代了。
column CREATED_AT 被转为date类型。因为日期控件的日期精度只到年月日，没有时分秒，实际使用中确实也没必要时分秒。
不同的数据库，支持的数据类型是不同的，比如Impala就不支持date类型。Metabase 用如下语句达到相同效果（由各个数据库驱动负责实现），将timestamp类型的精度截断到年月日：
CAST(from_unixtime(unix_timestamp(from_timestamp(CAST(`table`.`column` AS timestamp), &amp;#39;yyyy-MM-dd&amp;#39;), &amp;#39;yyyy-MM-dd&amp;#39;)) AS timestamp) BETWEEN to_timestamp(&amp;#39;2020-05-25 00:00:00&amp;#39;, &amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) AND to_timestamp(&amp;#39;2020-05-31 00:00:00&amp;#39;, &amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;) 参考：</description>
    </item>
    
    <item>
      <title>Metabase Impala Driver 0528更新日志</title>
      <link>https://xujiahua.github.io/posts/20200528-metabase-impala-type/</link>
      <pubDate>Thu, 28 May 2020 09:30:09 +0800</pubDate>
      
      <guid>https://xujiahua.github.io/posts/20200528-metabase-impala-type/</guid>
      <description>体验过程中还是碰到不少问题。
1. TIMESTAMP 类型没有过滤器样式 现象 连 SparkSQL 没这个问题。同样是TIMESTAMP类型，表现不同。
初步分析 在数据库中查看存储的字段信息，Impala/SparkSQL对比看，发现 Impala 数据库下的字段 base_type 都是 type/*。而 database_type，Impala 都是大写的，比如TIMESTAMP，而不是timestamp。所以，并不仅仅是TIMESTAMP类型没有过滤器样式。
Metabase 数据库类型会映射为 Clojure类型，数据库类型的名称是大小写敏感的。所以不能复用hive-like中的实现（都是小写的），而且Hive与Impala的类型还是有些不同的。
Hive Impala的数据类型异同 以 Hive Data Types 为基准。
   Type Name Type Catgory Comment Impala Support?     TINYINT Numeric Types  Yes   SMALLINT Numeric Types  Yes   INT Numeric Types  Yes   BIGINT Numeric Types  Yes   FLOAT Numeric Types  Yes   DOUBLE Numeric Types  Yes   DOUBLE PRECISION Numeric Types alias for DOUBLE, only available starting with Hive 2.</description>
    </item>
    
    <item>
      <title>Metabase Impala Driver</title>
      <link>https://xujiahua.github.io/posts/20200527-metabase-impala-driver/</link>
      <pubDate>Wed, 27 May 2020 12:16:36 +0800</pubDate>
      
      <guid>https://xujiahua.github.io/posts/20200527-metabase-impala-driver/</guid>
      <description>更新日志
 Metabase Impala Driver 0528更新日志 Metabase Impala Driver 0710更新日志  背景 我们的数据仓库是 Hadoop/Hive 体系的。Hadoop 版本采用的是 CDH 发行版。在这个背景下 SQL on Hadoop 的方案有 Hive/Impala/(SparkSQL)。作为 BI 数据库，Impala 在我们的场景下比较合适。
 Hive：太慢了。做 ETL 可以，BI 非常不适。 SparkSQL：CDH 官方 Spark 不含 Thrift Server。为了能够使用 Metabase ，独立于 CDH 启了个 Thrift Server，用着还不错。问题就在于缺乏统一管理，比如 Kerberos 的管理就得自己写脚本处理、进程 OOM 挂掉了 CDH Manager 也监测不到。 Impala：CDH 官方出品，为 BI 而设计，由 CDH Manager 管理。根据这份报告，见下参考链接，Impala 好于 SparkSQL。  出于尽可能复用已有基础设施的目的，选择 Impala。而 Metabase 官方、社区并不提供 Impala 驱动。本文就是为了探索并解决这个问题。
参考：
 开源OLAP引擎测评报告(SparkSql、Presto、Impala、HAWQ、ClickHouse、GreenPlum) http://www.clickhouse.com.cn/topic/5c453371389ad55f127768ea  现有驱动探索 搭建 Impala 开发环境 使用 Cloudera Quickstart Docker 镜像（官方已经下架 quickstart vm ）。其中，Impala版本 2.</description>
    </item>
    
  </channel>
</rss>