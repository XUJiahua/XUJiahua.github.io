<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习工程 on Happy Coding</title>
    <link>https://xujiahua.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B/</link>
    <description>Recent content in 机器学习工程 on Happy Coding</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 16 Apr 2020 11:33:18 +0800</lastBuildDate><atom:link href="https://xujiahua.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>机器学习在线推理部署方案：Cortex</title>
      <link>https://xujiahua.github.io/posts/20200416-cortex/</link>
      <pubDate>Thu, 16 Apr 2020 11:33:18 +0800</pubDate>
      
      <guid>https://xujiahua.github.io/posts/20200416-cortex/</guid>
      <description>Cortex 介绍 官方网站：Deploy machine learning models in production https://www.cortex.dev/
GitHub https://github.com/cortexlabs/cortex
 The CLI sends configuration and code to the cluster every time you run cortex deploy. Each model is loaded into a Docker container, along with any Python packages and request handling code. The model is exposed as a web service using Elastic Load Balancing (ELB), TensorFlow Serving, and ONNX Runtime. The containers are orchestrated on Elastic Kubernetes Service (EKS) while logs and metrics are streamed to CloudWatch.</description>
    </item>
    
  </channel>
</rss>
