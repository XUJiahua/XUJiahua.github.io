<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>许嘉华的博客</title>
    <link>https://xujiahua.github.io/</link>
    <description>Recent content on 许嘉华的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 14 May 2020 13:38:12 +0800</lastBuildDate>
    
        <atom:link href="https://xujiahua.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>微信头像</title>
        <link>https://xujiahua.github.io/posts/20200514-wx-avatar/</link>
        <pubDate>Thu, 14 May 2020 13:38:12 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200514-wx-avatar/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200514-wx-avatar/ -&lt;p&gt;项目需要基于头像、昵称对不同实体账号下的微信用户进行匹配。基于这个思路，打算先下载微信头像的图像，后计算其MD5，“单元测试”了下这个简单方法，结果惊人。&lt;/p&gt;
&lt;p&gt;同一个人的同一个头像链接返回的图像内容都不一样。内容不一样，MD5值也就不一样。&lt;/p&gt;
&lt;p&gt;看来微信对我们这些拙劣的手段早有防备。&lt;/p&gt;
&lt;h2 id=&#34;微信头像内容分析&#34;&gt;微信头像内容分析&lt;/h2&gt;
&lt;p&gt;同一个头像链接下载两次。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ wget -O 1.png https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoc614h6RfCUnwQTblG9y2dq4g5PKVicVZd5CQO9JNdPCWCovl8cmsvxQcWDemcLYGW6pSt97uUW5A/132
$ wget -O 2.png https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoc614h6RfCUnwQTblG9y2dq4g5PKVicVZd5CQO9JNdPCWCovl8cmsvxQcWDemcLYGW6pSt97uUW5A/132

$ md5 1.png
MD5 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1.png&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dd6aa938cbec381a3e83702776be88a3
$ md5 2.png
MD5 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;2.png&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 83668a6ad7eeee8fa8e5e0db339233d1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;肉眼比较&#34;&gt;肉眼比较&lt;/h3&gt;
&lt;p&gt;肉眼完全无法区分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514134445598.png&#34; alt=&#34;image-20200514134445598&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;字节级比较&#34;&gt;字节级比较&lt;/h3&gt;
&lt;p&gt;两张图，可以看出差异很大。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514134712953.png&#34; alt=&#34;image-20200514134712953&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;像素级比较&#34;&gt;像素级比较&lt;/h3&gt;
&lt;p&gt;为了方便对比，图先灰度化（一个像素点的RGB三值改为1个值）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514184021629.png&#34; alt=&#34;image-20200514184021629&#34;&gt;&lt;/p&gt;
&lt;p&gt;两张灰度图差值的数据分布。x轴为差值，y轴为出现次数。&lt;/p&gt;
&lt;p&gt;0代表相同位置的像素点相同，非0代表相同位置像素点有差异及其差异幅度。&lt;/p&gt;
&lt;p&gt;0出现次数最多，可见两张图的大部分像素点的值是相同的。差异主要分为两部分，1-10 闭区间。（试了几张图）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200515094333720.png&#34; alt=&#34;image-20200515094333720&#34;&gt;&lt;/p&gt;
&lt;p&gt;另一种可视化，白色代表两图相同位置像素点不同。可见，图片污染非常严重。&lt;/p&gt;
&lt;p&gt;上图生成脚本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_to_2d_array&lt;/span&gt;(filename):
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(filename)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(img)

data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.png&amp;#34;&lt;/span&gt;)
data2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.png&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# NOTE: np.uint8(3) - np.uint8(4) = 255 引起的误差让我绝望了&lt;/span&gt;
diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data1) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data2)))

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique(diff, return_counts&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{e}&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(x)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(y)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(x, y)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;count of non-zero point&amp;#34;&lt;/span&gt;, (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum())

diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(diff, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;diff12.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;目标消除白点&#34;&gt;目标：消除白点&lt;/h2&gt;
&lt;p&gt;要达到多份干扰图生成相同的哈希值的效果，就是要消除白点，也就是降采样图像，主要两个方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;降低灰度级别。比如 8bit（256级灰度）图像压缩到6bit（64级灰度）图像，原像素点0、1、2、3归为一个像素点0，以此类推。&lt;/li&gt;
&lt;li&gt;降低图像尺寸。比如尺寸同比缩小一倍。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在有限数据量下测试，32级灰度，10x10 尺寸下，白点消失了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_to_2d_array&lt;/span&gt;(filename, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;):
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(filename)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
        img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(size)
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(img)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bit &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;:
        data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;bit)) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;bit))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; data

size_options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
]

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; bit &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; size_options:
        data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.png&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;size, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bit)
        data2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.png&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;size, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bit)
        diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data1) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data2)))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(data1)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{bit}_{size}_1.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
            Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(data2)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{bit}_{size}_2.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
        ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bit: {0}, size: {1}, 脏点率：{2}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(bit, size, ratio))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相似图片搜索的原理 &lt;a href=&#34;http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html&#34;&gt;http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;微信为了保护用户隐私，防止通过头像昵称进行用户匹配，对每次通过头像链接获取的头像内容加入了随机的扰动，像素点扰动幅度范围在 [-10, 10]，大概15%的像素点（两份干扰图的差异），肉眼难以察觉。&lt;/p&gt;
&lt;p&gt;最终图像哈希用于 SQL JOIN，需要将有些许差异的图像映射成一个值。不考虑相似度算法。&lt;/p&gt;
&lt;p&gt;通过在图像色彩、尺寸上降维，初步解决了这个问题。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200514-wx-avatar/ - </description>
        </item>
    
    
    
        <item>
        <title>NUC8i5BEH Hackintosh</title>
        <link>https://xujiahua.github.io/posts/20200504-hackintosh/</link>
        <pubDate>Mon, 04 May 2020 13:11:09 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200504-hackintosh/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200504-hackintosh/ -&lt;p&gt;买了个 NUC8i5BEH 当玩具，不怎么折腾的方式体验下黑苹果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504145011481.png&#34; alt=&#34;image-20200504145011481&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;效果&#34;&gt;效果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504132303349.png&#34; alt=&#34;image-20200504132303349&#34;&gt;&lt;/p&gt;
&lt;p&gt;与我的 2018 MBP 13.3 做对比。处理器、显卡是一样的。用很少的钱提升内存，16GB 2133 DDR3 -&amp;gt; 32GB 2400 DDR4。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504132417310.png&#34; alt=&#34;image-20200504132417310&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;成本&#34;&gt;成本&lt;/h3&gt;
&lt;p&gt;大概 ￥4000。2018年买的MacBook近￥15000。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NUC8i5BEH ￥2379&lt;/li&gt;
&lt;li&gt;DDR4 2400 16 GB X 2 笔记本内存条 ￥978&lt;/li&gt;
&lt;li&gt;500GB M.2 SSD 大约￥600（不在这次消费计划里，从现有机器抠出来的）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;不足&#34;&gt;不足&lt;/h3&gt;
&lt;p&gt;WiFi、蓝牙，以及之上的AirDrop等功能缺失。&lt;/p&gt;
&lt;p&gt;网上有解决方案，主要是网卡使用Macbook的配件替代。感觉配件也不便宜，应该是炒热了。用网线，不折腾了。&lt;/p&gt;
&lt;h2 id=&#34;why-nuc8i5beh&#34;&gt;WHY NUC8i5BEH&lt;/h2&gt;
&lt;p&gt;豆子峡谷 NUC8i5BEH 机箱真的小！性能也不差。可以说，是最具性价比的了。&lt;/p&gt;
&lt;p&gt;能做这么小，机箱与电源分离的设计功不可没。- -!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/v2-80ec6cb9eb82fa2c5e0e16cbda516f41_720w.jpg&#34; alt=&#34;v2-80ec6cb9eb82fa2c5e0e16cbda516f41_720w&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i5bek&#34;&gt;NUC8i5BEH vs NUC8i5BEK&lt;/h3&gt;
&lt;p&gt;BEH 胖版，BEK 瘦版。瘦版差一个 2.5 寸盘位。硬盘只有一个M.2插槽。网卡魔改的方案使用M.2插槽，这样BEK就不能放硬盘了。BEH 虽然胖一点，还是很mini。&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i7beh&#34;&gt;NUC8i5BEH vs NUC8i7BEH&lt;/h3&gt;
&lt;p&gt;区别在CPU。差大约￥700。&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i7hvk&#34;&gt;NUC8i5BEH vs NUC8i7HVK&lt;/h3&gt;
&lt;p&gt;冥王峡谷 NUC8i7HVK 拥有 AMD 显卡。不玩电脑游戏，AMD卡又不方便做深度学习，另外小机身大功耗散热问题一定存在，就不考虑了。价格￥6000 起。那就非常没有必要了。&lt;/p&gt;
&lt;h2 id=&#34;安装教程&#34;&gt;安装教程&lt;/h2&gt;
&lt;h3 id=&#34;硬件安装&#34;&gt;硬件安装&lt;/h3&gt;
&lt;p&gt;插内存条和硬盘，看说明书就行。&lt;/p&gt;
&lt;h3 id=&#34;macos-安装&#34;&gt;MacOS 安装&lt;/h3&gt;
&lt;p&gt;MacOS是认硬件的，所以直接按照Apple官方制作MacOS启动盘的方式肯定不行。目前主要是用 Clover/OpenCore 等 BootLoader 骗过系统。安装过程中有两个阶段：U盘启动，硬盘启动，为了能够顺利进入系统，都要对它们的EFI分区进行修改。&lt;/p&gt;
&lt;p&gt;根据这个图文教程（NUC8i5BEH 黑果安装教程 &lt;a href=&#34;https://www.jianshu.com/p/ebd6054d4799&#34;&gt;https://www.jianshu.com/p/ebd6054d4799&lt;/a&gt; ），完成了 Mojave 的安装。图文教程对新人来说比较友好，对细节也有详细描述。（因为使用高手们封装好的镜像，U盘 EFI 分区在这个教程里就忽略了。）&lt;/p&gt;
&lt;p&gt;这个教程大差不差，但也是费了很长时间。&lt;/p&gt;
&lt;h4 id=&#34;意外情况&#34;&gt;意外情况&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;主要问题，引导很慢，一直是白苹果进度条的画面。睡了一觉起来还是这个状态，真的很气啊。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重启重试多几次。慢慢发现，要是2~3分钟进度条没走完，大概率是卡住了。多重启几次，总会有转机的。不明白到底发生了什么，所以这步操作运气成分很大。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;引导过程中遇到白苹果变成了禁止标志。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重启重试即可。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Mojave的镜像文件，内置的证书过期了。报错信息应用程序副本已损坏。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://blog.csdn.net/qq_41855420/article/details/102762647&#34;&gt;https://blog.csdn.net/qq_41855420/article/details/102762647&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;另外注意，MacOS 选择文件系统 APFS（教程中用的默认选项），适合SSD。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;bios-配置&#34;&gt;BIOS 配置&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;仅作记录&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boot -&amp;gt; Boot Configuration, disable &amp;ldquo;&lt;strong&gt;Network Boot&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Power -&amp;gt; Secondary Power Settings, &amp;ldquo;&lt;strong&gt;Wake on LAN from S4/S5&lt;/strong&gt;&amp;quot;, set to &amp;ldquo;&lt;strong&gt;Stay Off&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Boot -&amp;gt; Secure Boot, disable &amp;ldquo;&lt;strong&gt;Secure Boot&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Devices -&amp;gt; OnBoard Devices, disable &amp;ldquo;&lt;strong&gt;Bluetooth&lt;/strong&gt;&amp;rdquo; (macOS is not compatible well with Intel Wi-Fi/Bluetooth)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suggested:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boot -&amp;gt; Boot Priority -&amp;gt; Legacy Boot Priority, enable &amp;ldquo;&lt;strong&gt;Legacy Boot&lt;/strong&gt;&amp;quot;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&#34;&gt;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;apple-id--icloud--app-store&#34;&gt;Apple ID / iCloud / App Store&lt;/h4&gt;
&lt;p&gt;不考虑 iMessage / FaceTime，没使用场景。&lt;/p&gt;
&lt;p&gt;按照网上说法，只要生成随机三码（工具按照规则生成），使用 iCloud / App Store 没什么问题。&lt;/p&gt;
&lt;p&gt;怎么生成随机三码，参考：NUC8（豆子峡谷）在线安装macOS，这才是OpenCore正确的打开方式 &lt;a href=&#34;https://www.jianshu.com/p/78510cfa4a64&#34;&gt;https://www.jianshu.com/p/78510cfa4a64&lt;/a&gt; （最后一节）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200513100122246.png&#34; alt=&#34;image-20200513100122246&#34;&gt;&lt;/p&gt;
&lt;p&gt;关于什么是三码、AppleID的安全性，参考：NUC8（豆子峡谷）黑苹果新手指南Q&amp;amp;A &lt;a href=&#34;https://www.jianshu.com/p/b298da6afef3&#34;&gt;https://www.jianshu.com/p/b298da6afef3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200513100850310.png&#34; alt=&#34;image-20200513100850310&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;其他教程&#34;&gt;其他教程&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;[GUIDE] Building a Mac mini beast with NUC8i7BEH &lt;a href=&#34;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&#34;&gt;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;包含如何处理WiFi、蓝牙模块。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;NUC8I5BEH Hackintosh &lt;a href=&#34;https://github.com/csrutil/NUC8I5BEH&#34;&gt;https://github.com/csrutil/NUC8I5BEH&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;配置文件可以直接使用。不算是教程。描述得比较简略。不懂的还是不懂。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200504-hackintosh/ - </description>
        </item>
    
    
    
        <item>
        <title>consul 小结</title>
        <link>https://xujiahua.github.io/posts/20200421-use-consul/</link>
        <pubDate>Tue, 21 Apr 2020 09:01:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200421-use-consul/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200421-use-consul/ -&lt;h2 id=&#34;简单介绍&#34;&gt;简单介绍&lt;/h2&gt;
&lt;p&gt;hashicorp 对 Consul 的定位是服务间网络方案。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Consul is a service networking solution to connect and secure services across any runtime platform and public or private cloud. &lt;a href=&#34;https://www.consul.io/&#34;&gt;https://www.consul.io/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方的两个 use case 就是 service discovery, service mesh。&lt;/p&gt;
&lt;h3 id=&#34;service-discovery&#34;&gt;service discovery&lt;/h3&gt;
&lt;p&gt;与 etcd 比起来，Consul 的服务发现是开箱即用的。优点如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First class 的服务注册和获取接口。不需要像 etcd 那样在 kv 存储基础上做包装。&lt;/li&gt;
&lt;li&gt;服务注册，可以是consul 命令，也可以是HTTP API。&lt;/li&gt;
&lt;li&gt;获取服务注册表，除了 HTTP 接口，还可以使用  DNS 查询接口。&lt;/li&gt;
&lt;li&gt;健康检查。服务注册的时候可以提供健康检查项。健康检查机制保证了拿到的服务注册表是“健康”的。健康检查也包括节点的检查。单纯利用 consul 健康检查这个功能，consul 就是一个分布式监控工具。&lt;/li&gt;
&lt;li&gt;Web 管理界面。节点、服务、健康与否一目了然。&lt;/li&gt;
&lt;li&gt;Watch 功能。通过 blocking queries/ long-polling HTTP API 的方式得到服务注册表的改变的通知。&lt;/li&gt;
&lt;li&gt;跨数据中心（取资源）。When a request is made for a resource in another datacenter, the local Consul servers forward an RPC request to the remote Consul servers for that resource and return the results. &lt;a href=&#34;https://learn.hashicorp.com/consul/security-networking/datacenters#data-replication&#34;&gt;https://learn.hashicorp.com/consul/security-networking/datacenters#data-replication&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;service-mesh&#34;&gt;service mesh&lt;/h3&gt;
&lt;p&gt;service discovery 只是微服务治理的初级阶段。作为服务请求方，通过 consul/ etcd 获取到服务注册表，下一步就是选择其中一个服务实例，发送请求。这个步骤叫做负载均衡。可以想象，客户端的代码会越来越重了。&lt;/p&gt;
&lt;p&gt;service mesh可以理解为 service discovery的升级版。为每个服务实例引入 sidecar proxy，接管服务实例的入、出流量。将 service discovery，load balancer 从 service 本身抽离出来，下沉到基础设施，也就是 sidecar proxy。&lt;/p&gt;
&lt;p&gt;sidecar proxy 上的功能还有更多扩展，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;蓝绿部署，A/B 测试。打个比方，一个服务存在两个版本v1, v2，给v1分配80%的流量，给v2分配20%的流量。&lt;/li&gt;
&lt;li&gt;流量加密。authentication and authorization。&lt;/li&gt;
&lt;li&gt;服务指标的收集。比如HTTP协议的返回状态码。&lt;/li&gt;
&lt;li&gt;调用链追踪。&lt;/li&gt;
&lt;li&gt;Intention。可以设置服务与服务之间是否允许连接。Intentions define service based access control for services in the Consul service mesh and are used to control which services are allowed or not allowed to establish connections.&lt;/li&gt;
&lt;li&gt;这一切服务本身是无感知的。这也简化了应用的开发。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这就是 Consul Connect 的功能。与之对应的竞品是 Istio。&lt;/p&gt;
&lt;p&gt;当然，一切都有代价。&lt;strong&gt;给每个服务实例创建一个sidecar proxy，这在部署上需要做好准备。使用 Kubernetes 可以提高效率，会帮助自动创建 sidecar proxy。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;key-value-store&#34;&gt;key value store&lt;/h3&gt;
&lt;p&gt;consul 也能当 kv store 使用，这是服务发现的底子。使用方式跟 etcd 差不多。&lt;/p&gt;
&lt;p&gt;etcd 官方与 consul 做了比较。consul 在存储扩展性上不够好。也缺少KEY多版本存储，不方便追溯历史。key value store 这个场景，etcd 是更合适的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/dbtester/tree/master/test-results/2018Q1-02-etcd-zookeeper-consul&#34;&gt;As it stands in Consul 1.0&lt;/a&gt;, the storage system does not scale as well as other systems like etcd or Zookeeper in key-value operations; systems requiring millions of keys will suffer from high latencies and memory pressure. The key value API is missing, most notably, multi-version keys, conditional transactions, and reliable streaming watches.&lt;/p&gt;
&lt;p&gt;etcd and Consul solve different problems. If looking for a distributed consistent key value store, etcd is a better choice over Consul. If looking for end-to-end cluster service discovery, etcd will not have enough features; choose Kubernetes, Consul, or SmartStack.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;consul client agent的主要工作是健康检查，所以如果只是key value store的使用场景，可以直接与 consul server agent 交互，就像使用 etcd 那样。&lt;/p&gt;
&lt;h3 id=&#34;distributed-system-coordinate&#34;&gt;distributed system coordinate&lt;/h3&gt;
&lt;p&gt;分布式锁，分布式系统的协调 &lt;a href=&#34;https://www.consul.io/docs/internals/sessions.html&#34;&gt;https://www.consul.io/docs/internals/sessions.html&lt;/a&gt; 。使用场景比如Hadoop系统的选主。不过大部分开源分布式系统基本上使用zookeeper和etcd。&lt;/p&gt;
&lt;h2 id=&#34;核心概念&#34;&gt;核心概念&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-arch-420ce04a.png&#34; alt=&#34;Consul Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;Consul 架构图&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node&lt;/td&gt;
&lt;td&gt;每个 node 安装并运行 consul agent。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consul server agent&lt;/td&gt;
&lt;td&gt;1）维护核心状态并基于共识算法 consensus protocol raft 参与leader选举。2）server节点一般建议3个或是5个。写压力大的集群，考虑升级服务器实例的配置和低延迟的存储。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consul client agent&lt;/td&gt;
&lt;td&gt;1）当前节点、当前节点上的服务的健康检查。2）RPC请求转发到 consul server agent。3）每个主机都有一个agent的好处是，只要与本地agent通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datacenter&lt;/td&gt;
&lt;td&gt;可以理解为一个 consul 集群。一个consul 集群至少有一个 consul server agent。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LAN gossip pool&lt;/td&gt;
&lt;td&gt;单个 Datacenter 内，由 consul server agent 和 consul client agent 组成。pool内成员通过 gossip protocol 通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WAN gossip pool&lt;/td&gt;
&lt;td&gt;跨 Datacenter，由所有 Datacenter 内的 consul server agent 组成。可以跨网络通信。pool内成员通过 gossip protocol 通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service&lt;/td&gt;
&lt;td&gt;一个service对应多个service实例，注册时使用相同的service_name，并使用不同的service_id区分实例。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.consul.io/docs/internals/architecture.html&#34;&gt;https://www.consul.io/docs/internals/architecture.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.consul.io/docs/glossary.html&#34;&gt;https://www.consul.io/docs/glossary.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;consul-connect-体验&#34;&gt;Consul Connect 体验&lt;/h2&gt;
&lt;h3 id=&#34;1-quickstart-consul-connect&#34;&gt;1. Quickstart: Consul Connect&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul_connect_demo_service_flow.png&#34; alt=&#34;Flow diagram showing end user traffic being sent to the Dashboard Service at port 9002. The dashboard service makes requests for the counting service to the local Connect Proxy at port 5000. This traffic then traverses the Connect mesh over dynamic ports. The traffic exits the Connect mesh from the counting service&amp;rsquo;s local proxy. The proxy sends this traffic to the counting service itself at port 9003.&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Secure Service-to-Service Communication &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-services&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code &lt;a href=&#34;https://github.com/hashicorp/demo-consul-101&#34;&gt;https://github.com/hashicorp/demo-consul-101&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;简单说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;consul agent -dev -config-dir=&amp;quot;./demo-config-localhost&amp;quot; -node=laptop&lt;/code&gt; 这里已经完成了service和proxy的注册。这个可以后续脚本化，按需服务注册。&lt;/li&gt;
&lt;li&gt;service本身都不做服务发现和负载均衡。这些事情交给了 sidecar proxy。以dashboard service为例，&lt;code&gt;countingServiceURL = getEnvOrDefault(&amp;quot;COUNTING_SERVICE_URL&amp;quot;, &amp;quot;http://localhost:9001&amp;quot;)&lt;/code&gt;，默认读的是本地的9001端口，也就是sidecar proxy的绑定端口。这就是劫持流量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consul connect proxy -sidecar-for counting-1&lt;/code&gt; 需要手动为service创建proxy。这个可以后续脚本化。&lt;/li&gt;
&lt;li&gt;能看出Consul Connect /Service Mesh的好处了：不再侵入业务代码。重复的事情已下沉到基础设施，sidecar proxy处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;2-use-envoy&#34;&gt;2. use Envoy&lt;/h3&gt;
&lt;p&gt;Use Envoy with Connect &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-envoy&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-envoy&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-canary-deployments-using-traffic-splitting-and-resolution&#34;&gt;3. Canary deployments using traffic splitting and resolution&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-splitting-architecture.png&#34; alt=&#34;Architecture diagram of the splitting demo. A web service directly connects to two different versions of the API service through proxies. Consul configures those proxies.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Traffic Splitting for Service Deployments &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/consul-splitting&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/consul-splitting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code &lt;a href=&#34;https://github.com/hashicorp/consul-demo-traffic-splitting&#34;&gt;https://github.com/hashicorp/consul-demo-traffic-splitting&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-zipkin-tracing&#34;&gt;4. Zipkin tracing&lt;/h3&gt;
&lt;p&gt;code &lt;a href=&#34;https://github.com/hashicorp/consul-demo-tracing/tree/master/jaeger&#34;&gt;https://github.com/hashicorp/consul-demo-tracing/tree/master/jaeger&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;基于-consul-微服务改造&#34;&gt;基于 Consul 微服务改造&lt;/h2&gt;
&lt;p&gt;暂不用 Kubernetes 和 Docker。&lt;/p&gt;
&lt;p&gt;目前基本上是这种架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200421163153922.png&#34; alt=&#34;image-20200421163153922&#34;&gt;&lt;/p&gt;
&lt;p&gt;预期架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200421164508506.png&#34; alt=&#34;image-20200421164508506&#34;&gt;&lt;/p&gt;
&lt;p&gt;预期好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减少硬编码。&lt;/li&gt;
&lt;li&gt;可动态新增服务实例。&lt;/li&gt;
&lt;li&gt;基于sidecar做更多服务治理工作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;服务间通信&#34;&gt;服务间通信&lt;/h3&gt;
&lt;p&gt;目的：应用对 consul 无感知，降低应用开发的复杂度。&lt;/p&gt;
&lt;p&gt;需要做如下准备：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;独立服务器安装 consul server agent 集群。负责维护集群状态。&lt;/li&gt;
&lt;li&gt;每台应用服务器都有 consul client agent 运行，并已经连入 consul server agent。负责健康检查，与请求转发。&lt;/li&gt;
&lt;li&gt;每台应用服务器上安装有 envoy 二进制文件。负责sidecar proxy的创建。&lt;/li&gt;
&lt;li&gt;服务注册、注销的工作交给应用的伙伴脚本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;伙伴脚本的工作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;启动应用。&lt;/li&gt;
&lt;li&gt;服务注册和健康检查。所需的信息，比如IP可以通过命令取、端口可以从应用启动信息取、服务名是固定的。&lt;/li&gt;
&lt;li&gt;启动 sidecar proxy 进程。&lt;/li&gt;
&lt;li&gt;伙伴脚本还需要监测应用的状态，应用不存在后，发起服务注销。&lt;/li&gt;
&lt;li&gt;consul的健康检查机制会自动把不健康的服务过滤掉，对伙伴脚本的要求没那么高了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;对外服务&#34;&gt;对外服务&lt;/h3&gt;
&lt;p&gt;目的：动态更新 nginx upstream。&lt;/p&gt;
&lt;p&gt;目前，我们使用nginx作为对外服务。使用 consul-template，动态生成 nginx 配置（upstreams）并 reload nginx。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-nginx-template-arch.png&#34; alt=&#34;NGINX and Consul template architecture&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;参考-1&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Load Balancing with NGINX and Consul Template &lt;a href=&#34;https://learn.hashicorp.com/consul/integrations/nginx-consul-template&#34;&gt;https://learn.hashicorp.com/consul/integrations/nginx-consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;consul-template &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-configuration/consul-template&#34;&gt;https://learn.hashicorp.com/consul/developer-configuration/consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Manage local application configuration files using templates and data from etcd or consul 与consul-template的思路是一样的 &lt;a href=&#34;https://github.com/kelseyhightower/confd&#34;&gt;https://github.com/kelseyhightower/conf&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;基于-consul-的配置中心&#34;&gt;基于 Consul 的配置中心&lt;/h2&gt;
&lt;p&gt;目前，应用读本地配置文件。&lt;/p&gt;
&lt;p&gt;目标，从 consul 读配置文件，并监听配置变化。&lt;/p&gt;
&lt;p&gt;基于 Viper 库和 consul 做了一个demo。 &lt;a href=&#34;https://github.com/XUJiahua/consul_config_demo&#34;&gt;https://github.com/XUJiahua/consul_config_demo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;viper&#34;&gt;viper&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中 Viper 的 remote config 支持的不够好：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;OnConfigChange 对 remote config 无效。&lt;/li&gt;
&lt;li&gt;WatchRemoteConfig()与ReadRemoteConfig() 完全没区别。&lt;/li&gt;
&lt;li&gt;WatchRemoteConfigOnChannel() 是真正有watch功能的方法，但是没有通知应用代码。默默就更新配置了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以基于 PR &lt;a href=&#34;https://github.com/spf13/viper/pull/456/files&#34;&gt;https://github.com/spf13/viper/pull/456/files&lt;/a&gt; 更新了下viper。&lt;/p&gt;
&lt;p&gt;还有个不足。viper remote config 只接收一个 consul/etcd 的地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200422113501760.png&#34; alt=&#34;image-20200422113501760&#34;&gt;&lt;/p&gt;
&lt;p&gt;viper 依赖的 crypt 库因为consul api 库只支持一个地址，也支持不了多地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200422113617179.png&#34; alt=&#34;image-20200422113617179&#34;&gt;&lt;/p&gt;
&lt;p&gt;有几个解决办法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;搭配 consul 服务发现使用，只连本地的 consul client agent，client 节点挂了，本机和其上的服务等会标记为失败了，不会影响其他服务。&lt;/li&gt;
&lt;li&gt;保证 consul 地址是高可用的，比如 nginx 代理多个consul 地址。&lt;/li&gt;
&lt;li&gt;更新库，让 consul api 库支持多个地址。参考下 etcd client 的写法。 &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&#34;&gt;https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;其他一些资料&#34;&gt;其他：一些资料&lt;/h2&gt;
&lt;p&gt;可能有帮助。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Getting Started &lt;a href=&#34;https://learn.hashicorp.com/consul?track=getting-started#getting-started&#34;&gt;https://learn.hashicorp.com/consul?track=getting-started#getting-started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;基于consul构建golang系统分布式服务发现机制（使用Consul HTTP API） &lt;a href=&#34;https://segmentfault.com/a/1190000008471221&#34;&gt;https://segmentfault.com/a/1190000008471221&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service registry bridge for Docker 监听Docker的Unix套接字来获取Docker容器启动和消亡时的事件，并且它会通过在事先配置好的一个可插拔的后端服务中创建新记录的形式自动完成容器的服务注册 &lt;a href=&#34;https://gliderlabs.github.io/registrator/latest/&#34;&gt;https://gliderlabs.github.io/registrator/latest/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200421-use-consul/ - </description>
        </item>
    
    
    
        <item>
        <title>etcd 小结</title>
        <link>https://xujiahua.github.io/posts/20200420-use_etcd/</link>
        <pubDate>Mon, 20 Apr 2020 14:12:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200420-use_etcd/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200420-use_etcd/ -&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;取名有意思。Linux下的/etc目录放的是配置文件。etcd，etc代表配置，d代表distributed，代表分布式配置。&lt;/p&gt;
&lt;p&gt;特点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;designed to reliably store infrequently updated data and provide reliable watch queries &lt;a href=&#34;https://etcd.io/docs/v3.4.0/learning/data_model/&#34;&gt;https://etcd.io/docs/v3.4.0/learning/data_model/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KV 核心用户接口&lt;/li&gt;
&lt;li&gt;MVCC Multi-version Concurrency Control 也确实能读历史版本&lt;/li&gt;
&lt;li&gt;Raft consensus algorithms 共识算法&lt;/li&gt;
&lt;li&gt;Watch 配置更新能及时&amp;quot;通知&amp;quot;应用&lt;/li&gt;
&lt;li&gt;RBAC 用户、角色、权限&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于 etcd 可以做哪些事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置中心。元数据存储。应用的配置集中存储在配置中心。&lt;/li&gt;
&lt;li&gt;服务发现。配置中心的一个特例。相比起来，consul的服务发现是开箱即用的。&lt;/li&gt;
&lt;li&gt;分布式锁。分布式系统协调。选主。像是Hadoop使用Zookeeper做Namenode的选主。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;vs. Consul。Consul 官方（https://www.consul.io/）定义的usecase是 service discovery和 service mesh。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;etcd and Consul solve different problems. If looking for a distributed consistent key value store, etcd is a better choice over Consul. If looking for end-to-end cluster service discovery, etcd will not have enough features; choose Kubernetes, Consul, or SmartStack. &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果是分布式配置中心，etcd是更好的选择。&lt;/p&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;etcd versus other key-value stores &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;etcd集群安装&#34;&gt;etcd集群安装&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/linux_scripts/tree/master/etcd&#34;&gt;https://github.com/XUJiahua/linux_scripts/tree/master/etcd&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;常用操作&#34;&gt;常用操作&lt;/h2&gt;
&lt;p&gt;etcdctl的命令主要是kv操作，以及集群管理，和RBAC用户权限管理。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://etcd.io/docs/v3.4.0/demo/&#34;&gt;https://etcd.io/docs/v3.4.0/demo/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;kv相关&#34;&gt;KV相关&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;put foo &amp;quot;Hello World&amp;quot;&lt;/code&gt;  KV写&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get foo&lt;/code&gt; KV读，还可以读历史版本的值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get web --prefix&lt;/code&gt; KV前缀读，适用于服务发现&lt;/li&gt;
&lt;li&gt;&lt;code&gt;del key&lt;/code&gt; KV删除&lt;/li&gt;
&lt;li&gt;&lt;code&gt;del k --prefix&lt;/code&gt; KV前缀删除&lt;/li&gt;
&lt;li&gt;&lt;code&gt;txn --interactive&lt;/code&gt; KV事务&lt;/li&gt;
&lt;li&gt;&lt;code&gt;watch stock1&lt;/code&gt; KV关注value变化，适用于服务发现，服务发生变动&lt;/li&gt;
&lt;li&gt;&lt;code&gt;watch stock --prefix&lt;/code&gt;  watch也支持前缀匹配&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;lease&#34;&gt;Lease&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lease grant 300&lt;/code&gt; 创建300s的lease&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put sample value --lease=2be7547fbc6a5afa&lt;/code&gt; 有效期300s的key。不设置 lease的put操作，值是永久存储的。&lt;/li&gt;
&lt;li&gt;keep-alive 刷新TTL, list, revoke。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;分布式锁&#34;&gt;分布式锁&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lock mutex1&lt;/code&gt; 获取锁后，其他请求被block&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;集群管理&#34;&gt;集群管理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;member list&lt;/code&gt; list etcd member，member命令还可以增加新node，node也包含不投票的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;endpoint status&lt;/code&gt; 集群状态，能看到leader server&lt;/li&gt;
&lt;li&gt;&lt;code&gt;endpoint health&lt;/code&gt; 健康检查&lt;/li&gt;
&lt;li&gt;&lt;code&gt;snapshot save my.db&lt;/code&gt; 数据快照存储到本地&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;用户权限role-based-access-control&#34;&gt;用户权限（role based access control）&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;role add root&lt;/code&gt; 创建role&lt;/li&gt;
&lt;li&gt;&lt;code&gt;role grant-permission root readwrite foo&lt;/code&gt; role上赋予权限，这里赋予foo的读写权限&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user add root&lt;/code&gt; 创建用户，并指定密码&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user grant-role root root&lt;/code&gt; 赋予用户role&lt;/li&gt;
&lt;li&gt;&lt;code&gt;auth enable&lt;/code&gt; 开启认证，disable 即关闭auth。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--user=root:root put foo bar&lt;/code&gt; 操作时指定用户密码&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200420-use_etcd/ - </description>
        </item>
    
    
    
        <item>
        <title>k8s configmap 与热更新</title>
        <link>https://xujiahua.github.io/posts/20200417-kubernetes-configmap/</link>
        <pubDate>Fri, 17 Apr 2020 16:09:28 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200417-kubernetes-configmap/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200417-kubernetes-configmap/ -&lt;h2 id=&#34;configmap-简介&#34;&gt;configmap 简介&lt;/h2&gt;
&lt;p&gt;官方介绍：使用 ConfigMap 配置 Pod  &lt;a href=&#34;https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;他人总结：ConfigMap &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/configmap.html&#34;&gt;https://jimmysong.io/kubernetes-handbook/concepts/configmap.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;稍微总结下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个configmap都有一个名字，名字全局唯一（命名空间内），重复创建会报错。&lt;/li&gt;
&lt;li&gt;每个configmap本身是键值对。&lt;/li&gt;
&lt;li&gt;configmap可以通过环境变量的方式让Pod内容器读取。&lt;/li&gt;
&lt;li&gt;configmap可以通过挂载文件的方式让Pod内容器读取。k8s每隔一段时间同步configmap，如果有更新的话。当然，应用本身是不知道的。这个定时更新感觉有点鸡肋。&lt;/li&gt;
&lt;li&gt;configmap更新，不会自动重启应用。只能人工方式，滚动重启应用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;把配置更新也当作一次应用变更看待，心情就好很多了。&lt;/p&gt;
&lt;p&gt;官方不支持热更新，所以有了各种技巧，提高效率。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create a new ConfigMap with the changes you want to make, and point your deployment at the new ConfigMap &lt;a href=&#34;https://stackoverflow.com/a/40624029/820682&#34;&gt;https://stackoverflow.com/a/40624029/820682&lt;/a&gt; 因为 deployment 文件变化了，触发滚动重启。&lt;/li&gt;
&lt;li&gt;还有deployment 文件中配置 configmap hash值的。配置变化，hash值变化，deployment变化，滚动重启，一级级联动。 &lt;a href=&#34;https://blog.questionable.services/article/kubernetes-deployments-configmap-change/&#34;&gt;https://blog.questionable.services/article/kubernetes-deployments-configmap-change/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;还有使用sidecar的方式做热更新的，太复杂了 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/57570231&#34;&gt;https://zhuanlan.zhihu.com/p/57570231&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;关于热更新&#34;&gt;关于热更新&lt;/h2&gt;
&lt;p&gt;configmap的更新，容器化应用是无感知的。configmap这种方式没有推送更新到应用内的机制，要实现热更新过于复杂。&lt;/p&gt;
&lt;p&gt;k8s最核心的功能还是自动部署、伸缩、容器管理以及资源分配。微服务架构还是得需要其他框架来辅助的。&lt;/p&gt;
&lt;p&gt;配置热更新应用，就选择 etcd, consul 吧，有 watch 功能。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200417-kubernetes-configmap/ - </description>
        </item>
    
    
    
        <item>
        <title>etcd api client 请求重试逻辑</title>
        <link>https://xujiahua.github.io/posts/20200417-etcd_client/</link>
        <pubDate>Fri, 17 Apr 2020 15:05:51 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200417-etcd_client/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200417-etcd_client/ -&lt;p&gt;使用 Consul 作为配置中心，按照官方的说法，没必要创建 &lt;code&gt;consul client&lt;/code&gt; 节点。那么直接连 &lt;code&gt;consul server&lt;/code&gt; 就好了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.consul.io/intro/index.html#basic-architecture-of-consul&#34;&gt;https://www.consul.io/intro/index.html#basic-architecture-of-consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Consul api client (&lt;a href=&#34;https://github.com/hashicorp/consul/tree/master/api&#34;&gt;https://github.com/hashicorp/consul/tree/master/api&lt;/a&gt;) 目前只能接收一个server地址。那么这个server地址得保证高可用才行啊。&lt;/p&gt;
&lt;p&gt;etcd api client (&lt;a href=&#34;https://github.com/etcd-io/etcd/tree/master/client&#34;&gt;https://github.com/etcd-io/etcd/tree/master/client&lt;/a&gt;) 倒是能接收多个server地址，看看 etcd 是怎么做的。&lt;/p&gt;
&lt;h3 id=&#34;etcd-api-client&#34;&gt;etcd api client&lt;/h3&gt;
&lt;p&gt;创建了 httpClusterClient。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200417151856806.png&#34; alt=&#34;image-20200417151856806&#34;&gt;&lt;/p&gt;
&lt;p&gt;多个 endpoint 的处理核心逻辑。https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200417152639174.png&#34; alt=&#34;image-20200417152639174&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pinned 用于记录好用的连接地址的index，优先使用这个地址。&lt;/li&gt;
&lt;li&gt;context 类错误，比如取消请求，直接退出。&lt;/li&gt;
&lt;li&gt;遇到 5xx 类错误，服务端错误。需要考虑是否重试了。&lt;/li&gt;
&lt;li&gt;isOneShot 标记，true 代表是 Set/Delete 操作，请求失败不再重试。应该跟请求是否幂等有关。&lt;/li&gt;
&lt;li&gt;可以重试的请求，重试直到成功或是循环结束。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200417-etcd_client/ - </description>
        </item>
    
    
    
        <item>
        <title>机器学习在线推理部署方案：Cortex</title>
        <link>https://xujiahua.github.io/posts/20200416-cortex/</link>
        <pubDate>Thu, 16 Apr 2020 11:33:18 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200416-cortex/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200416-cortex/ -&lt;h2 id=&#34;cortex-介绍&#34;&gt;Cortex 介绍&lt;/h2&gt;
&lt;p&gt;官方网站：Deploy machine learning models in production &lt;a href=&#34;https://www.cortex.dev/&#34;&gt;https://www.cortex.dev/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub &lt;a href=&#34;https://github.com/cortexlabs/cortex&#34;&gt;https://github.com/cortexlabs/cortex&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The CLI sends configuration and code to the cluster every time you run &lt;code&gt;cortex deploy&lt;/code&gt;. Each model is loaded into a Docker container, along with any Python packages and request handling code. The model is exposed as a web service using Elastic Load Balancing (ELB), TensorFlow Serving, and ONNX Runtime. The containers are orchestrated on Elastic Kubernetes Service (EKS) while logs and metrics are streamed to CloudWatch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CLI工具将配置文件和代码推送到集群。模型连同Python依赖包和请求处理的代码被Docker容器打包。使用AWS ELB等暴露出Web服务。容器使用AWS EKS编排，日志和指标会推送到AWS CloudWatch。&lt;/p&gt;
&lt;h3 id=&#34;key-features&#34;&gt;Key Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi framework:&lt;/strong&gt; Cortex supports TensorFlow, PyTorch, scikit-learn, XGBoost, and more. 支持主流的机器学习、深度学习框架&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autoscaling:&lt;/strong&gt; Cortex automatically scales APIs to handle production workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU / GPU support:&lt;/strong&gt; Cortex can run inference on CPU or GPU infrastructure. CPU/GPU都支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spot instances:&lt;/strong&gt; Cortex supports EC2 spot instances.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rolling updates:&lt;/strong&gt; Cortex updates deployed APIs without any downtime. 依赖k8s的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log streaming:&lt;/strong&gt; Cortex streams logs from deployed models to your CLI. 依赖CloudWatch的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prediction monitoring:&lt;/strong&gt; Cortex monitors network metrics and tracks predictions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Minimal configuration:&lt;/strong&gt; Cortex deployments are defined in a single &lt;code&gt;cortex.yaml&lt;/code&gt; file.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;我的体验&#34;&gt;我的体验&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;与AWS深度绑定。对私有云、国内公有云不够友好了。&lt;/li&gt;
&lt;li&gt;依赖Kubernetes服务。&lt;/li&gt;
&lt;li&gt;依赖云存储服务，比如S3、OSS。cortex deploy的建议：cortex will zip files and upload them to the cluster; we recommend that you upload large files/directories (e.g. models) to s3 and download them in your api&amp;rsquo;s &lt;strong&gt;init&lt;/strong&gt; function,&lt;/li&gt;
&lt;li&gt;有一套Python API服务的模板，并使用Docker封装。比如 &lt;a href=&#34;https://github.com/cortexlabs/cortex/blob/master/images/python-serve/Dockerfile&#34;&gt;https://github.com/cortexlabs/cortex/blob/master/images/python-serve/Dockerfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推理Predictor类按照Cortex定义的接口规范实现，所在目录挂载到 /mnt/project 目录。&lt;/li&gt;
&lt;li&gt;启动容器，预置脚本会安装&lt;code&gt;requirement.txt&lt;/code&gt;，并动态加载Predictor类。&lt;/li&gt;
&lt;li&gt;使用者只需要处理模型训练和按照规范定义Predictor类。重复的API定义、部署、扩容，都已经被隐藏掉了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;代码结构&#34;&gt;代码结构&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;cli 目录：客户端。deploy操作，就是把本地的配置文件压缩成zip包上传。&lt;/li&gt;
&lt;li&gt;pkg/operator 目录：服务端。deploy接口在此：zip包会上传到S3，编程的方式申请k8s资源（deployment, service, virtualService），直接向k8s API server发送请求。&lt;/li&gt;
&lt;li&gt;pkg/lib 目录：比较核心的Go代码。&lt;/li&gt;
&lt;li&gt;pkg/workloads/cortex/downloader 目录：在k8s中作为InitContainer，用于下载配置文件到Pod中。&lt;/li&gt;
&lt;li&gt;pkg/workloads 目录：推理服务的代码，比较通用。pkg/workloads/cortex/serve/run.sh 留了个口子 &lt;code&gt;/mnt/project&lt;/code&gt;，每个服务个性化的部分留给开发者（遵从规范）。&lt;/li&gt;
&lt;li&gt;images 目录：镜像文件。包括 operator 的镜像文件，也包括推理服务的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;具体看看创建推理服务容器的过程。&lt;/p&gt;
&lt;p&gt;申请 K8s Deployment。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151230669.png&#34; alt=&#34;image-20200416151230669&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里分为三大类。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151318515.png&#34; alt=&#34;image-20200416151318515&#34;&gt;&lt;/p&gt;
&lt;p&gt;关注PythonPredictorType。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151537448.png&#34; alt=&#34;image-20200416151537448&#34;&gt;&lt;/p&gt;
&lt;p&gt;传入 InitContainer （代码见 pkg/workloads/cortex/downloader）的参数如下，将S3上存储的配置信息和predictor文件等下载到Pod中的 &lt;code&gt;/mnt/project&lt;/code&gt;目录（&lt;code&gt;_emptyDirMountPath = &amp;quot;/mnt&amp;quot;&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416152324873.png&#34; alt=&#34;image-20200416152324873&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为Pod内容器共享存储空间，这样推理服务容器就能读取到 &lt;code&gt;/mnt/project&lt;/code&gt;了。&lt;/p&gt;
&lt;h2 id=&#34;cortex-镜像体验&#34;&gt;cortex 镜像体验&lt;/h2&gt;
&lt;p&gt;下载地址 &lt;a href=&#34;https://hub.docker.com/r/cortexlabs/python-serve/tags&#34;&gt;https://hub.docker.com/r/cortexlabs/python-serve/tags&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;容器内代码也是依赖S3的，不修改还不能直接使用🤣。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416161622829.png&#34; alt=&#34;image-20200416161622829&#34;&gt;&lt;/p&gt;
&lt;p&gt;到此为止吧。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -e CORTEX_SERVING_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_WORKERS_PER_REPLICA&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_MAX_WORKER_CONCURRENCY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_THREADS_PER_WORKER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_SO_MAX_CONN&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_CACHE_DIR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/mnt/spec &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0.15.1 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -v &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;:/mnt/project &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -v &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;:/mnt/spec &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -p 5000:5000 cortexlabs/python-serve:0.15.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;- https://xujiahua.github.io/posts/20200416-cortex/ - </description>
        </item>
    
    
    
        <item>
        <title>k8s 应用日志收集</title>
        <link>https://xujiahua.github.io/posts/20200414-k8s-logging/</link>
        <pubDate>Tue, 14 Apr 2020 09:53:35 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200414-k8s-logging/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200414-k8s-logging/ -&lt;h2 id=&#34;k8s-日志收集架构&#34;&gt;k8s 日志收集架构&lt;/h2&gt;
&lt;p&gt;以下是比较一般、普适的架构。更多参考：Kubernetes 日志架构 &lt;a href=&#34;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&#34;&gt;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/logging-with-node-agent.png&#34; alt=&#34;使用节点日志记录代理&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;容器化应用将日志写入&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Docker容器引擎将&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;流重定向到日志驱动，比如默认的json-file。&lt;/li&gt;
&lt;li&gt;json-file日志驱动将日志写入到（宿主机上的）文件。&lt;/li&gt;
&lt;li&gt;日志收集工具以DaemonSet的形式安装在每个节点。&lt;/li&gt;
&lt;li&gt;日志收集工具监听文件变化，并将日志写入到日志中心服务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;k8s-日志收集细节&#34;&gt;k8s 日志收集细节&lt;/h2&gt;
&lt;h3 id=&#34;实战&#34;&gt;实战&lt;/h3&gt;
&lt;p&gt;可以直接参考以下教程：minikube创建了一个Kubernetes集群，Fluentd收集日志，存入ElasticSearch，使用Kibana查看日志。典型的EFK技术栈。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logging in Kubernetes with Elasticsearch, Kibana, and Fluentd &lt;a href=&#34;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&#34;&gt;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在Kibana上看收集到的日志。能看到日志收集工具也采集了容器、镜像、Pod有关的信息。这些上下文信息能让人定位到是哪个应用在生产日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414104511399.png&#34; alt=&#34;image-20200414104511399&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;fluentd-收集上下文信息&#34;&gt;fluentd 收集上下文信息&lt;/h3&gt;
&lt;p&gt;Docker &lt;code&gt;json-file&lt;/code&gt; 日志驱动写文件，并不记录上下文信息。 &lt;a href=&#34;https://docs.docker.com/config/containers/logging/json-file/&#34;&gt;https://docs.docker.com/config/containers/logging/json-file/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;log&amp;quot;:&amp;quot;Log line is here\n&amp;quot;,&amp;quot;stream&amp;quot;:&amp;quot;stdout&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2019-01-01T11:11:11.111111111Z&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上文中使用的日志收集镜像是 &lt;code&gt;fluent/fluentd-kubernetes-daemonset:v1.3-debian-elasticsearch&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;具体代码路径在此 &lt;a href=&#34;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&#34;&gt;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;收集容器目录下的日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105706563.png&#34; alt=&#34;image-20200414105706563&#34;&gt;&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;kubernetes_metadata&lt;/code&gt;这个第三方插件获取容器相关的上下文信息。这里是通过请求API server得到metadata的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105752287.png&#34; alt=&#34;image-20200414105752287&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubernetes_metadata&lt;/code&gt; 插件地址 &lt;a href=&#34;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&#34;&gt;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;插件中有缓存metadata的选项，不用担心每处理一条日志，就要向API server发送请求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414111028867.png&#34; alt=&#34;image-20200414111028867&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/20200414-k8s-logging/ - </description>
        </item>
    
    
    
        <item>
        <title>Metabase &#43; Spark SQL</title>
        <link>https://xujiahua.github.io/posts/20200410-metabase-spark-sql/</link>
        <pubDate>Fri, 10 Apr 2020 16:41:53 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200410-metabase-spark-sql/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200410-metabase-spark-sql/ -&lt;p&gt;这是大数据 BI 平台的第二步，BI 工具的搭建。假设已经配置好 Spark SQL JDBC Server，并启用了Kerberos。参考  &lt;a href=&#34;https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/&#34;&gt;https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里，我们选择了开源产品 Metabase。&lt;/p&gt;
&lt;p&gt;最终，大数据 BI 平台，是由 1) 以Metabase作为BI可视化，2) 由HDFS（分布式文件存储） + parquet（列式数据存储格式）+ Hive metastore（SQL表结构信息维护） + Spark SQL（批处理引擎）组合的OLAP数据库组成。&lt;/p&gt;
&lt;h2 id=&#34;metabase-简介&#34;&gt;Metabase 简介&lt;/h2&gt;
&lt;p&gt;Metabase is the easy, open source way for everyone in your company to ask questions and learn from data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.metabase.com/&#34;&gt;https://www.metabase.com/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据库支持&#34;&gt;数据库支持&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BigQuery&lt;/li&gt;
&lt;li&gt;Druid&lt;/li&gt;
&lt;li&gt;Google Analytics&lt;/li&gt;
&lt;li&gt;H2&lt;/li&gt;
&lt;li&gt;MongoDB&lt;/li&gt;
&lt;li&gt;MySQL/MariaDB&lt;/li&gt;
&lt;li&gt;PostgreSQL&lt;/li&gt;
&lt;li&gt;Presto&lt;/li&gt;
&lt;li&gt;Amazon Redshift&lt;/li&gt;
&lt;li&gt;Snowflake&lt;/li&gt;
&lt;li&gt;Spark SQL&lt;/li&gt;
&lt;li&gt;SQLite&lt;/li&gt;
&lt;li&gt;SQL Server&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.metabase.com/docs/latest/faq/setup/which-databases-does-metabase-support.html&#34;&gt;https://www.metabase.com/docs/latest/faq/setup/which-databases-does-metabase-support.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里有我们需要的Spark SQL，我们的大数据集群可以支持。比较遗憾的是没有Impala。&lt;/p&gt;
&lt;h2 id=&#34;metabase-安装&#34;&gt;Metabase 安装&lt;/h2&gt;
&lt;h3 id=&#34;mysql&#34;&gt;MySQL&lt;/h3&gt;
&lt;p&gt;使用MySQL作为元数据存储。复用之前CDH的MySQL实例。&lt;/p&gt;
&lt;p&gt;创建数据库、用户。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- 适合MySQL5.7及以上版本，支持更大的max key length。一个字符使用四个字节。
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; metabase CHARACTER &lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; utf8mb4 &lt;span style=&#34;color:#66d9ef&#34;&gt;COLLATE&lt;/span&gt; utf8mb4_unicode_ci;
&lt;span style=&#34;color:#75715e&#34;&gt;-- 适合MySQL5.6及以下版本。一个字符使用3个字节。
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; metabase CHARACTER &lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; utf8 &lt;span style=&#34;color:#66d9ef&#34;&gt;COLLATE&lt;/span&gt; utf8_unicode_ci;

&lt;span style=&#34;color:#75715e&#34;&gt;-- % 表示不限制host
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;USER&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt; IDENTIFIED &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;GRANT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ALL&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; metabase.&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TO&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;;

FLUSH &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIVILEGES&lt;/span&gt;;
&lt;span style=&#34;color:#75715e&#34;&gt;-- https://dev.mysql.com/doc/refman/5.7/en/grant.html
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;常见问题&#34;&gt;常见问题&lt;/h4&gt;
&lt;p&gt;mysql 5.7与5.6的区别。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;767 bytes is the &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.1/en/create-index.html&#34;&gt;stated prefix limitation&lt;/a&gt; for InnoDB tables in MySQL version 5.6 (and prior versions). It&amp;rsquo;s 1,000 bytes long for MyISAM tables. In MySQL version 5.7 and upwards this limit has been increased to 3072 bytes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Caused by: java.sql.SQLException: Specified key was too long; max key length is 767 bytes&lt;/p&gt;
&lt;p&gt;Caused by: liquibase.exception.DatabaseException: (conn=175553) Specified key was too long; max key length is 767 bytes [Failed SQL: CREATE TABLE &lt;code&gt;metabase&lt;/code&gt;.&lt;code&gt;core_organization&lt;/code&gt; (&lt;code&gt;id&lt;/code&gt; INT AUTO_INCREMENT NOT NULL, &lt;code&gt;slug&lt;/code&gt; VARCHAR(254) NOT NULL, &lt;code&gt;name&lt;/code&gt; VARCHAR(254) NOT NULL, &lt;code&gt;description&lt;/code&gt; TEXT NULL, &lt;code&gt;logo_url&lt;/code&gt; VARCHAR(254) NULL, &lt;code&gt;inherits&lt;/code&gt; BIT(1) NOT NULL, CONSTRAINT &lt;code&gt;PK_CORE_ORGANIZATION&lt;/code&gt; PRIMARY KEY (&lt;code&gt;id&lt;/code&gt;), UNIQUE (&lt;code&gt;slug&lt;/code&gt;))]&lt;/p&gt;
&lt;h3 id=&#34;metabase&#34;&gt;Metabase&lt;/h3&gt;
&lt;p&gt;下载metabase。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 以 /opt/metabase 为工作目录&lt;/span&gt;
mkdir /opt/metabase &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; cd /opt/metabase
&lt;span style=&#34;color:#75715e&#34;&gt;# 下载最新版本的metabase，参考 https://www.metabase.com/start/jar.html&lt;/span&gt;
wget https://downloads.metabase.com/v0.35.1/metabase.jar
&lt;span style=&#34;color:#75715e&#34;&gt;# 创建插件目录&lt;/span&gt; 
mkdir plugins
&lt;span style=&#34;color:#75715e&#34;&gt;# Spark SQL的驱动，jar包内置的有问题&lt;/span&gt;
wget https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar -O plugins/metabase-sparksql-deps-1.2.1.spark2-standalone.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动脚本 start.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
export MB_DB_TYPE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mysql
export MB_DB_DBNAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3306&lt;/span&gt;
export MB_DB_USER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_PASS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_HOST&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;172.31.0.100

kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING

mkdir -p logs

nohup java -Djavax.security.auth.useSubjectCredsOnly&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;false -jar metabase.jar  &amp;gt;&amp;gt; logs/metabase.log 2&amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &amp;amp;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;停止脚本 stop.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
ps -ef | grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase.jar&amp;#39;&lt;/span&gt; | grep -v &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;grep&amp;#39;&lt;/span&gt; | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt; | xargs kill -9

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;文件夹结构如下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 metabase&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ tree
├── hive.xh-hd2-peggy-dost000003.keytab
├── logs
│   └── metabase.log
├── metabase.jar
├── plugins
│   ├── metabase-sparksql-deps-1.2.1.spark2-standalone.jar
│   ├── sparksql.metabase-driver.jar
│   ├── ...
├── start.sh
└── stop.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Metabase搭建手册：使用SparkSQL连接Hive &lt;a href=&#34;https://webcache.googleusercontent.com/search?q=cache:DcmHXWOc9woJ:https://immm.in/archives/24.html+&amp;amp;cd=5&amp;amp;hl=zh-CN&amp;amp;ct=clnk&amp;amp;gl=hk&#34;&gt;https://webcache.googleusercontent.com/search?q=cache:DcmHXWOc9woJ:https://immm.in/archives/24.html+&amp;amp;cd=5&amp;amp;hl=zh-CN&amp;amp;ct=clnk&amp;amp;gl=hk&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;配置-spark-sql-连接&#34;&gt;配置 Spark SQL 连接&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410180255501.png&#34; alt=&#34;image-20200410180255501&#34;&gt;&lt;/p&gt;
&lt;p&gt;保存没有报错，就是成功了。&lt;/p&gt;
&lt;h4 id=&#34;常见问题-1&#34;&gt;常见问题&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;使用内置的驱动报错：Unrecognized Hadoop major version number: 3.1.1&lt;/li&gt;
&lt;li&gt;使用metabase-sparksql-deps-1.2.1.spark2-standalone.jar这个驱动报错，然而beeline连接是没问题的： transport.TSaslTransport :: SASL negotiation failure
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一个问题，暂时忽略，使用其他驱动。&lt;/p&gt;
&lt;p&gt;按理说，https://github.com/metabase/sparksql-deps 已经合并到 &lt;a href=&#34;https://github.com/metabase/metabase/tree/v0.35.1/modules/drivers/sparksql&#34;&gt;https://github.com/metabase/metabase/tree/v0.35.1/modules/drivers/sparksql&lt;/a&gt; 了。内置驱动就能用才对。&lt;/p&gt;
&lt;p&gt;能看到依赖hadoop-common包的版本差异。TODO: 还得细看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200411071918161.png&#34; alt=&#34;image-20200411071918161&#34;&gt;&lt;/p&gt;
&lt;p&gt;依赖的hadoop版本是3.1.0。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200411072135265.png&#34; alt=&#34;image-20200411072135265&#34;&gt;&lt;/p&gt;
&lt;p&gt;内置Driver依赖3.1.1。报错信息也是包含3.1.1，是否切到3.1.0，重新打包就可以了？&lt;/p&gt;
&lt;p&gt;第二个问题需要设置Java参数 &lt;code&gt;-Djavax.security.auth.useSubjectCredsOnly=false&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;通过底层机制获取凭证信息，而不是通过应用执行认证操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410173734177.png&#34; alt=&#34;image-20200410173734177&#34;&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to connnect sparksql in Kerberos enviroment &lt;a href=&#34;https://discourse.metabase.com/t/how-to-connnect-sparksql-in-kerberos-enviroment/8290/2&#34;&gt;https://discourse.metabase.com/t/how-to-connnect-sparksql-in-kerberos-enviroment/8290/2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided https://stackoverflow.com/questions/32205087/javax-security-sasl-saslexception-gss-initiate-failed-caused-by-gssexception&lt;/li&gt;
&lt;li&gt;Below are listed some problems that may occur when attempting a login, and suggestions for solving them. &lt;a href=&#34;https://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/Troubleshooting.html&#34;&gt;https://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/Troubleshooting.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;与-superset-比较&#34;&gt;与 Superset 比较&lt;/h2&gt;
&lt;p&gt;Superset是另外一个开源的BI工具。但是使用过程中体验不佳：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不支持多表JOIN。这个不能忍。&lt;/li&gt;
&lt;li&gt;直接写SQL，数据没法可视化。效率有点低下。&lt;/li&gt;
&lt;li&gt;外观丑陋。FlaskAppbuilder生成的前后端架子。&lt;/li&gt;
&lt;li&gt;Table源如果改了，建议删掉再添加，不然会有各种意外。&lt;/li&gt;
&lt;li&gt;交互体验差。自定义SELECT COUNT(cookie) as pv，死活搞不定。正确的使用方式是设置label，体验不直观。&lt;/li&gt;
&lt;li&gt;小bug多。用起来太容易烦躁了。对身心健康不好。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200410-metabase-spark-sql/ - </description>
        </item>
    
    
    
        <item>
        <title>CDH6 启用 Spark Thrift Server</title>
        <link>https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/</link>
        <pubDate>Fri, 10 Apr 2020 10:07:16 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/ -&lt;p&gt;很遗憾，CDH版本的Spark阉割了Thrift Server。（可能与自家产品Impala有竞争关系的原因。）&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark.html#spark__d99299e107&#34;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark.html#spark__d99299e107&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ll /opt/cloudera/parcels/CDH/lib/spark/sbin/
total 84
-rwxr-xr-x 1 root root 2803 Nov  9 00:05 slaves.sh
-rwxr-xr-x 1 root root 1429 Nov  9 00:05 spark-config.sh
-rwxr-xr-x 1 root root 5689 Nov  9 00:05 spark-daemon.sh
-rwxr-xr-x 1 root root 1262 Nov  9 00:05 spark-daemons.sh
-rwxr-xr-x 1 root root 1190 Nov  9 00:05 start-all.sh
-rwxr-xr-x 1 root root 1274 Nov  9 00:05 start-history-server.sh
-rwxr-xr-x 1 root root 2050 Nov  9 00:05 start-master.sh
-rwxr-xr-x 1 root root 1877 Nov  9 00:05 start-mesos-dispatcher.sh
-rwxr-xr-x 1 root root 1423 Nov  9 00:05 start-mesos-shuffle-service.sh
-rwxr-xr-x 1 root root 1279 Nov  9 00:05 start-shuffle-service.sh
-rwxr-xr-x 1 root root 3151 Nov  9 00:05 start-slave.sh
-rwxr-xr-x 1 root root 1527 Nov  9 00:05 start-slaves.sh
-rwxr-xr-x 1 root root 1478 Nov  9 00:05 stop-all.sh
-rwxr-xr-x 1 root root 1056 Nov  9 00:05 stop-history-server.sh
-rwxr-xr-x 1 root root 1080 Nov  9 00:05 stop-master.sh
-rwxr-xr-x 1 root root 1227 Nov  9 00:05 stop-mesos-dispatcher.sh
-rwxr-xr-x 1 root root 1084 Nov  9 00:05 stop-mesos-shuffle-service.sh
-rwxr-xr-x 1 root root 1067 Nov  9 00:05 stop-shuffle-service.sh
-rwxr-xr-x 1 root root 1557 Nov  9 00:05 stop-slave.sh
-rwxr-xr-x 1 root root 1064 Nov  9 00:05 stop-slaves.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可见，没有Thrift Server的启动脚本。&lt;/p&gt;
&lt;p&gt;借鉴网上资料（CDH 6成功启动spark-thrift服务 &lt;a href=&#34;https://blog.csdn.net/qq_34864753/article/details/102729859&#34;&gt;https://blog.csdn.net/qq_34864753/article/details/102729859&lt;/a&gt;），在不修改CDH Spark的前提下，我们需要启动一个独立的Spark Thrift Server。&lt;/p&gt;
&lt;p&gt;还需要考虑CDH Kerberos认证的问题。&lt;/p&gt;
&lt;h2 id=&#34;spark-thrift-server-简介&#34;&gt;Spark Thrift Server 简介&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/sparksqlthriftserver.png&#34; alt=&#34;Spark SQL Thrift Server&#34;&gt;&lt;/p&gt;
&lt;p&gt;Spark Thrift Server是Spark社区基于HiveServer2实现的一个Thrift服务。旨在无缝兼容HiveServer2。&lt;/p&gt;
&lt;p&gt;因为Spark Thrift Server的接口和协议都和HiveServer2完全一致，因此我们部署好Spark Thrift Server后，可以直接使用hive的beeline访问Spark Thrift Server执行相关语句。&lt;/p&gt;
&lt;p&gt;Spark Thrift Server的目的也只是取代HiveServer2，因此它依旧可以和Hive Metastore进行交互，获取到hive的元数据。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://www.jianshu.com/p/b719c6415411&#34;&gt;https://www.jianshu.com/p/b719c6415411&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;apache-spark配置&#34;&gt;Apache Spark配置&lt;/h2&gt;
&lt;h3 id=&#34;下载官方版本&#34;&gt;下载官方版本&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /opt
wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz
cd spark-2.4.0-bin-hadoop2.7 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ln -s &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt; /opt/spark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;spark配置文件&#34;&gt;Spark配置文件&lt;/h3&gt;
&lt;p&gt;通过软链接的方式复用Hive的配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ln -s /etc/hive/conf/hive-site.xml /opt/spark/conf/hive-site.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最后配置文件夹长这样。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# ll /opt/spark/conf/&lt;/span&gt;
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp  &lt;span style=&#34;color:#ae81ff&#34;&gt;996&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; docker.properties.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;1105&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; fairscheduler.xml.template
lrwxrwxrwx &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root   root     &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt; Apr  &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt; 11:05 hive-site.xml -&amp;gt; /etc/hive/conf/hive-site.xml
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;2025&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; log4j.properties.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;7801&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; metrics.properties.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp  &lt;span style=&#34;color:#ae81ff&#34;&gt;865&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; slaves.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;1292&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; spark-defaults.conf.template
-rwxr-xr-x &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;4221&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; spark-env.sh.template
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;spark配置文件配置方式&#34;&gt;Spark配置文件配置方式&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;默认配置路径：&lt;code&gt;$SPARK_HOME/conf&lt;/code&gt;，如果&lt;code&gt;$SPARK_HOME&lt;/code&gt;不存在，脚本中会把脚本上层目录当做&lt;code&gt;$SPARK_HOME&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SPARK_CONF_DIR&lt;/code&gt;，可以指定SPARK配置文件夹。&lt;/li&gt;
&lt;li&gt;Spark classpath，如果&lt;code&gt;hdfs-site.xml&lt;/code&gt; &lt;code&gt;core-site.xml&lt;/code&gt;在classpath，Spark可以读取。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$HADOOP_CONF_DIR&lt;/code&gt;，一般是&lt;code&gt;/etc/hadoop/conf&lt;/code&gt;目录，读Hadoop配置信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$YARN_CONF_DIR&lt;/code&gt;，一般也是&lt;code&gt;/etc/hadoop/conf&lt;/code&gt;目录。&lt;/li&gt;
&lt;li&gt;命令行中可以覆盖以上配置文件中的具体参数。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://spark.apache.org/docs/latest/configuration.html#inheriting-hadoop-cluster-configuration&#34;&gt;https://spark.apache.org/docs/latest/configuration.html#inheriting-hadoop-cluster-configuration&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;spark-lib修改&#34;&gt;Spark lib修改&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /opt/spark
rm -rf jars/hadoop-yarn-*
cp /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/hadoop-yarn-* jars/
cp /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/hive-shims-scheduler-2.1.1-cdh6.3.2.jar jars/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;kerberos-认证&#34;&gt;Kerberos 认证&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410140136660.png&#34; alt=&#34;image-20200410140136660&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;图中的三个角色，在Kerkeros认证体系下都对应一个principal。Kerberos principal相当于用户名，keytab相当于密码。权限配置，依靠hive与hdfs本身。&lt;/li&gt;
&lt;li&gt;JDBC客户端与Spark JDBC Server需要使用Kerberos认证。JDBC客户端需要拥有principal/keytab对。我们手动创建。&lt;/li&gt;
&lt;li&gt;Spark JDBC Server与Hive metastore需要使用Kerberos认证。JDBC服务端需要拥有principal/keytab对。我们手动创建。&lt;/li&gt;
&lt;li&gt;Hive metastore也拥有自己的principal/keytab对，不过这个已经由CDH托管了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;常见Kerberos错误：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;org.apache.hive.service.ServiceException: Unable to login to kerberos with given principal/keytab / Caused by: java.io.IOException: HiveServer2 Kerberos principal or keytab is not correctly configured&lt;/li&gt;
&lt;li&gt;Caused by: java.io.IOException: Login failure for &lt;a href=&#34;mailto:hive/xh-hd2-peggy-dost000003@PEGGY.LING&#34;&gt;hive/xh-hd2-peggy-dost000003@PEGGY.LING&lt;/a&gt; from keytab hive.keytab: javax.security.auth.login.LoginException: Unable to obtain password from user&lt;/li&gt;
&lt;li&gt;SASL negotiation failure
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;创建-spark-jdbc-server-的-principal&#34;&gt;创建 Spark JDBC Server 的 Principal&lt;/h3&gt;
&lt;p&gt;因为复用了Hive的配置文件，待创建的principal的名字需要满足配置中的规范。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000004 spark&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ cat conf/hive-site.xml
...
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.authentication.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hive/_HOST@PEGGY.LING&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
... 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在Kerberos服务器创建 principal及导出 keytab，同步到Spark JDBC Server所在机器。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create principal&lt;/span&gt;
kadmin.local addprinc -randkey hive/xh-hd2-peggy-dost000004
&lt;span style=&#34;color:#75715e&#34;&gt;# export keytab&lt;/span&gt;
kadmin.local ktadd -k hive.xh-hd2-peggy-dost000004.keytab hive/xh-hd2-peggy-dost000004
&lt;span style=&#34;color:#75715e&#34;&gt;# 验证是否OK&lt;/span&gt;
kinit -kt hive.xh-hd2-peggy-dost000004.keytab hive/xh-hd2-peggy-dost000004@PEGGY.LING
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动-spark-jdbc-server&#34;&gt;启动 Spark JDBC Server&lt;/h3&gt;
&lt;p&gt;启动脚本如下。因为配置文件里没有指定keytab的路径，需要通过&lt;code&gt;--hiveconf&lt;/code&gt;指定。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
export JAVA_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/java/jdk1.8.0_181-cloudera
export PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$PATH:$JAVA_HOME/bin
export HADOOP_CONF_DIR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/hadoop/conf

kinit -kt hive.xh-hd2-peggy-dost000004.keytab hive/xh-hd2-peggy-dost000004@PEGGY.LING

sbin/start-thriftserver.sh &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--hiveconf hive.server2.authentication.kerberos.keytab hive.xh-hd2-peggy-dost000004.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;也可以参考这篇文章：&lt;/p&gt;
&lt;p&gt;Configuring Spark Thrift Server with Kerberos &lt;a href=&#34;https://mapr.com/docs/61/Spark/ConfiguringSparkSQLThriftServer_Kerberos.html&#34;&gt;https://mapr.com/docs/61/Spark/ConfiguringSparkSQLThriftServer_Kerberos.html&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;kinit-ticket过期问题&#34;&gt;kinit ticket过期问题&lt;/h4&gt;
&lt;p&gt;Spark Thrift Server 进程会自动处理Kerberos ticket renewal操作。&lt;/p&gt;
&lt;p&gt;默认的ticket_lifetime 1d，renew_lifetime 7d。上次kinit是04/10。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webapp@xh-hd2-peggy-dost000004 spark]$ klist
Ticket cache: FILE:/tmp/krb5cc_1000
Default principal: hive/xh-hd2-peggy-dost000004@PEGGY.LING

Valid starting       Expires              Service principal
04/13/2020 01:32:45  04/14/2020 01:32:45  krbtgt/PEGGY.LING@PEGGY.LING
	renew until 04/17/2020 15:56:45
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就看7天后会怎么样了。renew周期过了，会重建么？理论上是可以的。&lt;/p&gt;
&lt;p&gt;看到Spark代码中已经有kerberos集成了，包括登录啥的。&lt;/p&gt;
&lt;p&gt;spark/sql/hive-thriftserver/v2.3.5/src/main/java/org/apache/hive/service/auth/HiveAuthFactory.java&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200413110032646.png&#34; alt=&#34;image-20200413110032646&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200413105917167.png&#34; alt=&#34;image-20200413105917167&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;创建-jdbc-client-的-principal&#34;&gt;创建 JDBC Client 的 Principal&lt;/h3&gt;
&lt;p&gt;在Kerberos服务器创建 principal及导出 keytab，同步到 JDBC Client 所在机器。这里对principal的名称没有严格要求。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create principal&lt;/span&gt;
kadmin.local addprinc -randkey hive/xh-hd2-peggy-dost000003
&lt;span style=&#34;color:#75715e&#34;&gt;# export keytab&lt;/span&gt;
kadmin.local ktadd -k hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003 
&lt;span style=&#34;color:#75715e&#34;&gt;# 验证是否OK&lt;/span&gt;
kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动-jdbc-client&#34;&gt;启动 JDBC Client&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 spark&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 spark&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ bin/beeline -u &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;jdbc:hive2://xh-hd2-peggy-dost000004:10000/default;principal=hive/xh-hd2-peggy-dost000004@PEGGY.LING&amp;#34;&lt;/span&gt;
Connecting to jdbc:hive2://xh-hd2-peggy-dost000004:10000/default;principal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hive/xh-hd2-peggy-dost000004@PEGGY.LING
2020-04-10 16:09:01 INFO  Utils:310 - Supplied authorities: xh-hd2-peggy-dost000004:10000
2020-04-10 16:09:01 INFO  Utils:397 - Resolved authority: xh-hd2-peggy-dost000004:10000
2020-04-10 16:09:01 INFO  HiveConnection:203 - Will try to open client transport with JDBC Uri: jdbc:hive2://xh-hd2-peggy-dost000004:10000/default;principal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hive/xh-hd2-peggy-dost000004@PEGGY.LING
Connected to: Spark SQL &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;version 2.4.0&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
Driver: Hive JDBC &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;version 1.2.1.spark2&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 1.2.1.spark2 by Apache Hive
0: jdbc:hive2://xh-hd2-peggy-dost000004:10000&amp;gt; show databases;
+---------------+--+
| databaseName  |
+---------------+--+
| db1           |
| default       |
| product       |
+---------------+--+
&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; rows selected &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.091 seconds&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;至此，Thrift Server的启用就完成了。&lt;/p&gt;
&lt;h3 id=&#34;yarn-运行&#34;&gt;YARN 运行&lt;/h3&gt;
&lt;p&gt;失败了，TODO&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sbin/start-thriftserver.sh --hiveconf hive.server2.authentication.kerberos.keytab hive.keytab --hiveconf hive.server2.thrift.port=10001 --queue root.zm_yarn_pool.development  --master yarn --executor-memory 4g --executor-cores 2 --num-executors 20

2020-04-09 17:56:19 INFO  Client:54 - Requesting a new application from cluster with 5 NodeManagers
Exception in thread &amp;quot;main&amp;quot; java.lang.NoClassDefFoundError: org/apache/hadoop/util/FastNumberFormat
        at org.apache.hadoop.yarn.api.records.ApplicationId.toString(ApplicationId.java:104)
        at org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$getAppStagingDir(Client.scala:1222)
        at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$cleanupStagingDirInternal$1(Client.scala:206)
        at org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:226)
        at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:191)
        at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57)
        at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:178)
        at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:501)
        at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
        at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:935)
        at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:926)
        at scala.Option.getOrElse(Option.scala:121)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;外传cdh是如何管理hadoop配置文件的&#34;&gt;【外传】CDH是如何管理Hadoop配置文件的&lt;/h2&gt;
&lt;p&gt;以下结果都是通过观察实践所得。&lt;/p&gt;
&lt;p&gt;以Hive为例，&lt;code&gt;/etc/hive/conf&lt;/code&gt;下的配置文件由CDH生成。（CDH管理界面上可以修改这些配置。）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# ll /etc/hive/conf/&lt;/span&gt;
total &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root   &lt;span style=&#34;color:#ae81ff&#34;&gt;21&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 __cloudera_generation__
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root   &lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 __cloudera_metadata__
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;3846&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 core-site.xml
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root  &lt;span style=&#34;color:#ae81ff&#34;&gt;617&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hadoop-env.sh
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;3839&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hdfs-site.xml
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;2655&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hive-env.sh
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;6925&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hive-site.xml
...

&lt;span style=&#34;color:#75715e&#34;&gt;# head /etc/hive/conf/hive-site.xml&lt;/span&gt;
&amp;lt;?xml version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.0&amp;#34;&lt;/span&gt; encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;UTF-8&amp;#34;&lt;/span&gt;?&amp;gt;

&amp;lt;!--Autogenerated by Cloudera Manager--&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;thrift://xh-hd2-peggy-dost001:9083&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.client.socket.timeout&amp;lt;/name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们的集群是开启了Kerberos认证的。但是上述配置文件里没见principal的keytab路径配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grep keytab /etc/hive/conf/hive-site.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;也就是说，&lt;code&gt;/etc/hive/conf&lt;/code&gt;不是真正在被使用的配置文件。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/var/run/cloudera-scm-agent/process/&lt;/code&gt; 这个目录中有所有CDH监控的进程，包括我们关注的Hive进程。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://community.cloudera.com/t5/Support-Questions/Location-of-keytab-files/td-p/33716&#34;&gt;https://community.cloudera.com/t5/Support-Questions/Location-of-keytab-files/td-p/33716&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ls /var/run/cloudera-scm-agent/process/*hive*
/var/run/cloudera-scm-agent/process/954-hive-HIVEMETASTORE:
cloudera-monitor.properties        config.zip     creds.localjceks  hdfs-site.xml  hive-log4j2.properties  logs       redaction-rules.json  service-metrics.properties  supervisor_status
cloudera-stack-monitor.properties  core-site.xml  exit_code         hive.keytab    hive-site.xml           proc.json  sentry-site.xml       supervisor.conf             yarn-conf

/var/run/cloudera-scm-agent/process/955-hive-HIVESERVER2:
cloudera-monitor.properties        config.zip     exit_code           hdfs-site.xml  hive-log4j2.properties  logs                         navigator.lineage.client.properties  redaction-rules.json  service-metrics.properties  supervisor.conf    yarn-conf
cloudera-stack-monitor.properties  core-site.xml  fair-scheduler.xml  hive.keytab    hive-site.xml           navigator.client.properties  proc.json                            sentry-site.xml       spark-defaults.conf         supervisor_status

/var/run/cloudera-scm-agent/process/956-hive-WEBHCAT:
cloudera-monitor.properties        config.zip     exit_code      hive-site.xml  logs       redaction-rules.json        supervisor.conf    webhcat-default.xml       webhcat-site.xml
cloudera-stack-monitor.properties  core-site.xml  hdfs-site.xml  HTTP.keytab    proc.json  service-metrics.properties  supervisor_status  webhcat-log4j.properties  yarn-conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里Hive有三个进程，metastore，hiveserver2，WEBHCAT。可见principal对应的keytab，这里的 &lt;code&gt;hive.keytab&lt;/code&gt;，也是在这里维护着。配置文件也是在&lt;code&gt;/etc/hive/conf&lt;/code&gt;基础上作了改动，比如keytab路径的设置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root 954-hive-HIVEMETASTORE&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grep kerberos hive-site.xml&lt;/span&gt;
    &amp;lt;name&amp;gt;hive.metastore.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.kerberos.keytab.file&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;kerberos&amp;lt;/value&amp;gt;
    
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root 955-hive-HIVESERVER2&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grep kerberos hive-site.xml&lt;/span&gt;
    &amp;lt;value&amp;gt;kerberos&amp;lt;/value&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.authentication.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.authentication.kerberos.keytab&amp;lt;/name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;HiveMetaStore与HiveServer2使用的keytab是不同的。一个principal对应多个keytab么？TODO：可能是因为加密随机的原因？？？&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root@xh-hd2-peggy-dost001 955-hive-HIVESERVER2&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# md5sum hive.keytab&lt;/span&gt;
523357eec4f542b7b3df7ec52cee43b2  hive.keytab

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root@xh-hd2-peggy-dost001 954-hive-HIVEMETASTORE&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# md5sum hive.keytab&lt;/span&gt;
3c6f52333067518ae4bdce1e99878857  hive.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TODO：实验发现，导出两次，之前的keytab就失效了！进入知识盲区。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@xh-hd2-peggy-rost01 ~]# kadmin.local addprinc -randkey hive/xh-hd2-peggy-dost000003
[root@xh-hd2-peggy-rost01 ~]# kadmin.local ktadd -k hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003
[root@xh-hd2-peggy-rost01 ~]# mv hive.xh-hd2-peggy-dost000003.keytab hive.xh-hd2-peggy-dost000003.keytab.bak
[root@xh-hd2-peggy-rost01 ~]# kadmin.local ktadd -k hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003
[root@xh-hd2-peggy-rost01 ~]# kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING
[root@xh-hd2-peggy-rost01 ~]# kinit -kt hive.xh-hd2-peggy-dost000003.keytab.bak hive/xh-hd2-peggy-dost000003@PEGGY.LING
kinit: Password incorrect while getting initial credentials
&lt;/code&gt;&lt;/pre&gt;- https://xujiahua.github.io/posts/20200410-spark-thrift-server-cdh/ - </description>
        </item>
    
    
  </channel>
</rss> 