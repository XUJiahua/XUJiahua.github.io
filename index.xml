<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>许嘉华的博客</title>
    <link>https://xujiahua.github.io/</link>
    <description>Recent content on 许嘉华的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 28 May 2020 09:30:09 +0800</lastBuildDate>
    
        <atom:link href="https://xujiahua.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>Metabase Impala Driver 0528更新日志</title>
        <link>https://xujiahua.github.io/posts/20200528-metabase-impala-type/</link>
        <pubDate>Thu, 28 May 2020 09:30:09 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200528-metabase-impala-type/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200528-metabase-impala-type/ -&lt;p&gt;体验过程中还是碰到不少问题。&lt;/p&gt;
&lt;h2 id=&#34;1-timestamp-类型没有过滤器样式&#34;&gt;1. TIMESTAMP 类型没有过滤器样式&lt;/h2&gt;
&lt;h3 id=&#34;现象&#34;&gt;现象&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528173609294.png&#34; alt=&#34;image-20200528173609294&#34;&gt;&lt;/p&gt;
&lt;p&gt;连 SparkSQL 没这个问题。同样是TIMESTAMP类型，表现不同。&lt;/p&gt;
&lt;h3 id=&#34;初步分析&#34;&gt;初步分析&lt;/h3&gt;
&lt;p&gt;在数据库中查看存储的字段信息，Impala/SparkSQL对比看，发现 Impala 数据库下的字段 base_type 都是 &lt;code&gt;type/*&lt;/code&gt;。而 database_type，Impala 都是大写的，比如TIMESTAMP，而不是timestamp。所以，并不仅仅是TIMESTAMP类型没有过滤器样式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528173915594.png&#34; alt=&#34;image-20200528173915594&#34;&gt;&lt;/p&gt;
&lt;p&gt;Metabase 数据库类型会映射为 Clojure类型，数据库类型的名称是大小写敏感的。所以不能复用hive-like中的实现（都是小写的），而且Hive与Impala的类型还是有些不同的。&lt;/p&gt;
&lt;h3 id=&#34;hive-impala的数据类型异同&#34;&gt;Hive Impala的数据类型异同&lt;/h3&gt;
&lt;p&gt;以 Hive Data Types 为基准。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type Name&lt;/th&gt;
&lt;th&gt;Type Catgory&lt;/th&gt;
&lt;th&gt;Comment&lt;/th&gt;
&lt;th&gt;Impala Support?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TINYINT&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SMALLINT&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;INT&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BIGINT&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FLOAT&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DOUBLE&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DOUBLE PRECISION&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;alias for DOUBLE, only available starting with Hive 2.2.0&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DECIMAL&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;Introduced in Hive 0.11.0 with a precision of 38 digits&lt;!-- raw HTML omitted --&gt;Hive 0.13.0 introduced user-definable precision and scale&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NUMERIC&lt;/td&gt;
&lt;td&gt;Numeric Types&lt;/td&gt;
&lt;td&gt;same as DECIMAL, starting with Hive 3.0.0&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TIMESTAMP&lt;/td&gt;
&lt;td&gt;Date/Time Types&lt;/td&gt;
&lt;td&gt;available starting with Hive 0.8.0&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DATE&lt;/td&gt;
&lt;td&gt;Date/Time Types&lt;/td&gt;
&lt;td&gt;available starting with Hive 0.12.0&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;INTERVAL&lt;/td&gt;
&lt;td&gt;Date/Time Types&lt;/td&gt;
&lt;td&gt;available starting with Hive 1.2.0&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;STRING&lt;/td&gt;
&lt;td&gt;String Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VARCHAR&lt;/td&gt;
&lt;td&gt;String Types&lt;/td&gt;
&lt;td&gt;available starting with Hive 0.12.0&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CHAR&lt;/td&gt;
&lt;td&gt;String Types&lt;/td&gt;
&lt;td&gt;available starting with Hive 0.13.0&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BOOLEAN&lt;/td&gt;
&lt;td&gt;Misc Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;BINARY&lt;/td&gt;
&lt;td&gt;Misc Types&lt;/td&gt;
&lt;td&gt;available starting with Hive 0.8.0&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;arrays: ARRAY&amp;lt;data_type&amp;gt;&lt;/td&gt;
&lt;td&gt;Complex Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;maps: MAP&amp;lt;primitive_type, data_type&amp;gt;&lt;/td&gt;
&lt;td&gt;Complex Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;structs: STRUCT&amp;lt;col_name : data_type [COMMENT col_comment], &amp;hellip;&amp;gt;&lt;/td&gt;
&lt;td&gt;Complex Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;union: UNIONTYPE&amp;lt;data_type, data_type, &amp;hellip;&amp;gt;&lt;/td&gt;
&lt;td&gt;Complex Types&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hive Data Types &lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types&#34;&gt;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Impala Data Types &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_datatypes.html&#34;&gt;https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_datatypes.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SQL Differences Between Impala and Hive &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_langref_unsupported.html&#34;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_langref_unsupported.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;fix&#34;&gt;fix&lt;/h3&gt;
&lt;p&gt;根据与Hive数据类型对比，重写方法 &lt;code&gt;sql-jdbc.sync/database-type-&amp;gt;base-type&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-clojure&#34; data-lang=&#34;clojure&#34;&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmethod &lt;/span&gt;sql-jdbc.sync/database-type-&amp;gt;base-type &lt;span style=&#34;color:#e6db74&#34;&gt;:impala&lt;/span&gt;
  [_ database-type]
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;condp&lt;/span&gt; re-matches (name database-type)
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TINYINT&amp;#34;&lt;/span&gt;          &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Integer&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;SMALLINT&amp;#34;&lt;/span&gt;         &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Integer&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;INT&amp;#34;&lt;/span&gt;              &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Integer&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;BIGINT&amp;#34;&lt;/span&gt;           &lt;span style=&#34;color:#e6db74&#34;&gt;:type/BigInteger&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;FLOAT&amp;#34;&lt;/span&gt;            &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Float&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DOUBLE&amp;#34;&lt;/span&gt;           &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Float&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DECIMAL.*&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Decimal&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;TIMESTAMP&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;:type/DateTime&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;STRING.*&amp;#34;&lt;/span&gt;         &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Text&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;VARCHAR.*&amp;#34;&lt;/span&gt;        &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Text&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CHAR.*&amp;#34;&lt;/span&gt;           &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Text&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;BOOLEAN&amp;#34;&lt;/span&gt;          &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Boolean&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ARRAY.*&amp;#34;&lt;/span&gt;          &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Array&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;MAP.*&amp;#34;&lt;/span&gt;            &lt;span style=&#34;color:#e6db74&#34;&gt;:type/Dictionary&lt;/span&gt;
    &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.*&amp;#34;&lt;/span&gt;               &lt;span style=&#34;color:#e6db74&#34;&gt;:type/*&lt;/span&gt;))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/metabase/pull/2/commits/e156683989844eb2405e5240e888249a2defe78c&#34;&gt;https://github.com/XUJiahua/metabase/pull/2/commits/e156683989844eb2405e5240e888249a2defe78c&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528120341696.png&#34; alt=&#34;image-20200528120341696&#34;&gt;&lt;/p&gt;
&lt;p&gt;这样，TIMESTAMP 类型就有过滤器样式了。&lt;/p&gt;
&lt;h2 id=&#34;2-timestamp-xxx-报错信息&#34;&gt;2. timestamp xxx 报错信息&lt;/h2&gt;
&lt;h3 id=&#34;现象-1&#34;&gt;现象&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;ParseException: Syntax error in line 4:\nAND date_timestamp &amp;lt; timestamp &amp;lsquo;2019-01-03 00:00:00.000&amp;rsquo;\n ^\nEncountered: TIMESTAMP\nExpected: CASE, CAST, DEFAULT, EXISTS, FALSE, IF, INTERVAL, LEFT, NOT, NULL, REPLACE, RIGHT, TRUNCATE, TRUE, IDENTIFIER\n\nCAUSED BY: Exception: Syntax error\n&amp;rdquo;,&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;SQL过滤器测试用例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;select&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;from&lt;/span&gt; product.dwd_dim_date_with_timestamp
&lt;span style=&#34;color:#66d9ef&#34;&gt;where&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
[[&lt;span style=&#34;color:#66d9ef&#34;&gt;AND&lt;/span&gt; date_timestamp &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;{{&lt;/span&gt;date_timestamp&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;}}&lt;/span&gt; ]]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;洪敏眼尖，发现是 Impala 不支持这个语法。&lt;/p&gt;
&lt;h3 id=&#34;分析&#34;&gt;分析&lt;/h3&gt;
&lt;p&gt;hive-like 并没有重写处理 LocalDateTime 的方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528165940717.png&#34; alt=&#34;image-20200528165940717&#34;&gt;&lt;/p&gt;
&lt;p&gt;而 Impala TIMESTAMP是没有时区的，大概率会用这个方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In Impala, the TIMESTAMP data type holds a value of date and time. It can be decomposed into year, month, day, hour, minute and seconds fields, but with no time zone information available, it does not correspond to any specific point in time. &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_timestamp.html&#34;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_timestamp.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;默认实现是 timestamp 语法，报错信息就在这。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-clojure&#34; data-lang=&#34;clojure&#34;&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmethod &lt;/span&gt;unprepare-value [&lt;span style=&#34;color:#e6db74&#34;&gt;:sql&lt;/span&gt; LocalDateTime]
  [_ t]
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;format&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;timestamp &amp;#39;%s&amp;#39;&amp;#34;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;t/format&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yyyy-MM-dd HH:mm:ss.SSS&amp;#34;&lt;/span&gt; t)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;fix-1&#34;&gt;fix&lt;/h3&gt;
&lt;p&gt;找到 Impala 对应的 SQL 函数。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-clojure&#34; data-lang=&#34;clojure&#34;&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmethod &lt;/span&gt;unprepare/unprepare-value [&lt;span style=&#34;color:#e6db74&#34;&gt;:impala&lt;/span&gt; LocalDateTime]
  [_ t]
  (&lt;span style=&#34;color:#a6e22e&#34;&gt;format&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;to_timestamp(&amp;#39;%s&amp;#39;, &amp;#39;yyyy-MM-dd HH:mm:ss&amp;#39;)&amp;#34;&lt;/span&gt; (&lt;span style=&#34;color:#a6e22e&#34;&gt;t/format&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;yyyy-MM-dd HH:mm:ss&amp;#34;&lt;/span&gt; t)))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/metabase/pull/2/commits/005b878caf2fbbbd8c00a7ed016c899187f59d3c&#34;&gt;https://github.com/XUJiahua/metabase/pull/2/commits/005b878caf2fbbbd8c00a7ed016c899187f59d3c&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;3-date_format-unknown&#34;&gt;3. date_format() unknown&lt;/h2&gt;
&lt;h3 id=&#34;现象-2&#34;&gt;现象&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528210146896.png&#34; alt=&#34;image-20200528210146896&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;分析-1&#34;&gt;分析&lt;/h3&gt;
&lt;p&gt;大概率又是 Impala 不支持 date_format 这个函数。代码中搜索关键字。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528212547249.png&#34; alt=&#34;image-20200528212547249&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里简单说明下，&lt;code&gt;(hsql/call :date_format xx xx)&lt;/code&gt; 这个方法最终会生成 SQL语句 &lt;code&gt;date_format(xx, xx)&lt;/code&gt;。又一次，我们得找到 Impala 中的SQL函数来替代它。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hive/SparkSQL Built-in Functions &lt;a href=&#34;https://spark.apache.org/docs/2.4.5/api/sql/index.html#date_format&#34;&gt;https://spark.apache.org/docs/2.4.5/api/sql/index.html#date_format&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Impala Built-In Functions &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_functions.html&#34;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_functions.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Impala Date and Time Functions &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_datetime_functions.html&#34;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/impala_datetime_functions.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;fix-2&#34;&gt;fix&lt;/h3&gt;
&lt;p&gt;因为 &lt;code&gt;date-format&lt;/code&gt; 被应用中很多 &lt;code&gt;defmethod sql.qp/date&lt;/code&gt; 方法里，所以在 Impala 重新实现这些方法，尽可能用 Impala 内置的函数。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/metabase/pull/2/commits/01046a664dc8bc9d815184fd6ec419b7a4c1aa10&#34;&gt;https://github.com/XUJiahua/metabase/pull/2/commits/01046a664dc8bc9d815184fd6ec419b7a4c1aa10&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;这些问题主要还是 Impala 和 Hive 的 SQL 规范不一样。令人头秃。不过对 Metabase 越来越熟悉了。&lt;/p&gt;
&lt;h3 id=&#34;未完待续&#34;&gt;未完待续&lt;/h3&gt;
&lt;p&gt;这2个选项还在报错，应该是不支持对应的方法。还好暂时用不到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200528213420179.png&#34; alt=&#34;image-20200528213420179&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/20200528-metabase-impala-type/ - </description>
        </item>
    
    
    
        <item>
        <title>Metabase Impala Driver</title>
        <link>https://xujiahua.github.io/posts/20200527-metabase-impala-driver/</link>
        <pubDate>Wed, 27 May 2020 12:16:36 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200527-metabase-impala-driver/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200527-metabase-impala-driver/ -&lt;p&gt;Metabase 版本：v0.35.3&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;我们的数据仓库是 Hadoop/Hive 体系的。Hadoop 版本采用的是 CDH 发行版。在这个背景下 SQL on Hadoop 的方案有 Hive/Impala/(SparkSQL)。作为 BI 数据库，Impala 在我们的场景下比较合适。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hive：太慢了。做 ETL 可以，BI 非常不适。&lt;/li&gt;
&lt;li&gt;SparkSQL：CDH 官方 Spark 不含 Thrift Server。为了能够使用 Metabase ，独立于 CDH 启了个 Thrift Server，用着还不错。问题就在于缺乏统一管理，比如 Kerberos 的管理就得自己写脚本处理、进程 OOM 挂掉了 CDH Manager 也监测不到。&lt;/li&gt;
&lt;li&gt;Impala：CDH 官方出品，为 BI 而设计，由 CDH Manager 管理。根据这份报告，见下参考链接，Impala 好于 SparkSQL。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;出于尽可能复用已有基础设施的目的，选择 Impala。而 Metabase 官方、社区并不提供 Impala 驱动。本文就是为了探索并解决这个问题。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开源OLAP引擎测评报告(SparkSql、Presto、Impala、HAWQ、ClickHouse、GreenPlum) &lt;a href=&#34;http://www.clickhouse.com.cn/topic/5c453371389ad55f127768ea&#34;&gt;http://www.clickhouse.com.cn/topic/5c453371389ad55f127768ea&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;现有驱动探索&#34;&gt;现有驱动探索&lt;/h2&gt;
&lt;h3 id=&#34;搭建-impala-开发环境&#34;&gt;搭建 Impala 开发环境&lt;/h3&gt;
&lt;p&gt;使用 Cloudera Quickstart Docker 镜像（官方已经下架 quickstart vm ）。其中，Impala版本 2.5.0。（我们的生产环境：CDH 6.3.2 Impala 3.2.0 Hive 2.1.1）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run --name cloudera_quickstart --hostname&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;quickstart.cloudera &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--privileged&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true -t -i -d -p 8888:8888 -p 80:80 -p 10000:10000 -p 7180:7180 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-p 21050:21050 -p 50070:50070 -p 50075:50075 -p 50010:50010 -p 50020:50020 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;-p 8020:8020 cloudera/quickstart /usr/bin/docker-quickstart
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一些端口使用的说明：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Port&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;td&gt;Tutorial&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8888&lt;/td&gt;
&lt;td&gt;HUE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;21050&lt;/td&gt;
&lt;td&gt;Impala&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10000&lt;/td&gt;
&lt;td&gt;Hive&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;注意：关闭再启动容器，Impala进程并没有重启。重启 Impala 最直接的方法就是重建容器。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;quickstart docker image &lt;a href=&#34;https://hub.docker.com/r/cloudera/quickstart&#34;&gt;https://hub.docker.com/r/cloudera/quickstart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;15分钟——在Docker启动Cloudera并开始体验 &lt;a href=&#34;https://xieshaohu.wordpress.com/2019/02/26/15%E5%88%86%E9%92%9F-%E5%9C%A8docker%E5%90%AF%E5%8A%A8cloudera%E5%B9%B6%E5%BC%80%E5%A7%8B%E4%BD%93%E9%AA%8C/&#34;&gt;https://xieshaohu.wordpress.com/2019/02/26/15%E5%88%86%E9%92%9F-%E5%9C%A8docker%E5%90%AF%E5%8A%A8cloudera%E5%B9%B6%E5%BC%80%E5%A7%8B%E4%BD%93%E9%AA%8C/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;尝试-mwullinkmetabase&#34;&gt;尝试 mwullink/metabase&lt;/h3&gt;
&lt;p&gt;在 metabase issue 里看到一个关掉的关于Impala的PR，这方面的资料真的很少。如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Support Apache Impala database #3002 #3749 &lt;a href=&#34;https://github.com/metabase/metabase/pull/3749&#34;&gt;https://github.com/metabase/metabase/pull/3749&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Support Apache Impala database #3002 &lt;a href=&#34;https://github.com/metabase/metabase/issues/3002&#34;&gt;https://github.com/metabase/metabase/issues/3002&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可惜，并没有被合并到官方库。尝试编译作者mwullink的metabase版本。 &lt;a href=&#34;https://github.com/mwullink/metabase&#34;&gt;https://github.com/mwullink/metabase&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/mwullink/metabase.git metabase-mwullink
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个metabase版本太老了，前端依赖还是node 4.4.7（warning You are using Node &amp;ldquo;4.4.7&amp;rdquo; which is not supported and may encounter bugs or unexpected behavior. Yarn supports the following semver range: &amp;ldquo;^4.8.0 || ^5.7.0 || ^6.2.2 || &amp;gt;=8.0.0&amp;rdquo;），另外yarn对node4.x也有兼容问题（ &lt;a href=&#34;https://github.com/yarnpkg/yarn/issues/6900&#34;&gt;https://github.com/yarnpkg/yarn/issues/6900&lt;/a&gt; ）。&lt;/p&gt;
&lt;p&gt;特殊处理逻辑：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# nvm 安装 node 4.x 版本&lt;/span&gt;
nvm install lts/argon

&lt;span style=&#34;color:#75715e&#34;&gt;# 修改 node 版本&lt;/span&gt;
vim package.json
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;engines&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;node&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;4.9.1&amp;#34;&lt;/span&gt;,
    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;npm&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.15.11&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,
  
&lt;span style=&#34;color:#75715e&#34;&gt;# 安装老版本的yarn&lt;/span&gt;
npm --global install yarn@1.12.3

&lt;span style=&#34;color:#75715e&#34;&gt;# 这样就可以了&lt;/span&gt;
./bin/build
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# jar目录&lt;/span&gt;
cd ./target/uberjar

&lt;span style=&#34;color:#75715e&#34;&gt;# 将impala驱动放这里。下载和安装参考 https://github.com/metabase/metabase/pull/3749/files&lt;/span&gt;
mkdir plugins

&lt;span style=&#34;color:#75715e&#34;&gt;# 换个端口号，本地还有其他版本metabase运行&lt;/span&gt;
java -DMB_JETTY_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12345&lt;/span&gt; -jar metabase.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;效果：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可以直接写SQL查询，基于查询结果也能做 chart/dashboard。&lt;/li&gt;
&lt;li&gt;但是metadata（比如表结构）并没有同步。SQL查询的右边表结构也不会显示，filter功能受影响。&lt;/li&gt;
&lt;li&gt;metadata没有同步，也没有报错信息。（作为对比，连mysql是有metadata同步的。）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;使用官方-sparksql-驱动&#34;&gt;使用官方 sparksql 驱动&lt;/h3&gt;
&lt;p&gt;尝试使用 sparksql 驱动来连接 Impala 数据库。&lt;/p&gt;
&lt;p&gt;因为 SparkSQL 的 thrift server 复用的是 HiveServer2 的实现，架构如下图。而 Impala 可以使用 Hive 的JDBC Driver （ &lt;a href=&#34;https://impala.apache.org/docs/build/html/topics/impala_jdbc.html&#34;&gt;https://impala.apache.org/docs/build/html/topics/impala_jdbc.html&lt;/a&gt; &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_jdbc.html#jdbc_driver_choice&#34;&gt;https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_jdbc.html#jdbc_driver_choice&lt;/a&gt; ）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200520093534168.png&#34; alt=&#34;image-20200520093534168&#34;&gt;&lt;/p&gt;
&lt;p&gt;效果：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可以直接写SQL查询，基于查询结果也能做chart/dashboard。&lt;/li&gt;
&lt;li&gt;但是表结构并没有同步。SQL查询的右边表结构也不会显示，filter功能受影响。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同步有报错信息。终于有线索了&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;db-metadata-同步出错&#34;&gt;db-metadata 同步出错&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200525102147780.png&#34; alt=&#34;image-20200525102147780&#34;&gt;&lt;/p&gt;
&lt;p&gt;第10行的这个方法崩了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200525162346701.png&#34; alt=&#34;image-20200525162346701&#34;&gt;&lt;/p&gt;
&lt;p&gt;方法 &lt;code&gt;driver/describe-database&lt;/code&gt; 的作用是获取db的所有表。方法 &lt;code&gt;driver/describe-table&lt;/code&gt;的作用是获取table的字段信息 。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-clojure&#34; data-lang=&#34;clojure&#34;&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmulti &lt;/span&gt;describe-database
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Return a map containing information that describes all of the tables in a `database`, an instance of the `Database`
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  model. It is expected that this function will be peformant and avoid draining meaningful resources of the database.
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  Results should match the `metabase.sync.interface/DatabaseMetadata` schema.&amp;#34;&lt;/span&gt;
  {&lt;span style=&#34;color:#e6db74&#34;&gt;:arglists&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#39;&lt;/span&gt;([driver database])}
  dispatch-on-initialized-driver
  &lt;span style=&#34;color:#e6db74&#34;&gt;:hierarchy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hierarchy&lt;/span&gt;)

(&lt;span style=&#34;color:#66d9ef&#34;&gt;defmulti &lt;/span&gt;describe-table
  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Return a map containing information that describes the physical schema of `table` (i.e. the fields contained
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  therein). `database` will be an instance of the `Database` model; and `table`, an instance of the `Table` model. It is
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  expected that this function will be peformant and avoid draining meaningful resources of the database. Results
&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  should match the `metabase.sync.interface/TableMetadata` schema.&amp;#34;&lt;/span&gt;
  {&lt;span style=&#34;color:#e6db74&#34;&gt;:arglists&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#39;&lt;/span&gt;([driver database table])}
  dispatch-on-initialized-driver
  &lt;span style=&#34;color:#e6db74&#34;&gt;:hierarchy&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;#&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hierarchy&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这（两）个方法调用失败，Metabase 上自然就没有表结构信息了。&lt;/p&gt;
&lt;p&gt;sparksql驱动“重载”了这两个方法。初步怀疑与重载有关，sparksql 的父驱动 jdbc-sql 是有默认实现的，尝试注释掉重载。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200525163902594.png&#34; alt=&#34;image-20200525163902594&#34;&gt;&lt;/p&gt;
&lt;p&gt;神奇地发现，注释掉这两个方法，可以直接通过sparksql驱动连接impala服务器了。&lt;/p&gt;
&lt;p&gt;猜想，SparkSQL的Thrift Server和Impala  Server实现有差异，SparkSQL Thrift Server可能因为有设计缺陷，需要在驱动上打上补丁。&lt;/p&gt;
&lt;h2 id=&#34;自己写驱动&#34;&gt;自己写驱动&lt;/h2&gt;
&lt;p&gt;基于最新版 Metabase 0.35.3 开发。（尝试编译 master 分支，发现打包结果 &lt;code&gt;java -jar metabase.jar&lt;/code&gt; 报错。）&lt;/p&gt;
&lt;p&gt;自己写驱动，目前来看有两条路：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过分析 sparksql 驱动的报错信息，貌似找到了连接 Impala 数据库的方式。为了兼容现有的 sparksql 实现，在 sparksql 包中新增一个 impala 文件（复用hive-like父类实现，与sparksql 平行）。&lt;/li&gt;
&lt;li&gt;新增一个驱动包 impala。基于Impala官方的JDBC驱动实现。需要系统理解下 Metabase 驱动开发逻辑。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然，都需要对 Metabase 有一定熟悉程度，先看下文档。&lt;/p&gt;
&lt;h3 id=&#34;sparksql-包中新增一个-impala-driver&#34;&gt;sparksql 包中新增一个 impala driver&lt;/h3&gt;
&lt;p&gt;按照上述思路，代码提交在这里。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql/modules/drivers/sparksql&#34;&gt;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql/modules/drivers/sparksql&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本地测试。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200526165539889.png&#34; alt=&#34;image-20200526165539889&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200526165644979.png&#34; alt=&#34;image-20200526165644979&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200526165735569.png&#34; alt=&#34;image-20200526165735569&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;sparksql-包的依赖问题-存量bug&#34;&gt;sparksql 包的依赖问题 （存量bug）&lt;/h4&gt;
&lt;p&gt;如果服务端启用了 Kerberos 认证，会有这个问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200527105225274.png&#34; alt=&#34;image-20200527105225274&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;05-27 10:39:39 ERROR driver.util :: Database connection error
java.lang.IllegalArgumentException: Unrecognized Hadoop major version number: 3.1.1
	at org.apache.hadoop.hive.shims.ShimLoader.getMajorVersion(ShimLoader.java:174)
	at org.apache.hadoop.hive.shims.ShimLoader.loadShims(ShimLoader.java:139)
	at org.apache.hadoop.hive.shims.ShimLoader.getHadoopThriftAuthBridge(ShimLoader.java:125)
	at org.apache.hive.service.auth.KerberosSaslHelper.getKerberosTransport(KerberosSaslHelper.java:54)
	at org.apache.hive.jdbc.HiveConnection.createBinaryTransport(HiveConnection.java:445)
	at org.apache.hive.jdbc.HiveConnection.openTransport(HiveConnection.java:201)
	at org.apache.hive.jdbc.HiveConnection.&amp;lt;init&amp;gt;(HiveConnection.java:176)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;sparksql jar 包依赖：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 作为 hadoop 基础包，含 Kerberos 认证逻辑代码
org.apache.hadoop/hadoop-common &amp;quot;3.1.1&amp;quot;

# 1.x 系列最后一个版本
org.apache.hive/hive-jdbc &amp;quot;1.2.1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据报错信息找到了Hive的源代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200527110418542.png&#34; alt=&#34;image-20200527110418542&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/apache/hive/blob/release-1.2.1/shims/common/src/main/java/org/apache/hadoop/hive/shims/ShimLoader.java#L159&#34;&gt;https://github.com/apache/hive/blob/release-1.2.1/shims/common/src/main/java/org/apache/hadoop/hive/shims/ShimLoader.java#L159&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;所以 org.apache.hive/hive-jdbc &amp;ldquo;1.2.1&amp;rdquo; 压根就不兼容 org.apache.hadoop/hadoop-common &amp;ldquo;3.x&amp;rdquo; 版本的。人写代码的时候没测到这个case。&lt;/p&gt;
&lt;p&gt;解决方式，引用hadoop-common 2.x最后一个版本：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;org.apache.hadoop/hadoop-common &amp;quot;2.10.0&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;重新编译打包后效果OK。&lt;/p&gt;
&lt;h4 id=&#34;uberjar-的弊端&#34;&gt;uberjar 的弊端&lt;/h4&gt;
&lt;p&gt;Metabase为了方便包的分发，整个项目、驱动都是uberjar的打包思路。弊端其实也挺明显。JDBC 驱动与数据库的兼容性问题，一般是适配数据库，JDBC 驱动被 uberjar 后，想换驱动就得重新编译源码。&lt;/p&gt;
&lt;p&gt;比如 Hive Server 1.1.0，Hive JDBC 1.2.1 就连不上。开源产品的兼容性问题让人头秃。&lt;/p&gt;
&lt;p&gt;TODO：驱动不再uberjar，可以使用自己需要的依赖版本，比如我们使用 CDH 6.x 的 hadoop/hive jar包。&lt;/p&gt;
&lt;h4 id=&#34;题外话-sparksql-deps&#34;&gt;题外话 sparksql-deps&lt;/h4&gt;
&lt;p&gt;网上有个老版本的sparksql 驱动包 &lt;a href=&#34;https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar&#34;&gt;https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar&lt;/a&gt; 。之前解决这个问题，就是将其放到plugins目录。究其原因，其引用的hadoop-common版本是2.x的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200527111551416.png&#34; alt=&#34;image-20200527111551416&#34;&gt;&lt;/p&gt;
&lt;p&gt;而其源码包括历史记录（ &lt;a href=&#34;https://github.com/metabase/sparksql-deps&#34;&gt;https://github.com/metabase/sparksql-deps&lt;/a&gt; ）的hadoop-common版本是3.1.0。不要被误导了。&lt;/p&gt;
&lt;h3 id=&#34;todo-新增-impala-包&#34;&gt;TODO 新增 impala 包&lt;/h3&gt;
&lt;p&gt;需要系统了解下驱动是怎么写的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有整体思路，教程有点缺失 &lt;a href=&#34;https://github.com/metabase/metabase/wiki/Writing-a-Driver&#34;&gt;https://github.com/metabase/metabase/wiki/Writing-a-Driver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;引用本地jar包（Impala jar包是本地） &lt;a href=&#34;https://github.com/kumarshantanu/lein-localrepo&#34;&gt;https://github.com/kumarshantanu/lein-localrepo&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;impala-jdbc-driver&#34;&gt;Impala JDBC Driver&lt;/h4&gt;
&lt;p&gt;我们可以使用JDBC 4.2版本的。其兼容性也挺高的。本地Impala 2.5.0，生产Impala 3.2.0都覆盖了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200524093032785.png&#34; alt=&#34;image-20200524093032785&#34;&gt;&lt;/p&gt;
&lt;p&gt;（Impala JDBC Driver压缩包内的文档）&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;通过摸索，改进 Metabase sparksql 包后，我们可以使用 Impala 了。至于有多少坑，还得等我深度使用后才知道。&lt;/p&gt;
&lt;p&gt;代码 &lt;a href=&#34;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql&#34;&gt;https://github.com/XUJiahua/metabase/tree/driver-impala-in-sparksql&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;因为时间关系，留下一些 TODO ，未完待续。&lt;/p&gt;
&lt;h2 id=&#34;heading&#34;&gt;&lt;/h2&gt;
- https://xujiahua.github.io/posts/20200527-metabase-impala-driver/ - </description>
        </item>
    
    
    
        <item>
        <title>微信用户授权头像内容带随机干扰的问题</title>
        <link>https://xujiahua.github.io/posts/20200514-wx-avatar/</link>
        <pubDate>Thu, 14 May 2020 13:38:12 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200514-wx-avatar/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200514-wx-avatar/ -&lt;p&gt;项目需要基于头像、昵称对不同实体账号下的微信用户进行匹配。基于这个思路，打算先下载微信头像的图像，后计算其MD5，“单元测试”了下这个简单方法，结果惊人。&lt;/p&gt;
&lt;p&gt;同一个人的同一个头像链接返回的图像内容都不一样。内容不一样，MD5值也就不一样。&lt;/p&gt;
&lt;p&gt;看来微信对我们这些拙劣的手段早有防备。&lt;/p&gt;
&lt;h2 id=&#34;微信头像内容分析&#34;&gt;微信头像内容分析&lt;/h2&gt;
&lt;p&gt;同一个头像链接下载两次。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ wget -O 1.png https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoc614h6RfCUnwQTblG9y2dq4g5PKVicVZd5CQO9JNdPCWCovl8cmsvxQcWDemcLYGW6pSt97uUW5A/132
$ wget -O 2.png https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoc614h6RfCUnwQTblG9y2dq4g5PKVicVZd5CQO9JNdPCWCovl8cmsvxQcWDemcLYGW6pSt97uUW5A/132

$ md5 1.png
MD5 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;1.png&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dd6aa938cbec381a3e83702776be88a3
$ md5 2.png
MD5 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;2.png&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; 83668a6ad7eeee8fa8e5e0db339233d1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;肉眼比较&#34;&gt;肉眼比较&lt;/h3&gt;
&lt;p&gt;肉眼完全无法区分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514134445598.png&#34; alt=&#34;image-20200514134445598&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;字节级比较&#34;&gt;字节级比较&lt;/h3&gt;
&lt;p&gt;两张图，可以看出差异很大。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514134712953.png&#34; alt=&#34;image-20200514134712953&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;像素级比较&#34;&gt;像素级比较&lt;/h3&gt;
&lt;p&gt;为了方便对比，图先灰度化（一个像素点的RGB三值改为1个值）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200514184021629.png&#34; alt=&#34;image-20200514184021629&#34;&gt;&lt;/p&gt;
&lt;p&gt;两张灰度图差值的数据分布。x轴为差值，y轴为出现次数。&lt;/p&gt;
&lt;p&gt;0代表相同位置的像素点相同，非0代表相同位置像素点有差异及其差异幅度。&lt;/p&gt;
&lt;p&gt;0出现次数最多，可见两张图的大部分像素点的值是相同的。差异主要分为两部分，1-10 闭区间。（试了几张图）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200515094333720.png&#34; alt=&#34;image-20200515094333720&#34;&gt;&lt;/p&gt;
&lt;p&gt;另一种可视化，白色代表两图相同位置像素点不同。可见，图片污染非常严重。&lt;/p&gt;
&lt;p&gt;上图生成脚本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_to_2d_array&lt;/span&gt;(filename):
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(filename)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(img)

data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.png&amp;#34;&lt;/span&gt;)
data2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.png&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;# NOTE: np.uint8(3) - np.uint8(4) = 255 引起的误差让我绝望了&lt;/span&gt;
diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data1) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data2)))

&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
x, y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique(diff, return_counts&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{e}&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; e &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; x]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(x)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(y)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bar(x, y)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()

&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;count of non-zero point&amp;#34;&lt;/span&gt;, (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum())

diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(diff, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;diff12.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;目标消除白点&#34;&gt;目标：消除白点&lt;/h2&gt;
&lt;p&gt;要达到多份干扰图生成相同的哈希值的效果，就是要消除白点，也就是降采样图像，主要两个方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;降低灰度级别。比如 8bit（256级灰度）图像压缩到6bit（64级灰度）图像，原像素点0、1、2、3归为一个像素点0，以此类推。&lt;/li&gt;
&lt;li&gt;降低图像尺寸。比如尺寸同比缩小一倍。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在有限数据量下测试，32级灰度，10x10 尺寸下，白点消失了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;read_to_2d_array&lt;/span&gt;(filename, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;None, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;):
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(filename)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; None:
        img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize(size)
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(img)
    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; bit &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;:
        data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;bit)) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;bit))
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; data

size_options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;),
    (&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;)
]

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; bit &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; size &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; size_options:
        data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.png&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;size, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bit)
        data2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; read_to_2d_array(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2.png&amp;#34;&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;size, bit&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bit)
        diff &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data1) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int16(data2)))
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
            Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(data1)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{bit}_{size}_1.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
            Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(data2)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(f&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{bit}_{size}_2.png&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;PNG&amp;#34;&lt;/span&gt;)
        ratio &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (diff &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;diff&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
        &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bit: {0}, size: {1}, 脏点率：{2}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;format(bit, size, ratio))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;相似图片搜索的原理 &lt;a href=&#34;http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html&#34;&gt;http://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;微信为了保护用户隐私，防止通过头像昵称进行用户匹配，对每次通过头像链接获取的头像内容加入了随机的扰动，像素点扰动幅度范围在 [-10, 10]，大概15%的像素点（两份干扰图的差异）受干扰，图像的差异肉眼难以察觉。&lt;/p&gt;
&lt;p&gt;最终图像哈希用于 SQL JOIN，需要将有些许差异的图像映射成一个值。不考虑相似度算法。&lt;/p&gt;
&lt;p&gt;通过在图像色彩、尺寸上降维，初步解决了这个问题。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200514-wx-avatar/ - </description>
        </item>
    
    
    
        <item>
        <title>NUC8i5BEH Hackintosh</title>
        <link>https://xujiahua.github.io/posts/20200504-hackintosh/</link>
        <pubDate>Mon, 04 May 2020 13:11:09 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200504-hackintosh/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200504-hackintosh/ -&lt;p&gt;买了个 NUC8i5BEH 当玩具，不怎么折腾的方式体验下黑苹果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504145011481.png&#34; alt=&#34;image-20200504145011481&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;效果&#34;&gt;效果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504132303349.png&#34; alt=&#34;image-20200504132303349&#34;&gt;&lt;/p&gt;
&lt;p&gt;与我的 2018 MBP 13.3 做对比。处理器、显卡是一样的。用很少的钱提升内存，16GB 2133 DDR3 -&amp;gt; 32GB 2400 DDR4。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200504132417310.png&#34; alt=&#34;image-20200504132417310&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;成本&#34;&gt;成本&lt;/h3&gt;
&lt;p&gt;大概 ￥4000。2018年买的MacBook近￥15000。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NUC8i5BEH ￥2379&lt;/li&gt;
&lt;li&gt;DDR4 2400 16 GB X 2 笔记本内存条 ￥978&lt;/li&gt;
&lt;li&gt;500GB M.2 SSD 大约￥600（不在这次消费计划里，从现有机器抠出来的）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;不足&#34;&gt;不足&lt;/h3&gt;
&lt;p&gt;WiFi、蓝牙，以及之上的AirDrop等功能缺失。&lt;/p&gt;
&lt;p&gt;网上有解决方案，主要是网卡使用Macbook的配件替代。感觉配件也不便宜，应该是炒热了。用网线，不折腾了。&lt;/p&gt;
&lt;h2 id=&#34;why-nuc8i5beh&#34;&gt;WHY NUC8i5BEH&lt;/h2&gt;
&lt;p&gt;豆子峡谷 NUC8i5BEH 机箱真的小！性能也不差。可以说，是最具性价比的了。&lt;/p&gt;
&lt;p&gt;能做这么小，机箱与电源分离的设计功不可没。- -!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/v2-80ec6cb9eb82fa2c5e0e16cbda516f41_720w.jpg&#34; alt=&#34;v2-80ec6cb9eb82fa2c5e0e16cbda516f41_720w&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i5bek&#34;&gt;NUC8i5BEH vs NUC8i5BEK&lt;/h3&gt;
&lt;p&gt;BEH 胖版，BEK 瘦版。瘦版差一个 2.5 寸盘位。硬盘只有一个M.2插槽。网卡魔改的方案使用M.2插槽，这样BEK就不能放硬盘了。BEH 虽然胖一点，还是很mini。&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i7beh&#34;&gt;NUC8i5BEH vs NUC8i7BEH&lt;/h3&gt;
&lt;p&gt;区别在CPU。差大约￥700。&lt;/p&gt;
&lt;h3 id=&#34;nuc8i5beh-vs-nuc8i7hvk&#34;&gt;NUC8i5BEH vs NUC8i7HVK&lt;/h3&gt;
&lt;p&gt;冥王峡谷 NUC8i7HVK 拥有 AMD 显卡。不玩电脑游戏，AMD卡又不方便做深度学习，另外小机身大功耗散热问题一定存在，就不考虑了。价格￥6000 起。那就非常没有必要了。&lt;/p&gt;
&lt;h2 id=&#34;安装教程&#34;&gt;安装教程&lt;/h2&gt;
&lt;h3 id=&#34;硬件安装&#34;&gt;硬件安装&lt;/h3&gt;
&lt;p&gt;插内存条和硬盘，看说明书就行。&lt;/p&gt;
&lt;h3 id=&#34;macos-安装&#34;&gt;MacOS 安装&lt;/h3&gt;
&lt;p&gt;MacOS是认硬件的，所以直接按照Apple官方制作MacOS启动盘的方式肯定不行。目前主要是用 Clover/OpenCore 等 BootLoader 骗过系统。安装过程中有两个阶段：U盘启动，硬盘启动，为了能够顺利进入系统，都要对它们的EFI分区进行修改。&lt;/p&gt;
&lt;p&gt;根据这个图文教程（NUC8i5BEH 黑果安装教程 &lt;a href=&#34;https://www.jianshu.com/p/ebd6054d4799&#34;&gt;https://www.jianshu.com/p/ebd6054d4799&lt;/a&gt; ），完成了 Mojave 的安装。图文教程对新人来说比较友好，对细节也有详细描述。（因为使用高手们封装好的镜像，U盘 EFI 分区在这个教程里就忽略了。）&lt;/p&gt;
&lt;p&gt;这个教程大差不差，但也是费了很长时间。&lt;/p&gt;
&lt;h4 id=&#34;意外情况&#34;&gt;意外情况&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;主要问题，引导很慢，一直是白苹果进度条的画面。睡了一觉起来还是这个状态，真的很气啊。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重启重试多几次。慢慢发现，要是2~3分钟进度条没走完，大概率是卡住了。多重启几次，总会有转机的。不明白到底发生了什么，所以这步操作运气成分很大。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;引导过程中遇到白苹果变成了禁止标志。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重启重试即可。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Mojave的镜像文件，内置的证书过期了。报错信息应用程序副本已损坏。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://blog.csdn.net/qq_41855420/article/details/102762647&#34;&gt;https://blog.csdn.net/qq_41855420/article/details/102762647&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;另外注意，MacOS 选择文件系统 APFS（教程中用的默认选项），适合SSD。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;bios-配置&#34;&gt;BIOS 配置&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;仅作记录&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boot -&amp;gt; Boot Configuration, disable &amp;ldquo;&lt;strong&gt;Network Boot&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Power -&amp;gt; Secondary Power Settings, &amp;ldquo;&lt;strong&gt;Wake on LAN from S4/S5&lt;/strong&gt;&amp;quot;, set to &amp;ldquo;&lt;strong&gt;Stay Off&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Boot -&amp;gt; Secure Boot, disable &amp;ldquo;&lt;strong&gt;Secure Boot&lt;/strong&gt;&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Devices -&amp;gt; OnBoard Devices, disable &amp;ldquo;&lt;strong&gt;Bluetooth&lt;/strong&gt;&amp;rdquo; (macOS is not compatible well with Intel Wi-Fi/Bluetooth)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suggested:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Boot -&amp;gt; Boot Priority -&amp;gt; Legacy Boot Priority, enable &amp;ldquo;&lt;strong&gt;Legacy Boot&lt;/strong&gt;&amp;quot;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&#34;&gt;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;apple-id--icloud--app-store&#34;&gt;Apple ID / iCloud / App Store&lt;/h4&gt;
&lt;p&gt;不考虑 iMessage / FaceTime，没使用场景。&lt;/p&gt;
&lt;p&gt;按照网上说法，只要生成随机三码（工具按照规则生成），使用 iCloud / App Store 没什么问题。&lt;/p&gt;
&lt;p&gt;怎么生成随机三码，参考：NUC8（豆子峡谷）在线安装macOS，这才是OpenCore正确的打开方式 &lt;a href=&#34;https://www.jianshu.com/p/78510cfa4a64&#34;&gt;https://www.jianshu.com/p/78510cfa4a64&lt;/a&gt; （最后一节）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200513100122246.png&#34; alt=&#34;image-20200513100122246&#34;&gt;&lt;/p&gt;
&lt;p&gt;关于什么是三码、AppleID的安全性，参考：NUC8（豆子峡谷）黑苹果新手指南Q&amp;amp;A &lt;a href=&#34;https://www.jianshu.com/p/b298da6afef3&#34;&gt;https://www.jianshu.com/p/b298da6afef3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200513100850310.png&#34; alt=&#34;image-20200513100850310&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;其他教程&#34;&gt;其他教程&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;[GUIDE] Building a Mac mini beast with NUC8i7BEH &lt;a href=&#34;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&#34;&gt;https://github.com/sarkrui/NUC8i7BEH-Hackintosh-Build&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;包含如何处理WiFi、蓝牙模块。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;NUC8I5BEH Hackintosh &lt;a href=&#34;https://github.com/csrutil/NUC8I5BEH&#34;&gt;https://github.com/csrutil/NUC8I5BEH&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;配置文件可以直接使用。不算是教程。描述得比较简略。不懂的还是不懂。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200504-hackintosh/ - </description>
        </item>
    
    
    
        <item>
        <title>consul 小结</title>
        <link>https://xujiahua.github.io/posts/20200421-use-consul/</link>
        <pubDate>Tue, 21 Apr 2020 09:01:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200421-use-consul/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200421-use-consul/ -&lt;h2 id=&#34;简单介绍&#34;&gt;简单介绍&lt;/h2&gt;
&lt;p&gt;hashicorp 对 Consul 的定位是服务间网络方案。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Consul is a service networking solution to connect and secure services across any runtime platform and public or private cloud. &lt;a href=&#34;https://www.consul.io/&#34;&gt;https://www.consul.io/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;官方的两个 use case 就是 service discovery, service mesh。&lt;/p&gt;
&lt;h3 id=&#34;service-discovery&#34;&gt;service discovery&lt;/h3&gt;
&lt;p&gt;与 etcd 比起来，Consul 的服务发现是开箱即用的。优点如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First class 的服务注册和获取接口。不需要像 etcd 那样在 kv 存储基础上做包装。&lt;/li&gt;
&lt;li&gt;服务注册，可以是consul 命令，也可以是HTTP API。&lt;/li&gt;
&lt;li&gt;获取服务注册表，除了 HTTP 接口，还可以使用  DNS 查询接口。&lt;/li&gt;
&lt;li&gt;健康检查。服务注册的时候可以提供健康检查项。健康检查机制保证了拿到的服务注册表是“健康”的。健康检查也包括节点的检查。单纯利用 consul 健康检查这个功能，consul 就是一个分布式监控工具。&lt;/li&gt;
&lt;li&gt;Web 管理界面。节点、服务、健康与否一目了然。&lt;/li&gt;
&lt;li&gt;Watch 功能。通过 blocking queries/ long-polling HTTP API 的方式得到服务注册表的改变的通知。&lt;/li&gt;
&lt;li&gt;跨数据中心（取资源）。When a request is made for a resource in another datacenter, the local Consul servers forward an RPC request to the remote Consul servers for that resource and return the results. &lt;a href=&#34;https://learn.hashicorp.com/consul/security-networking/datacenters#data-replication&#34;&gt;https://learn.hashicorp.com/consul/security-networking/datacenters#data-replication&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;service-mesh&#34;&gt;service mesh&lt;/h3&gt;
&lt;p&gt;service discovery 只是微服务治理的初级阶段。作为服务请求方，通过 consul/ etcd 获取到服务注册表，下一步就是选择其中一个服务实例，发送请求。这个步骤叫做负载均衡。可以想象，客户端的代码会越来越重了。&lt;/p&gt;
&lt;p&gt;service mesh可以理解为 service discovery的升级版。为每个服务实例引入 sidecar proxy，接管服务实例的入、出流量。将 service discovery，load balancer 从 service 本身抽离出来，下沉到基础设施，也就是 sidecar proxy。&lt;/p&gt;
&lt;p&gt;sidecar proxy 上的功能还有更多扩展，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;蓝绿部署，A/B 测试。打个比方，一个服务存在两个版本v1, v2，给v1分配80%的流量，给v2分配20%的流量。&lt;/li&gt;
&lt;li&gt;流量加密。authentication and authorization。&lt;/li&gt;
&lt;li&gt;服务指标的收集。比如HTTP协议的返回状态码。&lt;/li&gt;
&lt;li&gt;调用链追踪。&lt;/li&gt;
&lt;li&gt;Intention。可以设置服务与服务之间是否允许连接。Intentions define service based access control for services in the Consul service mesh and are used to control which services are allowed or not allowed to establish connections.&lt;/li&gt;
&lt;li&gt;这一切服务本身是无感知的。这也简化了应用的开发。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这就是 Consul Connect 的功能。与之对应的竞品是 Istio。&lt;/p&gt;
&lt;p&gt;当然，一切都有代价。&lt;strong&gt;给每个服务实例创建一个sidecar proxy，这在部署上需要做好准备。使用 Kubernetes 可以提高效率，会帮助自动创建 sidecar proxy。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;key-value-store&#34;&gt;key value store&lt;/h3&gt;
&lt;p&gt;consul 也能当 kv store 使用，这是服务发现的底子。使用方式跟 etcd 差不多。&lt;/p&gt;
&lt;p&gt;etcd 官方与 consul 做了比较。consul 在存储扩展性上不够好。也缺少KEY多版本存储，不方便追溯历史。key value store 这个场景，etcd 是更合适的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/coreos/dbtester/tree/master/test-results/2018Q1-02-etcd-zookeeper-consul&#34;&gt;As it stands in Consul 1.0&lt;/a&gt;, the storage system does not scale as well as other systems like etcd or Zookeeper in key-value operations; systems requiring millions of keys will suffer from high latencies and memory pressure. The key value API is missing, most notably, multi-version keys, conditional transactions, and reliable streaming watches.&lt;/p&gt;
&lt;p&gt;etcd and Consul solve different problems. If looking for a distributed consistent key value store, etcd is a better choice over Consul. If looking for end-to-end cluster service discovery, etcd will not have enough features; choose Kubernetes, Consul, or SmartStack.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;consul client agent的主要工作是健康检查，所以如果只是key value store的使用场景，可以直接与 consul server agent 交互，就像使用 etcd 那样。&lt;/p&gt;
&lt;h3 id=&#34;distributed-system-coordinate&#34;&gt;distributed system coordinate&lt;/h3&gt;
&lt;p&gt;分布式锁，分布式系统的协调 &lt;a href=&#34;https://www.consul.io/docs/internals/sessions.html&#34;&gt;https://www.consul.io/docs/internals/sessions.html&lt;/a&gt; 。使用场景比如Hadoop系统的选主。不过大部分开源分布式系统基本上使用zookeeper和etcd。&lt;/p&gt;
&lt;h2 id=&#34;核心概念&#34;&gt;核心概念&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-arch-420ce04a.png&#34; alt=&#34;Consul Architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;Consul 架构图&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node&lt;/td&gt;
&lt;td&gt;每个 node 安装并运行 consul agent。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consul server agent&lt;/td&gt;
&lt;td&gt;1）维护核心状态并基于共识算法 consensus protocol raft 参与leader选举。2）server节点一般建议3个或是5个。写压力大的集群，考虑升级服务器实例的配置和低延迟的存储。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;consul client agent&lt;/td&gt;
&lt;td&gt;1）当前节点、当前节点上的服务的健康检查。2）RPC请求转发到 consul server agent。3）每个主机都有一个agent的好处是，只要与本地agent通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Datacenter&lt;/td&gt;
&lt;td&gt;可以理解为一个 consul 集群。一个consul 集群至少有一个 consul server agent。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;LAN gossip pool&lt;/td&gt;
&lt;td&gt;单个 Datacenter 内，由 consul server agent 和 consul client agent 组成。pool内成员通过 gossip protocol 通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;WAN gossip pool&lt;/td&gt;
&lt;td&gt;跨 Datacenter，由所有 Datacenter 内的 consul server agent 组成。可以跨网络通信。pool内成员通过 gossip protocol 通信。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service&lt;/td&gt;
&lt;td&gt;一个service对应多个service实例，注册时使用相同的service_name，并使用不同的service_id区分实例。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.consul.io/docs/internals/architecture.html&#34;&gt;https://www.consul.io/docs/internals/architecture.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.consul.io/docs/glossary.html&#34;&gt;https://www.consul.io/docs/glossary.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;consul-connect-体验&#34;&gt;Consul Connect 体验&lt;/h2&gt;
&lt;h3 id=&#34;1-quickstart-consul-connect&#34;&gt;1. Quickstart: Consul Connect&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul_connect_demo_service_flow.png&#34; alt=&#34;Flow diagram showing end user traffic being sent to the Dashboard Service at port 9002. The dashboard service makes requests for the counting service to the local Connect Proxy at port 5000. This traffic then traverses the Connect mesh over dynamic ports. The traffic exits the Connect mesh from the counting service&amp;rsquo;s local proxy. The proxy sends this traffic to the counting service itself at port 9003.&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Secure Service-to-Service Communication &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-services&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code &lt;a href=&#34;https://github.com/hashicorp/demo-consul-101&#34;&gt;https://github.com/hashicorp/demo-consul-101&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;简单说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;consul agent -dev -config-dir=&amp;quot;./demo-config-localhost&amp;quot; -node=laptop&lt;/code&gt; 这里已经完成了service和proxy的注册。这个可以后续脚本化，按需服务注册。&lt;/li&gt;
&lt;li&gt;service本身都不做服务发现和负载均衡。这些事情交给了 sidecar proxy。以dashboard service为例，&lt;code&gt;countingServiceURL = getEnvOrDefault(&amp;quot;COUNTING_SERVICE_URL&amp;quot;, &amp;quot;http://localhost:9001&amp;quot;)&lt;/code&gt;，默认读的是本地的9001端口，也就是sidecar proxy的绑定端口。这就是劫持流量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consul connect proxy -sidecar-for counting-1&lt;/code&gt; 需要手动为service创建proxy。这个可以后续脚本化。&lt;/li&gt;
&lt;li&gt;能看出Consul Connect /Service Mesh的好处了：不再侵入业务代码。重复的事情已下沉到基础设施，sidecar proxy处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;2-use-envoy&#34;&gt;2. use Envoy&lt;/h3&gt;
&lt;p&gt;Use Envoy with Connect &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-envoy&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-envoy&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-canary-deployments-using-traffic-splitting-and-resolution&#34;&gt;3. Canary deployments using traffic splitting and resolution&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-splitting-architecture.png&#34; alt=&#34;Architecture diagram of the splitting demo. A web service directly connects to two different versions of the API service through proxies. Consul configures those proxies.&#34;&gt;&lt;/p&gt;
&lt;p&gt;Traffic Splitting for Service Deployments &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/consul-splitting&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/consul-splitting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code &lt;a href=&#34;https://github.com/hashicorp/consul-demo-traffic-splitting&#34;&gt;https://github.com/hashicorp/consul-demo-traffic-splitting&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;4-zipkin-tracing&#34;&gt;4. Zipkin tracing&lt;/h3&gt;
&lt;p&gt;code &lt;a href=&#34;https://github.com/hashicorp/consul-demo-tracing/tree/master/jaeger&#34;&gt;https://github.com/hashicorp/consul-demo-tracing/tree/master/jaeger&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;基于-consul-微服务改造&#34;&gt;基于 Consul 微服务改造&lt;/h2&gt;
&lt;p&gt;暂不用 Kubernetes 和 Docker。&lt;/p&gt;
&lt;p&gt;目前基本上是这种架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200421163153922.png&#34; alt=&#34;image-20200421163153922&#34;&gt;&lt;/p&gt;
&lt;p&gt;预期架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200421164508506.png&#34; alt=&#34;image-20200421164508506&#34;&gt;&lt;/p&gt;
&lt;p&gt;预期好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减少硬编码。&lt;/li&gt;
&lt;li&gt;可动态新增服务实例。&lt;/li&gt;
&lt;li&gt;基于sidecar做更多服务治理工作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;服务间通信&#34;&gt;服务间通信&lt;/h3&gt;
&lt;p&gt;目的：应用对 consul 无感知，降低应用开发的复杂度。&lt;/p&gt;
&lt;p&gt;需要做如下准备：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;独立服务器安装 consul server agent 集群。负责维护集群状态。&lt;/li&gt;
&lt;li&gt;每台应用服务器都有 consul client agent 运行，并已经连入 consul server agent。负责健康检查，与请求转发。&lt;/li&gt;
&lt;li&gt;每台应用服务器上安装有 envoy 二进制文件。负责sidecar proxy的创建。&lt;/li&gt;
&lt;li&gt;服务注册、注销的工作交给应用的伙伴脚本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;伙伴脚本的工作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;启动应用。&lt;/li&gt;
&lt;li&gt;服务注册和健康检查。所需的信息，比如IP可以通过命令取、端口可以从应用启动信息取、服务名是固定的。&lt;/li&gt;
&lt;li&gt;启动 sidecar proxy 进程。&lt;/li&gt;
&lt;li&gt;伙伴脚本还需要监测应用的状态，应用不存在后，发起服务注销。&lt;/li&gt;
&lt;li&gt;consul的健康检查机制会自动把不健康的服务过滤掉，对伙伴脚本的要求没那么高了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;对外服务&#34;&gt;对外服务&lt;/h3&gt;
&lt;p&gt;目的：动态更新 nginx upstream。&lt;/p&gt;
&lt;p&gt;目前，我们使用nginx作为对外服务。使用 consul-template，动态生成 nginx 配置（upstreams）并 reload nginx。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/consul-nginx-template-arch.png&#34; alt=&#34;NGINX and Consul template architecture&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;参考-1&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Load Balancing with NGINX and Consul Template &lt;a href=&#34;https://learn.hashicorp.com/consul/integrations/nginx-consul-template&#34;&gt;https://learn.hashicorp.com/consul/integrations/nginx-consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;consul-template &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-configuration/consul-template&#34;&gt;https://learn.hashicorp.com/consul/developer-configuration/consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Manage local application configuration files using templates and data from etcd or consul 与consul-template的思路是一样的 &lt;a href=&#34;https://github.com/kelseyhightower/confd&#34;&gt;https://github.com/kelseyhightower/conf&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;基于-consul-的配置中心&#34;&gt;基于 Consul 的配置中心&lt;/h2&gt;
&lt;p&gt;目前，应用读本地配置文件。&lt;/p&gt;
&lt;p&gt;目标，从 consul 读配置文件，并监听配置变化。&lt;/p&gt;
&lt;p&gt;基于 Viper 库和 consul 做了一个demo。 &lt;a href=&#34;https://github.com/XUJiahua/consul_config_demo&#34;&gt;https://github.com/XUJiahua/consul_config_demo&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;viper&#34;&gt;viper&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其中 Viper 的 remote config 支持的不够好：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;OnConfigChange 对 remote config 无效。&lt;/li&gt;
&lt;li&gt;WatchRemoteConfig()与ReadRemoteConfig() 完全没区别。&lt;/li&gt;
&lt;li&gt;WatchRemoteConfigOnChannel() 是真正有watch功能的方法，但是没有通知应用代码。默默就更新配置了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以基于 PR &lt;a href=&#34;https://github.com/spf13/viper/pull/456/files&#34;&gt;https://github.com/spf13/viper/pull/456/files&lt;/a&gt; 更新了下viper。&lt;/p&gt;
&lt;p&gt;还有个不足。viper remote config 只接收一个 consul/etcd 的地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200422113501760.png&#34; alt=&#34;image-20200422113501760&#34;&gt;&lt;/p&gt;
&lt;p&gt;viper 依赖的 crypt 库因为consul api 库只支持一个地址，也支持不了多地址。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200422113617179.png&#34; alt=&#34;image-20200422113617179&#34;&gt;&lt;/p&gt;
&lt;p&gt;有几个解决办法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;搭配 consul 服务发现使用，只连本地的 consul client agent，client 节点挂了，本机和其上的服务等会标记为失败了，不会影响其他服务。&lt;/li&gt;
&lt;li&gt;保证 consul 地址是高可用的，比如 nginx 代理多个consul 地址。&lt;/li&gt;
&lt;li&gt;更新库，让 consul api 库支持多个地址。参考下 etcd client 的写法。 &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&#34;&gt;https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;其他一些资料&#34;&gt;其他：一些资料&lt;/h2&gt;
&lt;p&gt;可能有帮助。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Getting Started &lt;a href=&#34;https://learn.hashicorp.com/consul?track=getting-started#getting-started&#34;&gt;https://learn.hashicorp.com/consul?track=getting-started#getting-started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;基于consul构建golang系统分布式服务发现机制（使用Consul HTTP API） &lt;a href=&#34;https://segmentfault.com/a/1190000008471221&#34;&gt;https://segmentfault.com/a/1190000008471221&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Service registry bridge for Docker 监听Docker的Unix套接字来获取Docker容器启动和消亡时的事件，并且它会通过在事先配置好的一个可插拔的后端服务中创建新记录的形式自动完成容器的服务注册 &lt;a href=&#34;https://gliderlabs.github.io/registrator/latest/&#34;&gt;https://gliderlabs.github.io/registrator/latest/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200421-use-consul/ - </description>
        </item>
    
    
    
        <item>
        <title>etcd 小结</title>
        <link>https://xujiahua.github.io/posts/20200420-use_etcd/</link>
        <pubDate>Mon, 20 Apr 2020 14:12:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200420-use_etcd/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200420-use_etcd/ -&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;取名有意思。Linux下的/etc目录放的是配置文件。etcd，etc代表配置，d代表distributed，代表分布式配置。&lt;/p&gt;
&lt;p&gt;特点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;designed to reliably store infrequently updated data and provide reliable watch queries &lt;a href=&#34;https://etcd.io/docs/v3.4.0/learning/data_model/&#34;&gt;https://etcd.io/docs/v3.4.0/learning/data_model/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KV 核心用户接口&lt;/li&gt;
&lt;li&gt;MVCC Multi-version Concurrency Control 也确实能读历史版本&lt;/li&gt;
&lt;li&gt;Raft consensus algorithms 共识算法&lt;/li&gt;
&lt;li&gt;Watch 配置更新能及时&amp;quot;通知&amp;quot;应用&lt;/li&gt;
&lt;li&gt;RBAC 用户、角色、权限&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于 etcd 可以做哪些事情：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置中心。元数据存储。应用的配置集中存储在配置中心。&lt;/li&gt;
&lt;li&gt;服务发现。配置中心的一个特例。相比起来，consul的服务发现是开箱即用的。&lt;/li&gt;
&lt;li&gt;分布式锁。分布式系统协调。选主。像是Hadoop使用Zookeeper做Namenode的选主。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;vs. Consul。Consul 官方（https://www.consul.io/）定义的usecase是 service discovery和 service mesh。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;etcd and Consul solve different problems. If looking for a distributed consistent key value store, etcd is a better choice over Consul. If looking for end-to-end cluster service discovery, etcd will not have enough features; choose Kubernetes, Consul, or SmartStack. &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md#consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果是分布式配置中心，etcd是更好的选择。&lt;/p&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;etcd versus other key-value stores &lt;a href=&#34;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md&#34;&gt;https://github.com/etcd-io/etcd/blob/master/Documentation/learning/why.md&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;etcd集群安装&#34;&gt;etcd集群安装&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/XUJiahua/linux_scripts/tree/master/etcd&#34;&gt;https://github.com/XUJiahua/linux_scripts/tree/master/etcd&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;常用操作&#34;&gt;常用操作&lt;/h2&gt;
&lt;p&gt;etcdctl的命令主要是kv操作，以及集群管理，和RBAC用户权限管理。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://etcd.io/docs/v3.4.0/demo/&#34;&gt;https://etcd.io/docs/v3.4.0/demo/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;kv相关&#34;&gt;KV相关&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;put foo &amp;quot;Hello World&amp;quot;&lt;/code&gt;  KV写&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get foo&lt;/code&gt; KV读，还可以读历史版本的值&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get web --prefix&lt;/code&gt; KV前缀读，适用于服务发现&lt;/li&gt;
&lt;li&gt;&lt;code&gt;del key&lt;/code&gt; KV删除&lt;/li&gt;
&lt;li&gt;&lt;code&gt;del k --prefix&lt;/code&gt; KV前缀删除&lt;/li&gt;
&lt;li&gt;&lt;code&gt;txn --interactive&lt;/code&gt; KV事务&lt;/li&gt;
&lt;li&gt;&lt;code&gt;watch stock1&lt;/code&gt; KV关注value变化，适用于服务发现，服务发生变动&lt;/li&gt;
&lt;li&gt;&lt;code&gt;watch stock --prefix&lt;/code&gt;  watch也支持前缀匹配&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;lease&#34;&gt;Lease&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lease grant 300&lt;/code&gt; 创建300s的lease&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put sample value --lease=2be7547fbc6a5afa&lt;/code&gt; 有效期300s的key。不设置 lease的put操作，值是永久存储的。&lt;/li&gt;
&lt;li&gt;keep-alive 刷新TTL, list, revoke。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;分布式锁&#34;&gt;分布式锁&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lock mutex1&lt;/code&gt; 获取锁后，其他请求被block&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;集群管理&#34;&gt;集群管理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;member list&lt;/code&gt; list etcd member，member命令还可以增加新node，node也包含不投票的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;endpoint status&lt;/code&gt; 集群状态，能看到leader server&lt;/li&gt;
&lt;li&gt;&lt;code&gt;endpoint health&lt;/code&gt; 健康检查&lt;/li&gt;
&lt;li&gt;&lt;code&gt;snapshot save my.db&lt;/code&gt; 数据快照存储到本地&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;用户权限role-based-access-control&#34;&gt;用户权限（role based access control）&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;role add root&lt;/code&gt; 创建role&lt;/li&gt;
&lt;li&gt;&lt;code&gt;role grant-permission root readwrite foo&lt;/code&gt; role上赋予权限，这里赋予foo的读写权限&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user add root&lt;/code&gt; 创建用户，并指定密码&lt;/li&gt;
&lt;li&gt;&lt;code&gt;user grant-role root root&lt;/code&gt; 赋予用户role&lt;/li&gt;
&lt;li&gt;&lt;code&gt;auth enable&lt;/code&gt; 开启认证，disable 即关闭auth。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--user=root:root put foo bar&lt;/code&gt; 操作时指定用户密码&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200420-use_etcd/ - </description>
        </item>
    
    
    
        <item>
        <title>k8s configmap 与热更新</title>
        <link>https://xujiahua.github.io/posts/20200417-kubernetes-configmap/</link>
        <pubDate>Fri, 17 Apr 2020 16:09:28 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200417-kubernetes-configmap/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200417-kubernetes-configmap/ -&lt;h2 id=&#34;configmap-简介&#34;&gt;configmap 简介&lt;/h2&gt;
&lt;p&gt;官方介绍：使用 ConfigMap 配置 Pod  &lt;a href=&#34;https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/&#34;&gt;https://kubernetes.io/zh/docs/tasks/configure-pod-container/configure-pod-configmap/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;他人总结：ConfigMap &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/configmap.html&#34;&gt;https://jimmysong.io/kubernetes-handbook/concepts/configmap.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;稍微总结下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个configmap都有一个名字，名字全局唯一（命名空间内），重复创建会报错。&lt;/li&gt;
&lt;li&gt;每个configmap本身是键值对。&lt;/li&gt;
&lt;li&gt;configmap可以通过环境变量的方式让Pod内容器读取。&lt;/li&gt;
&lt;li&gt;configmap可以通过挂载文件的方式让Pod内容器读取。k8s每隔一段时间同步configmap，如果有更新的话。当然，应用本身是不知道的。这个定时更新感觉有点鸡肋。&lt;/li&gt;
&lt;li&gt;configmap更新，不会自动重启应用。只能人工方式，滚动重启应用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;把配置更新也当作一次应用变更看待，心情就好很多了。&lt;/p&gt;
&lt;p&gt;官方不支持热更新，所以有了各种技巧，提高效率。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;create a new ConfigMap with the changes you want to make, and point your deployment at the new ConfigMap &lt;a href=&#34;https://stackoverflow.com/a/40624029/820682&#34;&gt;https://stackoverflow.com/a/40624029/820682&lt;/a&gt; 因为 deployment 文件变化了，触发滚动重启。&lt;/li&gt;
&lt;li&gt;还有deployment 文件中配置 configmap hash值的。配置变化，hash值变化，deployment变化，滚动重启，一级级联动。 &lt;a href=&#34;https://blog.questionable.services/article/kubernetes-deployments-configmap-change/&#34;&gt;https://blog.questionable.services/article/kubernetes-deployments-configmap-change/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;还有使用sidecar的方式做热更新的，太复杂了 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/57570231&#34;&gt;https://zhuanlan.zhihu.com/p/57570231&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;关于热更新&#34;&gt;关于热更新&lt;/h2&gt;
&lt;p&gt;configmap的更新，容器化应用是无感知的。configmap这种方式没有推送更新到应用内的机制，要实现热更新过于复杂。&lt;/p&gt;
&lt;p&gt;k8s最核心的功能还是自动部署、伸缩、容器管理以及资源分配。微服务架构还是得需要其他框架来辅助的。&lt;/p&gt;
&lt;p&gt;配置热更新应用，就选择 etcd, consul 吧，有 watch 功能。&lt;/p&gt;
- https://xujiahua.github.io/posts/20200417-kubernetes-configmap/ - </description>
        </item>
    
    
    
        <item>
        <title>etcd api client 请求重试逻辑</title>
        <link>https://xujiahua.github.io/posts/20200417-etcd_client/</link>
        <pubDate>Fri, 17 Apr 2020 15:05:51 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200417-etcd_client/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200417-etcd_client/ -&lt;p&gt;使用 Consul 作为配置中心，按照官方的说法，没必要创建 &lt;code&gt;consul client&lt;/code&gt; 节点。那么直接连 &lt;code&gt;consul server&lt;/code&gt; 就好了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.consul.io/intro/index.html#basic-architecture-of-consul&#34;&gt;https://www.consul.io/intro/index.html#basic-architecture-of-consul&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Consul api client (&lt;a href=&#34;https://github.com/hashicorp/consul/tree/master/api&#34;&gt;https://github.com/hashicorp/consul/tree/master/api&lt;/a&gt;) 目前只能接收一个server地址。那么这个server地址得保证高可用才行啊。&lt;/p&gt;
&lt;p&gt;etcd api client (&lt;a href=&#34;https://github.com/etcd-io/etcd/tree/master/client&#34;&gt;https://github.com/etcd-io/etcd/tree/master/client&lt;/a&gt;) 倒是能接收多个server地址，看看 etcd 是怎么做的。&lt;/p&gt;
&lt;h3 id=&#34;etcd-api-client&#34;&gt;etcd api client&lt;/h3&gt;
&lt;p&gt;创建了 httpClusterClient。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200417151856806.png&#34; alt=&#34;image-20200417151856806&#34;&gt;&lt;/p&gt;
&lt;p&gt;多个 endpoint 的处理核心逻辑。https://github.com/etcd-io/etcd/blob/master/client/client.go#L362&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200417152639174.png&#34; alt=&#34;image-20200417152639174&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pinned 用于记录好用的连接地址的index，优先使用这个地址。&lt;/li&gt;
&lt;li&gt;context 类错误，比如取消请求，直接退出。&lt;/li&gt;
&lt;li&gt;遇到 5xx 类错误，服务端错误。需要考虑是否重试了。&lt;/li&gt;
&lt;li&gt;isOneShot 标记，true 代表是 Set/Delete 操作，请求失败不再重试。应该跟请求是否幂等有关。&lt;/li&gt;
&lt;li&gt;可以重试的请求，重试直到成功或是循环结束。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/20200417-etcd_client/ - </description>
        </item>
    
    
    
        <item>
        <title>机器学习在线推理部署方案：Cortex</title>
        <link>https://xujiahua.github.io/posts/20200416-cortex/</link>
        <pubDate>Thu, 16 Apr 2020 11:33:18 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200416-cortex/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200416-cortex/ -&lt;h2 id=&#34;cortex-介绍&#34;&gt;Cortex 介绍&lt;/h2&gt;
&lt;p&gt;官方网站：Deploy machine learning models in production &lt;a href=&#34;https://www.cortex.dev/&#34;&gt;https://www.cortex.dev/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GitHub &lt;a href=&#34;https://github.com/cortexlabs/cortex&#34;&gt;https://github.com/cortexlabs/cortex&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The CLI sends configuration and code to the cluster every time you run &lt;code&gt;cortex deploy&lt;/code&gt;. Each model is loaded into a Docker container, along with any Python packages and request handling code. The model is exposed as a web service using Elastic Load Balancing (ELB), TensorFlow Serving, and ONNX Runtime. The containers are orchestrated on Elastic Kubernetes Service (EKS) while logs and metrics are streamed to CloudWatch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;CLI工具将配置文件和代码推送到集群。模型连同Python依赖包和请求处理的代码被Docker容器打包。使用AWS ELB等暴露出Web服务。容器使用AWS EKS编排，日志和指标会推送到AWS CloudWatch。&lt;/p&gt;
&lt;h3 id=&#34;key-features&#34;&gt;Key Features&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi framework:&lt;/strong&gt; Cortex supports TensorFlow, PyTorch, scikit-learn, XGBoost, and more. 支持主流的机器学习、深度学习框架&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Autoscaling:&lt;/strong&gt; Cortex automatically scales APIs to handle production workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU / GPU support:&lt;/strong&gt; Cortex can run inference on CPU or GPU infrastructure. CPU/GPU都支持。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Spot instances:&lt;/strong&gt; Cortex supports EC2 spot instances.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rolling updates:&lt;/strong&gt; Cortex updates deployed APIs without any downtime. 依赖k8s的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log streaming:&lt;/strong&gt; Cortex streams logs from deployed models to your CLI. 依赖CloudWatch的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prediction monitoring:&lt;/strong&gt; Cortex monitors network metrics and tracks predictions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Minimal configuration:&lt;/strong&gt; Cortex deployments are defined in a single &lt;code&gt;cortex.yaml&lt;/code&gt; file.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;我的体验&#34;&gt;我的体验&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;与AWS深度绑定。对私有云、国内公有云不够友好了。&lt;/li&gt;
&lt;li&gt;依赖Kubernetes服务。&lt;/li&gt;
&lt;li&gt;依赖云存储服务，比如S3、OSS。cortex deploy的建议：cortex will zip files and upload them to the cluster; we recommend that you upload large files/directories (e.g. models) to s3 and download them in your api&amp;rsquo;s &lt;strong&gt;init&lt;/strong&gt; function,&lt;/li&gt;
&lt;li&gt;有一套Python API服务的模板，并使用Docker封装。比如 &lt;a href=&#34;https://github.com/cortexlabs/cortex/blob/master/images/python-serve/Dockerfile&#34;&gt;https://github.com/cortexlabs/cortex/blob/master/images/python-serve/Dockerfile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;推理Predictor类按照Cortex定义的接口规范实现，所在目录挂载到 /mnt/project 目录。&lt;/li&gt;
&lt;li&gt;启动容器，预置脚本会安装&lt;code&gt;requirement.txt&lt;/code&gt;，并动态加载Predictor类。&lt;/li&gt;
&lt;li&gt;使用者只需要处理模型训练和按照规范定义Predictor类。重复的API定义、部署、扩容，都已经被隐藏掉了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;代码结构&#34;&gt;代码结构&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;cli 目录：客户端。deploy操作，就是把本地的配置文件压缩成zip包上传。&lt;/li&gt;
&lt;li&gt;pkg/operator 目录：服务端。deploy接口在此：zip包会上传到S3，编程的方式申请k8s资源（deployment, service, virtualService），直接向k8s API server发送请求。&lt;/li&gt;
&lt;li&gt;pkg/lib 目录：比较核心的Go代码。&lt;/li&gt;
&lt;li&gt;pkg/workloads/cortex/downloader 目录：在k8s中作为InitContainer，用于下载配置文件到Pod中。&lt;/li&gt;
&lt;li&gt;pkg/workloads 目录：推理服务的代码，比较通用。pkg/workloads/cortex/serve/run.sh 留了个口子 &lt;code&gt;/mnt/project&lt;/code&gt;，每个服务个性化的部分留给开发者（遵从规范）。&lt;/li&gt;
&lt;li&gt;images 目录：镜像文件。包括 operator 的镜像文件，也包括推理服务的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;具体看看创建推理服务容器的过程。&lt;/p&gt;
&lt;p&gt;申请 K8s Deployment。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151230669.png&#34; alt=&#34;image-20200416151230669&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里分为三大类。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151318515.png&#34; alt=&#34;image-20200416151318515&#34;&gt;&lt;/p&gt;
&lt;p&gt;关注PythonPredictorType。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416151537448.png&#34; alt=&#34;image-20200416151537448&#34;&gt;&lt;/p&gt;
&lt;p&gt;传入 InitContainer （代码见 pkg/workloads/cortex/downloader）的参数如下，将S3上存储的配置信息和predictor文件等下载到Pod中的 &lt;code&gt;/mnt/project&lt;/code&gt;目录（&lt;code&gt;_emptyDirMountPath = &amp;quot;/mnt&amp;quot;&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416152324873.png&#34; alt=&#34;image-20200416152324873&#34;&gt;&lt;/p&gt;
&lt;p&gt;因为Pod内容器共享存储空间，这样推理服务容器就能读取到 &lt;code&gt;/mnt/project&lt;/code&gt;了。&lt;/p&gt;
&lt;h2 id=&#34;cortex-镜像体验&#34;&gt;cortex 镜像体验&lt;/h2&gt;
&lt;p&gt;下载地址 &lt;a href=&#34;https://hub.docker.com/r/cortexlabs/python-serve/tags&#34;&gt;https://hub.docker.com/r/cortexlabs/python-serve/tags&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;容器内代码也是依赖S3的，不修改还不能直接使用🤣。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200416161622829.png&#34; alt=&#34;image-20200416161622829&#34;&gt;&lt;/p&gt;
&lt;p&gt;到此为止吧。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -e CORTEX_SERVING_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5000&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_WORKERS_PER_REPLICA&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_MAX_WORKER_CONCURRENCY&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_THREADS_PER_WORKER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_SO_MAX_CONN&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2048&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_CACHE_DIR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/mnt/spec &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -e CORTEX_VERSION&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;0.15.1 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -v &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;:/mnt/project &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -v &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;:/mnt/spec &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        -p 5000:5000 cortexlabs/python-serve:0.15.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;- https://xujiahua.github.io/posts/20200416-cortex/ - </description>
        </item>
    
    
    
        <item>
        <title>k8s 应用日志收集</title>
        <link>https://xujiahua.github.io/posts/20200414-k8s-logging/</link>
        <pubDate>Tue, 14 Apr 2020 09:53:35 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200414-k8s-logging/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200414-k8s-logging/ -&lt;h2 id=&#34;k8s-日志收集架构&#34;&gt;k8s 日志收集架构&lt;/h2&gt;
&lt;p&gt;以下是比较一般、普适的架构。更多参考：Kubernetes 日志架构 &lt;a href=&#34;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&#34;&gt;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/logging-with-node-agent.png&#34; alt=&#34;使用节点日志记录代理&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;容器化应用将日志写入&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Docker容器引擎将&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;流重定向到日志驱动，比如默认的json-file。&lt;/li&gt;
&lt;li&gt;json-file日志驱动将日志写入到（宿主机上的）文件。&lt;/li&gt;
&lt;li&gt;日志收集工具以DaemonSet的形式安装在每个节点。&lt;/li&gt;
&lt;li&gt;日志收集工具监听文件变化，并将日志写入到日志中心服务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;k8s-日志收集细节&#34;&gt;k8s 日志收集细节&lt;/h2&gt;
&lt;h3 id=&#34;实战&#34;&gt;实战&lt;/h3&gt;
&lt;p&gt;可以直接参考以下教程：minikube创建了一个Kubernetes集群，Fluentd收集日志，存入ElasticSearch，使用Kibana查看日志。典型的EFK技术栈。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logging in Kubernetes with Elasticsearch, Kibana, and Fluentd &lt;a href=&#34;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&#34;&gt;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在Kibana上看收集到的日志。能看到日志收集工具也采集了容器、镜像、Pod有关的信息。这些上下文信息能让人定位到是哪个应用在生产日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414104511399.png&#34; alt=&#34;image-20200414104511399&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;fluentd-收集上下文信息&#34;&gt;fluentd 收集上下文信息&lt;/h3&gt;
&lt;p&gt;Docker &lt;code&gt;json-file&lt;/code&gt; 日志驱动写文件，并不记录上下文信息。 &lt;a href=&#34;https://docs.docker.com/config/containers/logging/json-file/&#34;&gt;https://docs.docker.com/config/containers/logging/json-file/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;log&amp;quot;:&amp;quot;Log line is here\n&amp;quot;,&amp;quot;stream&amp;quot;:&amp;quot;stdout&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2019-01-01T11:11:11.111111111Z&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上文中使用的日志收集镜像是 &lt;code&gt;fluent/fluentd-kubernetes-daemonset:v1.3-debian-elasticsearch&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;具体代码路径在此 &lt;a href=&#34;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&#34;&gt;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;收集容器目录下的日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105706563.png&#34; alt=&#34;image-20200414105706563&#34;&gt;&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;kubernetes_metadata&lt;/code&gt;这个第三方插件获取容器相关的上下文信息。这里是通过请求API server得到metadata的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105752287.png&#34; alt=&#34;image-20200414105752287&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubernetes_metadata&lt;/code&gt; 插件地址 &lt;a href=&#34;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&#34;&gt;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;插件中有缓存metadata的选项，不用担心每处理一条日志，就要向API server发送请求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414111028867.png&#34; alt=&#34;image-20200414111028867&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/20200414-k8s-logging/ - </description>
        </item>
    
    
  </channel>
</rss> 