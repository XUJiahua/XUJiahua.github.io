<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>许嘉华的博客</title>
    <link>https://xujiahua.github.io/</link>
    <description>Recent content on 许嘉华的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 14 Apr 2020 09:53:35 +0800</lastBuildDate>
    
        <atom:link href="https://xujiahua.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    
        <item>
        <title>k8s 应用日志收集</title>
        <link>https://xujiahua.github.io/posts/20200414-k8s-logging/</link>
        <pubDate>Tue, 14 Apr 2020 09:53:35 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/20200414-k8s-logging/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/20200414-k8s-logging/ -&lt;h2 id=&#34;k8s-日志收集架构&#34;&gt;k8s 日志收集架构&lt;/h2&gt;
&lt;p&gt;以下是比较一般、普适的架构。更多参考：Kubernetes 日志架构 &lt;a href=&#34;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&#34;&gt;https://kubernetes.io/zh/docs/concepts/cluster-administration/logging/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/logging-with-node-agent.png&#34; alt=&#34;使用节点日志记录代理&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;容器化应用将日志写入&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;Docker容器引擎将&lt;code&gt;stdout&lt;/code&gt;、&lt;code&gt;stderr&lt;/code&gt;流重定向到日志驱动，比如默认的json-file。&lt;/li&gt;
&lt;li&gt;json-file日志驱动将日志写入到（宿主机上的）文件。&lt;/li&gt;
&lt;li&gt;日志收集工具以DaemonSet的形式安装在每个节点。&lt;/li&gt;
&lt;li&gt;日志收集工具监听文件变化，并将日志写入到日志中心服务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;k8s-日志收集细节&#34;&gt;k8s 日志收集细节&lt;/h2&gt;
&lt;h3 id=&#34;实战&#34;&gt;实战&lt;/h3&gt;
&lt;p&gt;可以直接参考以下教程：minikube创建了一个Kubernetes集群，Fluentd收集日志，存入ElasticSearch，使用Kibana查看日志。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Logging in Kubernetes with Elasticsearch, Kibana, and Fluentd &lt;a href=&#34;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&#34;&gt;https://mherman.org/blog/logging-in-kubernetes-with-elasticsearch-Kibana-fluentd/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在Kibana上看收集到的日志。能看到日志收集工具也采集了容器、镜像、Pod有关的信息。这些上下文信息能让人定位到是哪个应用在生产日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414104511399.png&#34; alt=&#34;image-20200414104511399&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;fluentd-收集上下文信息&#34;&gt;fluentd 收集上下文信息&lt;/h3&gt;
&lt;p&gt;Docker &lt;code&gt;json-file&lt;/code&gt; 日志驱动写文件，并不记录上下文信息。 &lt;a href=&#34;https://docs.docker.com/config/containers/logging/json-file/&#34;&gt;https://docs.docker.com/config/containers/logging/json-file/&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;log&amp;quot;:&amp;quot;Log line is here\n&amp;quot;,&amp;quot;stream&amp;quot;:&amp;quot;stdout&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2019-01-01T11:11:11.111111111Z&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上文中使用的日志收集镜像是 &lt;code&gt;fluent/fluentd-kubernetes-daemonset:v1.3-debian-elasticsearch&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;具体代码路径在此 &lt;a href=&#34;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&#34;&gt;https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.3/debian-elasticsearch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;收集容器目录下的日志。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105706563.png&#34; alt=&#34;image-20200414105706563&#34;&gt;&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;kubernetes_metadata&lt;/code&gt;这个第三方插件获取容器相关的上下文信息。这里是通过请求API server得到metadata的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414105752287.png&#34; alt=&#34;image-20200414105752287&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubernetes_metadata&lt;/code&gt; 插件地址 &lt;a href=&#34;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&#34;&gt;https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;插件中有缓存metadata的选项，不用担心每处理一条日志，就要向API server发送请求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414111028867.png&#34; alt=&#34;image-20200414111028867&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/20200414-k8s-logging/ - </description>
        </item>
    
    
    
        <item>
        <title>Metabase &#43; Spark SQL</title>
        <link>https://xujiahua.github.io/posts/bi-metabase-spark-sql/</link>
        <pubDate>Fri, 10 Apr 2020 16:41:53 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/bi-metabase-spark-sql/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/bi-metabase-spark-sql/ -&lt;p&gt;这是大数据 BI 平台的第二步，BI 工具的搭建。假设已经配置好 Spark SQL JDBC Server，并启用了Kerberos。参考  &lt;a href=&#34;https://xujiahua.github.io/posts/spark-thrift-server-cdh/&#34;&gt;https://xujiahua.github.io/posts/spark-thrift-server-cdh/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里，我们选择了开源产品 Metabase。&lt;/p&gt;
&lt;p&gt;最终，大数据 BI 平台，是由 1) 以Metabase作为BI可视化，2) 由HDFS（分布式文件存储） + parquet（列式数据存储格式）+ Hive metastore（SQL表结构信息维护） + Spark SQL（批处理引擎）组合的OLAP数据库组成。&lt;/p&gt;
&lt;h2 id=&#34;metabase-简介&#34;&gt;Metabase 简介&lt;/h2&gt;
&lt;p&gt;Metabase is the easy, open source way for everyone in your company to ask questions and learn from data.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.metabase.com/&#34;&gt;https://www.metabase.com/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据库支持&#34;&gt;数据库支持&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BigQuery&lt;/li&gt;
&lt;li&gt;Druid&lt;/li&gt;
&lt;li&gt;Google Analytics&lt;/li&gt;
&lt;li&gt;H2&lt;/li&gt;
&lt;li&gt;MongoDB&lt;/li&gt;
&lt;li&gt;MySQL/MariaDB&lt;/li&gt;
&lt;li&gt;PostgreSQL&lt;/li&gt;
&lt;li&gt;Presto&lt;/li&gt;
&lt;li&gt;Amazon Redshift&lt;/li&gt;
&lt;li&gt;Snowflake&lt;/li&gt;
&lt;li&gt;Spark SQL&lt;/li&gt;
&lt;li&gt;SQLite&lt;/li&gt;
&lt;li&gt;SQL Server&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.metabase.com/docs/latest/faq/setup/which-databases-does-metabase-support.html&#34;&gt;https://www.metabase.com/docs/latest/faq/setup/which-databases-does-metabase-support.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这里有我们需要的Spark SQL，我们的大数据集群可以支持。比较遗憾的是没有Impala。&lt;/p&gt;
&lt;h2 id=&#34;metabase-安装&#34;&gt;Metabase 安装&lt;/h2&gt;
&lt;h3 id=&#34;mysql&#34;&gt;MySQL&lt;/h3&gt;
&lt;p&gt;使用MySQL作为元数据存储。复用之前CDH的MySQL实例。&lt;/p&gt;
&lt;p&gt;创建数据库、用户。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-SQL&#34; data-lang=&#34;SQL&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;-- 登录
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;mysql &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;u metabase &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p
&lt;span style=&#34;color:#75715e&#34;&gt;-- 适合MySQL5.7及以上版本，支持更大的max key length。一个字符使用四个字节。
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; metabase CHARACTER &lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; utf8mb4 &lt;span style=&#34;color:#66d9ef&#34;&gt;COLLATE&lt;/span&gt; utf8mb4_unicode_ci;
&lt;span style=&#34;color:#75715e&#34;&gt;-- 适合MySQL5.6及以下版本。一个字符使用3个字节。
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DATABASE&lt;/span&gt; metabase CHARACTER &lt;span style=&#34;color:#66d9ef&#34;&gt;SET&lt;/span&gt; utf8 &lt;span style=&#34;color:#66d9ef&#34;&gt;COLLATE&lt;/span&gt; utf8_unicode_ci;

&lt;span style=&#34;color:#75715e&#34;&gt;-- % 表示不限制host
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;CREATE&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;USER&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt; IDENTIFIED &lt;span style=&#34;color:#66d9ef&#34;&gt;BY&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;;
&lt;span style=&#34;color:#66d9ef&#34;&gt;GRANT&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ALL&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;ON&lt;/span&gt; metabase.&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;TO&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;%&amp;#39;&lt;/span&gt;;

FLUSH &lt;span style=&#34;color:#66d9ef&#34;&gt;PRIVILEGES&lt;/span&gt;;
&lt;span style=&#34;color:#75715e&#34;&gt;-- https://dev.mysql.com/doc/refman/5.7/en/grant.html
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;常见问题&#34;&gt;常见问题&lt;/h4&gt;
&lt;p&gt;mysql 5.7与5.6的区别。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;767 bytes is the &lt;a href=&#34;http://dev.mysql.com/doc/refman/5.1/en/create-index.html&#34;&gt;stated prefix limitation&lt;/a&gt; for InnoDB tables in MySQL version 5.6 (and prior versions). It&amp;rsquo;s 1,000 bytes long for MyISAM tables. In MySQL version 5.7 and upwards this limit has been increased to 3072 bytes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Caused by: java.sql.SQLException: Specified key was too long; max key length is 767 bytes&lt;/p&gt;
&lt;p&gt;Caused by: liquibase.exception.DatabaseException: (conn=175553) Specified key was too long; max key length is 767 bytes [Failed SQL: CREATE TABLE &lt;code&gt;metabase&lt;/code&gt;.&lt;code&gt;core_organization&lt;/code&gt; (&lt;code&gt;id&lt;/code&gt; INT AUTO_INCREMENT NOT NULL, &lt;code&gt;slug&lt;/code&gt; VARCHAR(254) NOT NULL, &lt;code&gt;name&lt;/code&gt; VARCHAR(254) NOT NULL, &lt;code&gt;description&lt;/code&gt; TEXT NULL, &lt;code&gt;logo_url&lt;/code&gt; VARCHAR(254) NULL, &lt;code&gt;inherits&lt;/code&gt; BIT(1) NOT NULL, CONSTRAINT &lt;code&gt;PK_CORE_ORGANIZATION&lt;/code&gt; PRIMARY KEY (&lt;code&gt;id&lt;/code&gt;), UNIQUE (&lt;code&gt;slug&lt;/code&gt;))]&lt;/p&gt;
&lt;h3 id=&#34;metabase&#34;&gt;Metabase&lt;/h3&gt;
&lt;p&gt;下载metabase。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 以 /opt/metabase 为工作目录&lt;/span&gt;
mkdir /opt/metabase &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; cd /opt/metabase
&lt;span style=&#34;color:#75715e&#34;&gt;# 下载最新版本的metabase，参考 https://www.metabase.com/start/jar.html&lt;/span&gt;
wget https://downloads.metabase.com/v0.35.1/metabase.jar
&lt;span style=&#34;color:#75715e&#34;&gt;# 创建插件目录&lt;/span&gt; 
mkdir plugins
&lt;span style=&#34;color:#75715e&#34;&gt;# Spark SQL的驱动，jar包内置的有问题&lt;/span&gt;
wget https://s3.amazonaws.com/sparksql-deps/metabase-sparksql-deps-1.2.1.spark2-standalone.jar -O plugins/metabase-sparksql-deps-1.2.1.spark2-standalone.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启动脚本 start.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
export MB_DB_TYPE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mysql
export MB_DB_DBNAME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_PORT&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3306&lt;/span&gt;
export MB_DB_USER&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_PASS&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;metabase
export MB_DB_HOST&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;172.31.0.100

kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING

mkdir -p logs

nohup java -Djavax.security.auth.useSubjectCredsOnly&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;false -jar metabase.jar  &amp;gt;&amp;gt; logs/metabase.log 2&amp;gt;&amp;amp;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &amp;amp;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;停止脚本 stop.sh。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
ps -ef | grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;metabase.jar&amp;#39;&lt;/span&gt; | grep -v &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;grep&amp;#39;&lt;/span&gt; | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt; | xargs kill -9

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;文件夹结构如下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 metabase&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ tree
├── hive.xh-hd2-peggy-dost000003.keytab
├── logs
│   └── metabase.log
├── metabase.jar
├── plugins
│   ├── metabase-sparksql-deps-1.2.1.spark2-standalone.jar
│   ├── sparksql.metabase-driver.jar
│   ├── ...
├── start.sh
└── stop.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Metabase搭建手册：使用SparkSQL连接Hive &lt;a href=&#34;https://webcache.googleusercontent.com/search?q=cache:DcmHXWOc9woJ:https://immm.in/archives/24.html+&amp;amp;cd=5&amp;amp;hl=zh-CN&amp;amp;ct=clnk&amp;amp;gl=hk&#34;&gt;https://webcache.googleusercontent.com/search?q=cache:DcmHXWOc9woJ:https://immm.in/archives/24.html+&amp;amp;cd=5&amp;amp;hl=zh-CN&amp;amp;ct=clnk&amp;amp;gl=hk&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;配置-spark-sql-连接&#34;&gt;配置 Spark SQL 连接&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410180255501.png&#34; alt=&#34;image-20200410180255501&#34;&gt;&lt;/p&gt;
&lt;p&gt;保存没有报错，就是成功了。&lt;/p&gt;
&lt;h4 id=&#34;常见问题-1&#34;&gt;常见问题&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;使用内置的驱动报错：Unrecognized Hadoop major version number: 3.1.1&lt;/li&gt;
&lt;li&gt;使用metabase-sparksql-deps-1.2.1.spark2-standalone.jar这个驱动报错，然而beeline连接是没问题的： transport.TSaslTransport :: SASL negotiation failure
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一个问题，暂时忽略，使用其他驱动。&lt;/p&gt;
&lt;p&gt;按理说，https://github.com/metabase/sparksql-deps 已经合并到 &lt;a href=&#34;https://github.com/metabase/metabase/tree/v0.35.1/modules/drivers/sparksql&#34;&gt;https://github.com/metabase/metabase/tree/v0.35.1/modules/drivers/sparksql&lt;/a&gt; 了。内置驱动就能用才对。&lt;/p&gt;
&lt;p&gt;能看到依赖hadoop-common包的版本差异。还得细看。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200411071918161.png&#34; alt=&#34;image-20200411071918161&#34;&gt;&lt;/p&gt;
&lt;p&gt;依赖的hadoop版本是3.1.0。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200411072135265.png&#34; alt=&#34;image-20200411072135265&#34;&gt;&lt;/p&gt;
&lt;p&gt;内置Driver依赖3.1.1。报错信息也是包含3.1.1，是否切到3.1.0，重新打包就可以了？&lt;/p&gt;
&lt;p&gt;第二个问题需要设置Java参数 &lt;code&gt;-Djavax.security.auth.useSubjectCredsOnly=false&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;通过底层机制获取凭证信息，而不是通过应用执行认证操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410173734177.png&#34; alt=&#34;image-20200410173734177&#34;&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How to connnect sparksql in Kerberos enviroment &lt;a href=&#34;https://discourse.metabase.com/t/how-to-connnect-sparksql-in-kerberos-enviroment/8290/2&#34;&gt;https://discourse.metabase.com/t/how-to-connnect-sparksql-in-kerberos-enviroment/8290/2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided https://stackoverflow.com/questions/32205087/javax-security-sasl-saslexception-gss-initiate-failed-caused-by-gssexception&lt;/li&gt;
&lt;li&gt;Below are listed some problems that may occur when attempting a login, and suggestions for solving them. &lt;a href=&#34;https://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/Troubleshooting.html&#34;&gt;https://docs.oracle.com/javase/7/docs/technotes/guides/security/jgss/tutorials/Troubleshooting.html&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;与-superset-比较&#34;&gt;与 Superset 比较&lt;/h2&gt;
&lt;p&gt;Superset是另外一个开源的BI工具。但是使用过程中体验不佳：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不支持多表JOIN。这个不能忍。&lt;/li&gt;
&lt;li&gt;直接写SQL，数据没法可视化。效率有点低下。&lt;/li&gt;
&lt;li&gt;外观丑陋。FlaskAppbuilder生成的前后端架子。&lt;/li&gt;
&lt;li&gt;Table源如果改了，建议删掉再添加，不然会有各种意外。&lt;/li&gt;
&lt;li&gt;交互体验差。自定义SELECT COUNT(cookie) as pv，死活搞不定。正确的使用方式是设置label，体验不直观。&lt;/li&gt;
&lt;li&gt;小bug多。用起来太容易烦躁了。对身心健康不好。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/bi-metabase-spark-sql/ - </description>
        </item>
    
    
    
        <item>
        <title>CDH6 启用 Spark Thrift Server</title>
        <link>https://xujiahua.github.io/posts/spark-thrift-server-cdh/</link>
        <pubDate>Fri, 10 Apr 2020 10:07:16 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/spark-thrift-server-cdh/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/spark-thrift-server-cdh/ -&lt;p&gt;很遗憾，CDH版本的Spark阉割了Thrift Server。（可能与自家产品Impala有竞争关系的原因。）&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark.html#spark__d99299e107&#34;&gt;https://docs.cloudera.com/documentation/enterprise/6/6.3/topics/spark.html#spark__d99299e107&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ll /opt/cloudera/parcels/CDH/lib/spark/sbin/
total 84
-rwxr-xr-x 1 root root 2803 Nov  9 00:05 slaves.sh
-rwxr-xr-x 1 root root 1429 Nov  9 00:05 spark-config.sh
-rwxr-xr-x 1 root root 5689 Nov  9 00:05 spark-daemon.sh
-rwxr-xr-x 1 root root 1262 Nov  9 00:05 spark-daemons.sh
-rwxr-xr-x 1 root root 1190 Nov  9 00:05 start-all.sh
-rwxr-xr-x 1 root root 1274 Nov  9 00:05 start-history-server.sh
-rwxr-xr-x 1 root root 2050 Nov  9 00:05 start-master.sh
-rwxr-xr-x 1 root root 1877 Nov  9 00:05 start-mesos-dispatcher.sh
-rwxr-xr-x 1 root root 1423 Nov  9 00:05 start-mesos-shuffle-service.sh
-rwxr-xr-x 1 root root 1279 Nov  9 00:05 start-shuffle-service.sh
-rwxr-xr-x 1 root root 3151 Nov  9 00:05 start-slave.sh
-rwxr-xr-x 1 root root 1527 Nov  9 00:05 start-slaves.sh
-rwxr-xr-x 1 root root 1478 Nov  9 00:05 stop-all.sh
-rwxr-xr-x 1 root root 1056 Nov  9 00:05 stop-history-server.sh
-rwxr-xr-x 1 root root 1080 Nov  9 00:05 stop-master.sh
-rwxr-xr-x 1 root root 1227 Nov  9 00:05 stop-mesos-dispatcher.sh
-rwxr-xr-x 1 root root 1084 Nov  9 00:05 stop-mesos-shuffle-service.sh
-rwxr-xr-x 1 root root 1067 Nov  9 00:05 stop-shuffle-service.sh
-rwxr-xr-x 1 root root 1557 Nov  9 00:05 stop-slave.sh
-rwxr-xr-x 1 root root 1064 Nov  9 00:05 stop-slaves.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可见，没有Thrift Server的启动脚本。&lt;/p&gt;
&lt;p&gt;借鉴网上资料（CDH 6成功启动spark-thrift服务 &lt;a href=&#34;https://blog.csdn.net/qq_34864753/article/details/102729859&#34;&gt;https://blog.csdn.net/qq_34864753/article/details/102729859&lt;/a&gt;），在不修改CDH Spark的前提下，我们需要启动一个独立的Spark Thrift Server。&lt;/p&gt;
&lt;p&gt;还需要考虑CDH Kerberos认证的问题。&lt;/p&gt;
&lt;h2 id=&#34;spark-thrift-server-简介&#34;&gt;Spark Thrift Server 简介&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/sparksqlthriftserver.png&#34; alt=&#34;Spark SQL Thrift Server&#34;&gt;&lt;/p&gt;
&lt;p&gt;Spark Thrift Server是Spark社区基于HiveServer2实现的一个Thrift服务。旨在无缝兼容HiveServer2。&lt;/p&gt;
&lt;p&gt;因为Spark Thrift Server的接口和协议都和HiveServer2完全一致，因此我们部署好Spark Thrift Server后，可以直接使用hive的beeline访问Spark Thrift Server执行相关语句。&lt;/p&gt;
&lt;p&gt;Spark Thrift Server的目的也只是取代HiveServer2，因此它依旧可以和Hive Metastore进行交互，获取到hive的元数据。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://www.jianshu.com/p/b719c6415411&#34;&gt;https://www.jianshu.com/p/b719c6415411&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;apache-spark配置&#34;&gt;Apache Spark配置&lt;/h2&gt;
&lt;h3 id=&#34;下载官方版本&#34;&gt;下载官方版本&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /opt
wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz
cd spark-2.4.0-bin-hadoop2.7 &lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ln -s &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;pwd&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt; /opt/spark
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;spark配置文件&#34;&gt;Spark配置文件&lt;/h3&gt;
&lt;p&gt;通过软链接的方式复用Hive的配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;ln -s /etc/hive/conf/hive-site.xml /opt/spark/conf/hive-site.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最后配置文件夹长这样。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# ll /opt/spark/conf/&lt;/span&gt;
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp  &lt;span style=&#34;color:#ae81ff&#34;&gt;996&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; docker.properties.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;1105&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; fairscheduler.xml.template
lrwxrwxrwx &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root   root     &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt; Apr  &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt; 11:05 hive-site.xml -&amp;gt; /etc/hive/conf/hive-site.xml
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;2025&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; log4j.properties.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;7801&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; metrics.properties.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp  &lt;span style=&#34;color:#ae81ff&#34;&gt;865&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; slaves.template
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;1292&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; spark-defaults.conf.template
-rwxr-xr-x &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; webapp webapp &lt;span style=&#34;color:#ae81ff&#34;&gt;4221&lt;/span&gt; Oct &lt;span style=&#34;color:#ae81ff&#34;&gt;29&lt;/span&gt;  &lt;span style=&#34;color:#ae81ff&#34;&gt;2018&lt;/span&gt; spark-env.sh.template
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;spark配置文件配置方式&#34;&gt;Spark配置文件配置方式&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;默认配置路径：&lt;code&gt;$SPARK_HOME/conf&lt;/code&gt;，如果&lt;code&gt;$SPARK_HOME&lt;/code&gt;不存在，脚本中会把脚本上层目录当做&lt;code&gt;$SPARK_HOME&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$SPARK_CONF_DIR&lt;/code&gt;，可以指定SPARK配置文件夹。&lt;/li&gt;
&lt;li&gt;Spark classpath，如果&lt;code&gt;hdfs-site.xml&lt;/code&gt; &lt;code&gt;core-site.xml&lt;/code&gt;在classpath，Spark可以读取。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$HADOOP_CONF_DIR&lt;/code&gt;，一般是&lt;code&gt;/etc/hadoop/conf&lt;/code&gt;目录，读Hadoop配置信息。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$YARN_CONF_DIR&lt;/code&gt;，一般也是&lt;code&gt;/etc/hadoop/conf&lt;/code&gt;目录。&lt;/li&gt;
&lt;li&gt;命令行中可以覆盖以上配置文件中的具体参数。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://spark.apache.org/docs/latest/configuration.html#inheriting-hadoop-cluster-configuration&#34;&gt;https://spark.apache.org/docs/latest/configuration.html#inheriting-hadoop-cluster-configuration&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;spark-lib修改&#34;&gt;Spark lib修改&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cd /opt/spark
rm -rf jars/hadoop-yarn-*
cp /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/hadoop-yarn-* jars/
cp /opt/cloudera/parcels/CDH-6.3.2-1.cdh6.3.2.p0.1605554/jars/hive-shims-scheduler-2.1.1-cdh6.3.2.jar jars/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;kerberos-认证&#34;&gt;Kerberos 认证&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200410140136660.png&#34; alt=&#34;image-20200410140136660&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;图中的三个角色，在Kerkeros认证体系下都对应一个principal。Kerberos principal相当于用户名，keytab相当于密码。权限配置，依靠hive与hdfs本身。&lt;/li&gt;
&lt;li&gt;JDBC客户端与Spark JDBC Server需要使用Kerberos认证。JDBC客户端需要拥有principal/keytab对。我们手动创建。&lt;/li&gt;
&lt;li&gt;Spark JDBC Server与Hive metastore需要使用Kerberos认证。JDBC服务端需要拥有principal/keytab对。我们手动创建。&lt;/li&gt;
&lt;li&gt;Hive metastore也拥有自己的principal/keytab对，不过这个已经由CDH托管了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;常见Kerberos错误：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;org.apache.hive.service.ServiceException: Unable to login to kerberos with given principal/keytab / Caused by: java.io.IOException: HiveServer2 Kerberos principal or keytab is not correctly configured&lt;/li&gt;
&lt;li&gt;Caused by: java.io.IOException: Login failure for &lt;a href=&#34;mailto:hive/xh-hd2-peggy-dost000003@PEGGY.LING&#34;&gt;hive/xh-hd2-peggy-dost000003@PEGGY.LING&lt;/a&gt; from keytab hive.keytab: javax.security.auth.login.LoginException: Unable to obtain password from user&lt;/li&gt;
&lt;li&gt;SASL negotiation failure
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;创建-spark-jdbc-server-的-principal&#34;&gt;创建 Spark JDBC Server 的 Principal&lt;/h3&gt;
&lt;p&gt;因为复用了Hive的配置文件，待创建的principal的名字需要满足配置中的规范。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000004 spark&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ cat conf/hive-site.xml
...
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.authentication.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hive/_HOST@PEGGY.LING&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
... 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在Kerberos服务器创建 principal及导出 keytab，同步到Spark JDBC Server所在机器。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create principal&lt;/span&gt;
kadmin.local addprinc -randkey hive/xh-hd2-peggy-dost000004
&lt;span style=&#34;color:#75715e&#34;&gt;# export keytab&lt;/span&gt;
kadmin.local ktadd -k hive.xh-hd2-peggy-dost000004.keytab hive/xh-hd2-peggy-dost000004
&lt;span style=&#34;color:#75715e&#34;&gt;# 验证是否OK&lt;/span&gt;
kinit -kt hive.xh-hd2-peggy-dost000004.keytab hive/xh-hd2-peggy-dost000004@PEGGY.LING
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动-spark-jdbc-server&#34;&gt;启动 Spark JDBC Server&lt;/h3&gt;
&lt;p&gt;启动脚本如下。因为配置文件里没有指定keytab的路径，需要通过&lt;code&gt;--hiveconf&lt;/code&gt;指定。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#!/usr/bin/bash
&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
export JAVA_HOME&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/java/jdk1.8.0_181-cloudera
export PATH&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;$PATH:$JAVA_HOME/bin
export HADOOP_CONF_DIR&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/hadoop/conf

kinit -kt hive.xh-hd2-peggy-dost000004.keytab hive/xh-hd2-peggy-dost000004@PEGGY.LING

sbin/start-thriftserver.sh &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;--hiveconf hive.server2.authentication.kerberos.keytab hive.xh-hd2-peggy-dost000004.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;也可以参考这篇文章：&lt;/p&gt;
&lt;p&gt;Configuring Spark Thrift Server with Kerberos &lt;a href=&#34;https://mapr.com/docs/61/Spark/ConfiguringSparkSQLThriftServer_Kerberos.html&#34;&gt;https://mapr.com/docs/61/Spark/ConfiguringSparkSQLThriftServer_Kerberos.html&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;kinit-ticket过期问题&#34;&gt;kinit ticket过期问题&lt;/h4&gt;
&lt;p&gt;Spark进程会自动处理Kerberos ticket renewal操作。&lt;/p&gt;
&lt;p&gt;默认的ticket_lifetime 1d，renew_lifetime 7d。上次kinit是04/10。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[webapp@xh-hd2-peggy-dost000004 spark]$ klist
Ticket cache: FILE:/tmp/krb5cc_1000
Default principal: hive/xh-hd2-peggy-dost000004@PEGGY.LING

Valid starting       Expires              Service principal
04/13/2020 01:32:45  04/14/2020 01:32:45  krbtgt/PEGGY.LING@PEGGY.LING
	renew until 04/17/2020 15:56:45
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;就看7天后会怎么样了。renew周期过了，会重建么？理论上是可以的。&lt;/p&gt;
&lt;p&gt;看到Spark代码中已经有kerberos集成了，包括登录啥的。&lt;/p&gt;
&lt;p&gt;spark/sql/hive-thriftserver/v2.3.5/src/main/java/org/apache/hive/service/auth/HiveAuthFactory.java&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200413110032646.png&#34; alt=&#34;image-20200413110032646&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200413105917167.png&#34; alt=&#34;image-20200413105917167&#34;&gt;&lt;/p&gt;
&lt;p&gt;TODO: kinit得到的ticket的有效期是24h。过了24h，怎么自动重置？crontab建个定时任务刷新吧。不知道CDH是怎么处理这个问题的。&lt;/p&gt;
&lt;h3 id=&#34;创建-jdbc-client-的-principal&#34;&gt;创建 JDBC Client 的 Principal&lt;/h3&gt;
&lt;p&gt;在Kerberos服务器创建 principal及导出 keytab，同步到 JDBC Client 所在机器。这里对principal的名称没有严格要求。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create principal&lt;/span&gt;
kadmin.local addprinc -randkey hive/xh-hd2-peggy-dost000003
&lt;span style=&#34;color:#75715e&#34;&gt;# export keytab&lt;/span&gt;
kadmin.local ktadd -k hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003 
&lt;span style=&#34;color:#75715e&#34;&gt;# 验证是否OK&lt;/span&gt;
kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;启动-jdbc-client&#34;&gt;启动 JDBC Client&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 spark&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;webapp@xh-hd2-peggy-dost000003 spark&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;$ bin/beeline -u &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;jdbc:hive2://xh-hd2-peggy-dost000004:10000/default;principal=hive/xh-hd2-peggy-dost000004@PEGGY.LING&amp;#34;&lt;/span&gt;
Connecting to jdbc:hive2://xh-hd2-peggy-dost000004:10000/default;principal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hive/xh-hd2-peggy-dost000004@PEGGY.LING
2020-04-10 16:09:01 INFO  Utils:310 - Supplied authorities: xh-hd2-peggy-dost000004:10000
2020-04-10 16:09:01 INFO  Utils:397 - Resolved authority: xh-hd2-peggy-dost000004:10000
2020-04-10 16:09:01 INFO  HiveConnection:203 - Will try to open client transport with JDBC Uri: jdbc:hive2://xh-hd2-peggy-dost000004:10000/default;principal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hive/xh-hd2-peggy-dost000004@PEGGY.LING
Connected to: Spark SQL &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;version 2.4.0&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
Driver: Hive JDBC &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;version 1.2.1.spark2&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 1.2.1.spark2 by Apache Hive
0: jdbc:hive2://xh-hd2-peggy-dost000004:10000&amp;gt; show databases;
+---------------+--+
| databaseName  |
+---------------+--+
| db1           |
| default       |
| product       |
+---------------+--+
&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; rows selected &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.091 seconds&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;至此，Thrift Server的启用就完成了。&lt;/p&gt;
&lt;h3 id=&#34;yarn-运行&#34;&gt;YARN 运行&lt;/h3&gt;
&lt;p&gt;失败了，TODO&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sbin/start-thriftserver.sh --hiveconf hive.server2.authentication.kerberos.keytab hive.keytab --hiveconf hive.server2.thrift.port=10001 --queue root.zm_yarn_pool.development  --master yarn --executor-memory 4g --executor-cores 2 --num-executors 20

2020-04-09 17:56:19 INFO  Client:54 - Requesting a new application from cluster with 5 NodeManagers
Exception in thread &amp;quot;main&amp;quot; java.lang.NoClassDefFoundError: org/apache/hadoop/util/FastNumberFormat
        at org.apache.hadoop.yarn.api.records.ApplicationId.toString(ApplicationId.java:104)
        at org.apache.spark.deploy.yarn.Client$.org$apache$spark$deploy$yarn$Client$$getAppStagingDir(Client.scala:1222)
        at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$cleanupStagingDirInternal$1(Client.scala:206)
        at org.apache.spark.deploy.yarn.Client.cleanupStagingDir(Client.scala:226)
        at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:191)
        at org.apache.spark.scheduler.cluster.YarnClientSchedulerBackend.start(YarnClientSchedulerBackend.scala:57)
        at org.apache.spark.scheduler.TaskSchedulerImpl.start(TaskSchedulerImpl.scala:178)
        at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:501)
        at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
        at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:935)
        at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:926)
        at scala.Option.getOrElse(Option.scala:121)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;外传cdh是如何管理hadoop配置文件的&#34;&gt;【外传】CDH是如何管理Hadoop配置文件的&lt;/h2&gt;
&lt;p&gt;以下结果都是通过观察实践所得。&lt;/p&gt;
&lt;p&gt;以Hive为例，&lt;code&gt;/etc/hive/conf&lt;/code&gt;下的配置文件由CDH生成。（CDH管理界面上可以修改这些配置。）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# ll /etc/hive/conf/&lt;/span&gt;
total &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root   &lt;span style=&#34;color:#ae81ff&#34;&gt;21&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 __cloudera_generation__
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root   &lt;span style=&#34;color:#ae81ff&#34;&gt;70&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 __cloudera_metadata__
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;3846&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 core-site.xml
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root  &lt;span style=&#34;color:#ae81ff&#34;&gt;617&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hadoop-env.sh
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;3839&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hdfs-site.xml
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;2655&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hive-env.sh
-rw-r--r-- &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root root &lt;span style=&#34;color:#ae81ff&#34;&gt;6925&lt;/span&gt; Dec &lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt; 15:02 hive-site.xml
...

&lt;span style=&#34;color:#75715e&#34;&gt;# head /etc/hive/conf/hive-site.xml&lt;/span&gt;
&amp;lt;?xml version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1.0&amp;#34;&lt;/span&gt; encoding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;UTF-8&amp;#34;&lt;/span&gt;?&amp;gt;

&amp;lt;!--Autogenerated by Cloudera Manager--&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.uris&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;thrift://xh-hd2-peggy-dost001:9083&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.client.socket.timeout&amp;lt;/name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们的集群是开启了Kerberos认证的。但是上述配置文件里没见principal的keytab路径配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grep keytab /etc/hive/conf/hive-site.xml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;也就是说，&lt;code&gt;/etc/hive/conf&lt;/code&gt;不是真正在被使用的配置文件。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/var/run/cloudera-scm-agent/process/&lt;/code&gt; 这个目录中有所有CDH监控的进程，包括我们关注的Hive进程。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://community.cloudera.com/t5/Support-Questions/Location-of-keytab-files/td-p/33716&#34;&gt;https://community.cloudera.com/t5/Support-Questions/Location-of-keytab-files/td-p/33716&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ls /var/run/cloudera-scm-agent/process/*hive*
/var/run/cloudera-scm-agent/process/954-hive-HIVEMETASTORE:
cloudera-monitor.properties        config.zip     creds.localjceks  hdfs-site.xml  hive-log4j2.properties  logs       redaction-rules.json  service-metrics.properties  supervisor_status
cloudera-stack-monitor.properties  core-site.xml  exit_code         hive.keytab    hive-site.xml           proc.json  sentry-site.xml       supervisor.conf             yarn-conf

/var/run/cloudera-scm-agent/process/955-hive-HIVESERVER2:
cloudera-monitor.properties        config.zip     exit_code           hdfs-site.xml  hive-log4j2.properties  logs                         navigator.lineage.client.properties  redaction-rules.json  service-metrics.properties  supervisor.conf    yarn-conf
cloudera-stack-monitor.properties  core-site.xml  fair-scheduler.xml  hive.keytab    hive-site.xml           navigator.client.properties  proc.json                            sentry-site.xml       spark-defaults.conf         supervisor_status

/var/run/cloudera-scm-agent/process/956-hive-WEBHCAT:
cloudera-monitor.properties        config.zip     exit_code      hive-site.xml  logs       redaction-rules.json        supervisor.conf    webhcat-default.xml       webhcat-site.xml
cloudera-stack-monitor.properties  core-site.xml  hdfs-site.xml  HTTP.keytab    proc.json  service-metrics.properties  supervisor_status  webhcat-log4j.properties  yarn-conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里Hive有三个进程，metastore，hiveserver2，WEBHCAT。可见principal对应的keytab，这里的 &lt;code&gt;hive.keytab&lt;/code&gt;，也是在这里维护着。配置文件也是在&lt;code&gt;/etc/hive/conf&lt;/code&gt;基础上作了改动，比如keytab路径的设置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root 954-hive-HIVEMETASTORE&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grep kerberos hive-site.xml&lt;/span&gt;
    &amp;lt;name&amp;gt;hive.metastore.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.kerberos.keytab.file&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;kerberos&amp;lt;/value&amp;gt;
    
&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root 955-hive-HIVESERVER2&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grep kerberos hive-site.xml&lt;/span&gt;
    &amp;lt;value&amp;gt;kerberos&amp;lt;/value&amp;gt;
    &amp;lt;name&amp;gt;hive.metastore.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.authentication.kerberos.principal&amp;lt;/name&amp;gt;
    &amp;lt;name&amp;gt;hive.server2.authentication.kerberos.keytab&amp;lt;/name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;HiveMetaStore与HiveServer2使用的keytab是不同的。一个principal对应多个keytab么？TODO：可能是因为加密随机的原因？？？&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root@xh-hd2-peggy-dost001 955-hive-HIVESERVER2&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# md5sum hive.keytab&lt;/span&gt;
523357eec4f542b7b3df7ec52cee43b2  hive.keytab

&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;root@xh-hd2-peggy-dost001 954-hive-HIVEMETASTORE&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# md5sum hive.keytab&lt;/span&gt;
3c6f52333067518ae4bdce1e99878857  hive.keytab
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TODO：实验发现，导出两次，之前的keytab就失效了！进入知识盲区。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@xh-hd2-peggy-rost01 ~]# kadmin.local addprinc -randkey hive/xh-hd2-peggy-dost000003
[root@xh-hd2-peggy-rost01 ~]# kadmin.local ktadd -k hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003
[root@xh-hd2-peggy-rost01 ~]# mv hive.xh-hd2-peggy-dost000003.keytab hive.xh-hd2-peggy-dost000003.keytab.bak
[root@xh-hd2-peggy-rost01 ~]# kadmin.local ktadd -k hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003
[root@xh-hd2-peggy-rost01 ~]# kinit -kt hive.xh-hd2-peggy-dost000003.keytab hive/xh-hd2-peggy-dost000003@PEGGY.LING
[root@xh-hd2-peggy-rost01 ~]# kinit -kt hive.xh-hd2-peggy-dost000003.keytab.bak hive/xh-hd2-peggy-dost000003@PEGGY.LING
kinit: Password incorrect while getting initial credentials
&lt;/code&gt;&lt;/pre&gt;- https://xujiahua.github.io/posts/spark-thrift-server-cdh/ - </description>
        </item>
    
    
    
        <item>
        <title>Docker日志驱动小结</title>
        <link>https://xujiahua.github.io/posts/docker-logging/</link>
        <pubDate>Fri, 03 Apr 2020 15:43:07 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/docker-logging/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/docker-logging/ -&lt;p&gt;&lt;code&gt;docker logs&lt;/code&gt;， &lt;code&gt;kubectl logs&lt;/code&gt;能看到Docker容器的标准输出、标准错误，方便定位问题。而 &lt;code&gt;xxx logs&lt;/code&gt;之所以能看到，是因为标准输出、标准错误存储在每个容器独有的日志文件中。&lt;/p&gt;
&lt;p&gt;另外日志量大了，用&lt;code&gt;docker logs&lt;/code&gt;看历史数据不大合适。我们就需要考虑将日志存储到日志中心去。&lt;/p&gt;
&lt;p&gt;Docker默认支持如下日志驱动。有直接写文件的，有使用云服务的。下面简单介绍下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/Screen-Shot-2017-09-11-at-3.08.50-PM.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;credit: &lt;a href=&#34;https://jaxenter.com/docker-logging-gotchas-137049.html&#34;&gt;https://jaxenter.com/docker-logging-gotchas-137049.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;官方文档 &lt;a href=&#34;https://docs.docker.com/config/containers/logging/configure/&#34;&gt;https://docs.docker.com/config/containers/logging/configure/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;默认驱动json-file&#34;&gt;默认驱动：json-file&lt;/h2&gt;
&lt;p&gt;默认的Logging Driver是json-file。&lt;code&gt;docker info&lt;/code&gt;可以查看。全局的日志驱动设置，可以修改daemon配置文件 &lt;code&gt;/etc/docker/daemon.json&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;写入文件的日志格式长这样：&lt;code&gt;{&amp;quot;log&amp;quot;:&amp;quot;Log line is here\n&amp;quot;,&amp;quot;stream&amp;quot;:&amp;quot;stdout&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2019-01-01T11:11:11.111111111Z&amp;quot;}&lt;/code&gt;，每一行是一个json文件，log字段为容器原来输出的每行内容。&lt;/p&gt;
&lt;p&gt;默认配置，创建的容器的信息在这个目录下： &lt;code&gt;/var/lib/docker/containers&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;实验&#34;&gt;实验&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;root@ubuntu-parallel:~# docker run --name default_logging_driver hello-world

root@ubuntu-parallel:~# cd /var/lib/docker/containers/&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;docker ps --no-trunc -aqf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name=default_logging_driver&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;

root@ubuntu-parallel:~# cat &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;docker ps --no-trunc -aqf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name=default_logging_driver&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;-json.log
&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;log&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stream&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stdout&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2020-04-02T01:46:54.096347888Z&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;log&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Hello from Docker!\n&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stream&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stdout&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2020-04-02T01:46:54.096377382Z&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;log&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;This message shows that your installation appears to be working correctly.\n&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stream&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stdout&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2020-04-02T01:46:54.096381118Z&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;log&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;\n&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stream&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stdout&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2020-04-02T01:46:54.096383725Z&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/config/containers/logging/json-file/&#34;&gt;https://docs.docker.com/config/containers/logging/json-file/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;怎么记录更多上下文信息&#34;&gt;怎么记录更多上下文信息&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;json-file&lt;/code&gt;本身是没有记录上下文信息的。集中存储到日志中心服务器，就无法区分具体是哪个应用产生的日志了。&lt;/p&gt;
&lt;p&gt;k8s的容器日志收集，上下文信息是由日志收集工具 &lt;code&gt;fluentd&lt;/code&gt; 通过请求api server采集并缓存起来的。参考 &lt;a href=&#34;https://xujiahua.github.io/posts/20200414-k8s-logging/&#34;&gt;https://xujiahua.github.io/posts/20200414-k8s-logging/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;同样的思路，&lt;code&gt;fluentd&lt;/code&gt;也有不少通过docker daemon查询或是解析容器目录下&lt;code&gt;config.v2.json&lt;/code&gt;获取metadata的 filter 插件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200414112709859.png&#34; alt=&#34;image-20200414112709859&#34;&gt;&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://www.fluentd.org/plugins&#34;&gt;https://www.fluentd.org/plugins&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;local&#34;&gt;local&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;--log-driver&lt;/code&gt;指定日志驱动。&lt;/p&gt;
&lt;p&gt;cat输出local文件，部分结果乱码。挺不方便日志解析的。&lt;/p&gt;
&lt;h3 id=&#34;实验-1&#34;&gt;实验&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;root@ubuntu-parallel:~# docker run --name local_logging_driver --log-driver local hello-world

root@ubuntu-parallel:~# cd /var/lib/docker/containers/&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;docker ps --no-trunc -aqf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name=local_logging_driver&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;

root@ubuntu-parallel:~# cat local-logs/container.log
stdout�������&amp;amp;
stdout�������Hello from Docker!&amp;amp;^
stdout˧�����JThis message shows that your installation appears to be working correctly.^
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/config/containers/logging/local/&#34;&gt;https://docs.docker.com/config/containers/logging/local/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;none&#34;&gt;none&lt;/h2&gt;
&lt;p&gt;不生成日志文件，&lt;code&gt;docker logs&lt;/code&gt;也拿不到日志。实际使用不会考虑。&lt;/p&gt;
&lt;h3 id=&#34;实验-2&#34;&gt;实验&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;root@ubuntu-parallel:~# docker run --name none_logging_driver --log-driver none hello-world

root@ubuntu-parallel:~# cd /var/lib/docker/containers/&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;docker ps --no-trunc -aqf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name=none_logging_driver&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;

root@ubuntu-parallel:~# docker logs none_logging_driver
Error response from daemon: configured logging driver does not support reading
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;syslog&#34;&gt;syslog&lt;/h2&gt;
&lt;p&gt;因为日志被写入了syslog，并混在其他应用的日志中，&lt;code&gt;docker logs&lt;/code&gt;没办法工作了。&lt;/p&gt;
&lt;h3 id=&#34;实验-3&#34;&gt;实验&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 观察syslog&lt;/span&gt;
root@ubuntu-parallel:~# tail -f /var/log/syslog

root@ubuntu-parallel:~# docker run --name syslog_logging_driver --log-driver syslog hello-world

&lt;span style=&#34;color:#75715e&#34;&gt;# 日志不会写本地&lt;/span&gt;
root@ubuntu-parallel:~# cd /var/lib/docker/containers/&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;docker ps --no-trunc -aqf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name=syslog_logging_driver&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;

root@ubuntu-parallel:~# docker logs syslog_logging_driver
Error response from daemon: configured logging driver does not support reading
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/config/containers/logging/syslog/&#34;&gt;https://docs.docker.com/config/containers/logging/syslog/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;journald&#34;&gt;journald&lt;/h2&gt;
&lt;p&gt;写入syslog和journald，应用日志与系统日志混在一起，难以辨认了。&lt;/p&gt;
&lt;p&gt;倒是journald驱动下，可以使用&lt;code&gt;docker logs&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;参考：https://wiki.archlinux.org/index.php/Systemd/Journal&lt;/p&gt;
&lt;h3 id=&#34;实验-4&#34;&gt;实验&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;root@ubuntu-parallel:~# docker run --name journald_logging_driver --log-driver journald hello-world

root@ubuntu-parallel:~# journalctl
Apr &lt;span style=&#34;color:#ae81ff&#34;&gt;02&lt;/span&gt; 10:30:36 ubuntu-parallel 4b948bf091a8&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;999&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: To try something more ambitious, you can run an Ubuntu container with:
Apr &lt;span style=&#34;color:#ae81ff&#34;&gt;02&lt;/span&gt; 10:30:36 ubuntu-parallel 4b948bf091a8&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;999&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;:  $ docker run -it ubuntu bash
Apr &lt;span style=&#34;color:#ae81ff&#34;&gt;02&lt;/span&gt; 10:30:36 ubuntu-parallel 4b948bf091a8&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;999&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;:
Apr &lt;span style=&#34;color:#ae81ff&#34;&gt;02&lt;/span&gt; 10:30:36 ubuntu-parallel 4b948bf091a8&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;999&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: Share images, automate workflows, and more with a free Docker ID:
Apr &lt;span style=&#34;color:#ae81ff&#34;&gt;02&lt;/span&gt; 10:30:36 ubuntu-parallel 4b948bf091a8&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;999&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;:  https://hub.docker.com/

root@ubuntu-parallel:~# cd /var/lib/docker/containers/&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;docker ps --no-trunc -aqf &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name=journald_logging_driver&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# docker logs管用&lt;/span&gt;
root@ubuntu-parallel:~# docker logs journald_logging_driver

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/config/containers/logging/journald/&#34;&gt;https://docs.docker.com/config/containers/logging/journald/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;fluentd&#34;&gt;Fluentd&lt;/h2&gt;
&lt;p&gt;通过服务请求，让docker吐日志到fluentd进程。https://docs.docker.com/config/containers/logging/fluentd/&lt;/p&gt;
&lt;p&gt;使用包括fluentd在很多日志驱动，因为日志写入到远程服务器，会导致&lt;code&gt;docker logs&lt;/code&gt;， &lt;code&gt;kubectl logs&lt;/code&gt;不可用。&lt;/p&gt;
&lt;p&gt;Fluentd是一个挺灵活的工具，可以让fluentd主动监听容器目录下的日志文件。参考另一篇文章 &lt;a href=&#34;https://xujiahua.github.io/posts/use-fluentd/&#34;&gt;https://xujiahua.github.io/posts/use-fluentd/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;为了兼容可使用&lt;code&gt;docker logs&lt;/code&gt; ，&lt;code&gt;kubectl logs&lt;/code&gt;，必须使用写本地文件的日志驱动。而json格式更方便工具（比如fluentd，logstash）解析，所以json-file是首选。&lt;/p&gt;
&lt;p&gt;然后使用日志收集工具集中采集docker容器日志。k8s中日志收集策略，一般是在每台服务器上以DaemonSet的形式安装logging agent，监听本地文件、文件夹，将日志转发到日志中心。&lt;/p&gt;
&lt;p&gt;当然这个前提条件是，应用日志是输出到标准输出和标准错误的。这对应用日志的规范有一定要求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不输出多行日志。比如panic、exception。&lt;/li&gt;
&lt;li&gt;应用日志使用JSON格式输出，方便后续的日志分析。&lt;/li&gt;
&lt;li&gt;应用日志中加入更多的上下文信息。用于问题定位，维度分析。&lt;/li&gt;
&lt;li&gt;Go应用开发，使用logrus日志库，加字段，以JSON格式输出都很方便。&lt;/li&gt;
&lt;li&gt;应用不关注日志该如何收集这个问题。不在应用层写日志到kafka、redis等中间件，让基础设施层处理。&lt;/li&gt;
&lt;li&gt;应用要么写入文件、要么写入标准输出，这个应该很方便做成可配置的。对程序来说，都有共同的抽象，io.Writer。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;应用日志如果是写到文件的，需要考虑通过数据卷，挂载等将日志与容器分离。采集挂载目录上的日志文件，以前怎么收集，现在还是怎么收集。还是建议写标准输出，这是目前的最佳实践。&lt;/p&gt;
- https://xujiahua.github.io/posts/docker-logging/ - </description>
        </item>
    
    
    
        <item>
        <title>Fluentd实战</title>
        <link>https://xujiahua.github.io/posts/use-fluentd/</link>
        <pubDate>Thu, 02 Apr 2020 16:58:23 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/use-fluentd/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/use-fluentd/ -&lt;p&gt;以收集Docker容器日志的例子，介绍下Fluentd的用法。不考虑logstash，太占服务器资源了。&lt;/p&gt;
&lt;h2 id=&#34;安装-fluentd&#34;&gt;安装 Fluentd&lt;/h2&gt;
&lt;p&gt;Ubuntu 18.04上的安装命令（https://docs.fluentd.org/installation/install-by-deb）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# curl -L https://toolbelt.treasuredata.com/sh/install-ubuntu-bionic-td-agent3.sh | sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;以Daemon方式启动：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# systemctl start td-agent.service
root@ubuntu-parallel:~# systemctl status td-agent.service
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;fluentd的安装目录是在/opt/td-agent/下的。为演示方便，我们可以直接使用 &lt;code&gt;/opt/td-agent/embedded/bin/fluentd&lt;/code&gt;这个程序。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# ps -ef | grep fluentd
td-agent 30596     1  0 17:10 ?        00:00:00 /opt/td-agent/embedded/bin/ruby /opt/td-agent/embedded/bin/fluentd --log /var/log/td-agent/td-agent.log --daemon /var/run/td-agent/td-agent.pid
td-agent 30602 30596  9 17:10 ?        00:00:00 /opt/td-agent/embedded/bin/ruby -Eascii-8bit:ascii-8bit /opt/td-agent/embedded/bin/fluentd --log /var/log/td-agent/td-agent.log --daemon /var/run/td-agent/td-agent.pid --under-supervisor
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其他系统的安装参考：https://docs.fluentd.org/installation&lt;/p&gt;
&lt;h3 id=&#34;小试牛刀&#34;&gt;小试牛刀&lt;/h3&gt;
&lt;p&gt;配置文件 test.conf，启动一个HTTP服务，并把接收到的日志，打印到标准输出。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type http
  port 9880
&amp;lt;/source&amp;gt;

&amp;lt;match *.*&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;启动fluentd进程。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# /opt/td-agent/embedded/bin/fluentd -c test.conf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过HTTP服务提交日志。可以看到fluentd终端打印出了输入的日志。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# curl -X POST -d &#39;json={&amp;quot;event&amp;quot;:&amp;quot;data&amp;quot;}&#39; http://localhost:9880/my.tag
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;实战收集linux主机上的docker容器日志&#34;&gt;实战：收集Linux主机上的Docker容器日志&lt;/h2&gt;
&lt;p&gt;Docker官方有fluentd的Logging Driver。不足之处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为没有了本地日志文件，docker logs 不管用了。&lt;/li&gt;
&lt;li&gt;需要额外配置，或是在daemon.json里设定，或是docker run时候设定。新增机器或是运行容器，很容易忘记。&lt;/li&gt;
&lt;li&gt;如果远程数据存储down了，会不会丢日志。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;考虑到这些问题，本实验以收集本地日志的方式使用fluentd。&lt;/p&gt;
&lt;h3 id=&#34;实验前提条件&#34;&gt;实验前提条件&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Linux系统&lt;/li&gt;
&lt;li&gt;Docker容器使用默认的Logging Driver，也就是json-file&lt;/li&gt;
&lt;li&gt;容器日志目录（也包含其他配置文件的）&lt;code&gt;/var/lib/docker/containers&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;配置文件输出到stdout&#34;&gt;配置文件（输出到stdout）&lt;/h3&gt;
&lt;p&gt;定义一个配置文件 docker.container.log.conf&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;source&amp;gt;
  @type tail
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/docker_container.log.pos
  tag docker.*
  refresh_interval 10
  read_from_head true
  &amp;lt;parse&amp;gt;
    @type json
  &amp;lt;/parse&amp;gt;
&amp;lt;/source&amp;gt;

&amp;lt;filter docker.var.lib.docker.containers.*.*.log&amp;gt;
  @type parser
  key_name log
  remove_key_name_field true
  &amp;lt;parse&amp;gt;
    @type json
  &amp;lt;/parse&amp;gt;
&amp;lt;/filter&amp;gt;

&amp;lt;filter docker.var.lib.docker.containers.*.*.log&amp;gt;
  @type record_transformer
  &amp;lt;record&amp;gt;
    container_id ${tag_parts[5]}
    hostname &amp;quot;#{Socket.gethostname}&amp;quot;
  &amp;lt;/record&amp;gt;
&amp;lt;/filter&amp;gt;

&amp;lt;match docker.var.lib.docker.containers.*.*.log&amp;gt;
  @type stdout
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;简要介绍&#34;&gt;简要介绍&lt;/h4&gt;
&lt;p&gt;一个典型的日志收集过程分三部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定义数据源，也就是source部分&lt;/li&gt;
&lt;li&gt;每条数据可以增删修改字段，也就是filter部分，filter可以是0个或是多个，按顺序处理。&lt;/li&gt;
&lt;li&gt;数据输出，也就是match部分&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;source&#34;&gt;source&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;@type tail 使用tail插件 &lt;a href=&#34;https://docs.fluentd.org/input/tail&#34;&gt;https://docs.fluentd.org/input/tail&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;path 定义路径，正则匹配&lt;/li&gt;
&lt;li&gt;pos_file 存放读文件的offset&lt;/li&gt;
&lt;li&gt;需要定义tag，filter、match使用tag进行匹配。&lt;/li&gt;
&lt;li&gt;tag docker.*，*会被实际的文件名给替代&lt;/li&gt;
&lt;li&gt;refresh_interval 设置多久刷新监听的文件列表，默认60秒&lt;/li&gt;
&lt;li&gt;read_from_head 默认false，也就是，没有pos存在的话，从文件尾读取。设置为true，解决新增文件而文件又没被fluentd及时监听起来的问题。&lt;/li&gt;
&lt;li&gt;parse 使用json解析，因为docker的logging driver用的json-file&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;更多source插件见：https://docs.fluentd.org/input&lt;/p&gt;
&lt;h4 id=&#34;filter&#34;&gt;filter&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;指定tag pattern&lt;/li&gt;
&lt;li&gt;@type parser 使用parser插件 &lt;a href=&#34;https://docs.fluentd.org/filter/parser&#34;&gt;https://docs.fluentd.org/filter/parser&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;key_name 需要parse的字段名&lt;/li&gt;
&lt;li&gt;remove_key_name_field 因为我们只需要log字段的json内容，log字段本身不需要保留&lt;/li&gt;
&lt;li&gt;parse 解析为json，因为我们的应用日志是json格式输出的&lt;/li&gt;
&lt;li&gt;@type record_transformer 使用record_transformer插件 &lt;a href=&#34;https://docs.fluentd.org/filter/record_transformer&#34;&gt;https://docs.fluentd.org/filter/record_transformer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;record 新增字段&lt;/li&gt;
&lt;li&gt;${tag_parts[5]} 预定义的变量，tag_parts是tag字符串被&amp;rdquo;.&amp;ldquo;切分后的数组，第6个代表的是container_id&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;quot;#{Socket.gethostname}&amp;quot;&lt;/code&gt; ruby内的变量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;更多filter插件见：https://docs.fluentd.org/filter&lt;/p&gt;
&lt;h4 id=&#34;match&#34;&gt;match&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;指定tag pattern&lt;/li&gt;
&lt;li&gt;@type stdout 使用stdout插件，用于演示 &lt;a href=&#34;https://docs.fluentd.org/output/stdout&#34;&gt;https://docs.fluentd.org/output/stdout&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;启动fluentd&#34;&gt;启动fluentd&lt;/h3&gt;
&lt;p&gt;注意查看日志。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# /opt/td-agent/embedded/bin/fluentd -c docker.container.log.conf
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;生成日志&#34;&gt;生成日志&lt;/h3&gt;
&lt;p&gt;JSON格式输出每一行日志。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# docker run -it busybox echo &#39;{&amp;quot;user&amp;quot;:1,&amp;quot;num&amp;quot;:2}&#39;
{&amp;quot;user&amp;quot;:1,&amp;quot;num&amp;quot;:2}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;观察 &lt;code&gt;/var/lib/docker/containers/*/*-json.log&lt;/code&gt;日志内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;log&amp;quot;:&amp;quot;{\&amp;quot;user\&amp;quot;:1,\&amp;quot;num\&amp;quot;:2}\r\n&amp;quot;,&amp;quot;stream&amp;quot;:&amp;quot;stdout&amp;quot;,&amp;quot;time&amp;quot;:&amp;quot;2020-04-02T12:25:50.877037148Z&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;fluentd stdout输出：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;user&amp;quot;:1,&amp;quot;num&amp;quot;:2,&amp;quot;container_id&amp;quot;:&amp;quot;e4fb94ee2d067450eeaf15837ed1497e2b7eb2f6754ba4eec1792ee37e31f12f&amp;quot;,&amp;quot;hostname&amp;quot;:&amp;quot;ubuntu-parallel&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;输出从stdout改为elasticsearch&#34;&gt;输出从stdout改为elasticsearch&lt;/h3&gt;
&lt;h4 id=&#34;启动es&#34;&gt;启动ES&lt;/h4&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html&#34;&gt;https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html&lt;/a&gt;，使用docker-compose启动es和kibana服务。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# docker-compose up
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;修改match&#34;&gt;修改match&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;match docker.var.lib.docker.containers.*.*.log&amp;gt;
  @type elasticsearch
  host localhost
  port 9200
  logstash_format true
&amp;lt;/match&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;参考：https://docs.fluentd.org/output/elasticsearch&lt;/p&gt;
&lt;h4 id=&#34;启动fluentd-1&#34;&gt;启动fluentd&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;root@ubuntu-parallel:~# /opt/td-agent/embedded/bin/fluentd -c docker.container.log.es.conf
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;kibana日志分析&#34;&gt;kibana日志分析&lt;/h4&gt;
&lt;p&gt;因为ES的日志已经是JSON格式输出的，所以也不需要额外造数据了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200403001746670.png&#34; alt=&#34;image-20200403001746670&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/use-fluentd/ - </description>
        </item>
    
    
    
        <item>
        <title>Google Vision API</title>
        <link>https://xujiahua.github.io/posts/google-vision-api/</link>
        <pubDate>Wed, 01 Apr 2020 14:20:51 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/google-vision-api/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/google-vision-api/ -&lt;h2 id=&#34;目标&#34;&gt;目标&lt;/h2&gt;
&lt;p&gt;业务上需要识别出文本、图像敏感内容，降低业务风险。&lt;/p&gt;
&lt;p&gt;调用下云服务的产品。&lt;/p&gt;
&lt;h2 id=&#34;google-cloud-platform&#34;&gt;Google Cloud Platform&lt;/h2&gt;
&lt;p&gt;GCP上，图像识别有两个产品：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Vision API 直接使用预先训练的模型&lt;/li&gt;
&lt;li&gt;AutoML 迁移学习，使用用户提交的新分类数据，训练模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关于文本识别的产品是类似的，也分直接使用预训练模型和迁移学习重新训练。&lt;/p&gt;
&lt;h2 id=&#34;vision-api图像内容识别&#34;&gt;Vision API：图像内容识别&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Google Vision API的模型已经有审核内容的能力：暴力、成人内容的识别。&lt;/li&gt;
&lt;li&gt;提供API，也提供了各个语言的SDK。&lt;/li&gt;
&lt;li&gt;不需要开发者训练模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401145549783.png&#34; alt=&#34;image-20200401145549783&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401145658730.png&#34; alt=&#34;image-20200401145658730&#34;&gt;&lt;/p&gt;
&lt;p&gt;参考：https://cloud.google.com/vision?hl=zh-cn&lt;/p&gt;
&lt;h3 id=&#34;试用&#34;&gt;试用&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401142058025.png&#34; alt=&#34;image-20200401142058025&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;安全搜索的分类说明&#34;&gt;安全搜索的分类说明&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401144423857.png&#34; alt=&#34;image-20200401144423857&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Adult 成人内容&lt;/li&gt;
&lt;li&gt;Spoof 恶搞，比如恶搞政治人物&lt;/li&gt;
&lt;li&gt;Medical 医疗影像&lt;/li&gt;
&lt;li&gt;Violence 暴力内容&lt;/li&gt;
&lt;li&gt;Racy 猥亵类，类似成人内容&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;参考：https://cloud.google.com/vision/docs/reference/rpc/google.cloud.vision.v1?hl=zh-cn#google.cloud.vision.v1.SafeSearchAnnotation&lt;/p&gt;
&lt;h3 id=&#34;对接流程&#34;&gt;对接流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401143626559.png&#34; alt=&#34;image-20200401143626559&#34;&gt;&lt;/p&gt;
&lt;p&gt;参考：https://codelabs.developers.google.com/codelabs/cloud-vision-intro/index.html?index=..%2F..cloudai&amp;amp;hl=zh-cn&amp;amp;_ga=2.102874504.925825070.1585721382-1910642988.1585296097#0&lt;/p&gt;
&lt;p&gt;注意，图像不一定需要上传到Google的云存储。&lt;/p&gt;
&lt;p&gt;开发对接参考：检测露骨内容（安全搜索）https://cloud.google.com/vision/docs/detecting-safe-search?hl=zh-cn&lt;/p&gt;
&lt;h3 id=&#34;demo&#34;&gt;DEMO&lt;/h3&gt;
&lt;p&gt;创建服务账号、创建密钥，自动下载json文件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401160832697.png&#34; alt=&#34;image-20200401160832697&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200401161206429.png&#34; alt=&#34;image-20200401161206429&#34;&gt;&lt;/p&gt;
&lt;p&gt;code：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/GoogleCloudPlatform/golang-samples/blob/master/vision/detect/README.md&#34;&gt;https://github.com/GoogleCloudPlatform/golang-samples/blob/master/vision/detect/README.md&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;请求次数限制&#34;&gt;请求次数限制&lt;/h3&gt;
&lt;p&gt;对请求内容大小有限制外，需要注意请求配额，每分钟请求数1800，QPS也就是30。如果无法满足需求，需要在平台申请增加配额。&lt;/p&gt;
&lt;p&gt;使用默认配额，业务上需要考虑采样数据，再调用Vision API。&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://cloud.google.com/vision/quotas?hl=zh-cn&#34;&gt;https://cloud.google.com/vision/quotas?hl=zh-cn&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;请求响应时间&#34;&gt;请求响应时间&lt;/h3&gt;
&lt;p&gt;请求响应时间，取决于两个因素：&lt;/p&gt;
&lt;h4 id=&#34;上传数据大小&#34;&gt;上传数据大小&lt;/h4&gt;
&lt;p&gt;越大越慢。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;手机拍照软件生成的图像一般3M，建议图像压缩后上传。&lt;/li&gt;
&lt;li&gt;考虑gcloud上先存储图像文件。参考 &lt;a href=&#34;https://medium.com/bankify-tech-blog/how-to-optimize-the-speed-of-google-vision-api-cdc5e452104b&#34;&gt;https://medium.com/bankify-tech-blog/how-to-optimize-the-speed-of-google-vision-api-cdc5e452104b&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;vision-api本身&#34;&gt;Vision API本身&lt;/h4&gt;
&lt;p&gt;对一张249K的图像进行简单压测。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ll demo/trump.jpg 
-rw-r--r--  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; jiahua  staff   249K Apr  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; 14:14 demo/trump.jpg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Go benchmark。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;BenchmarkDetectSafeSearchForFile&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;testing&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;B&lt;/span&gt;) {
	&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;&lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;&amp;lt;&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;N&lt;/span&gt;;&lt;span style=&#34;color:#a6e22e&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;{
		&lt;span style=&#34;color:#a6e22e&#34;&gt;result&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;err&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;:=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;DetectSafeSearchForFile&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;demo/trump.jpg&amp;#34;&lt;/span&gt;)
		&lt;span style=&#34;color:#a6e22e&#34;&gt;assert&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Equal&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;, &lt;span style=&#34;color:#66d9ef&#34;&gt;nil&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;err&lt;/span&gt;)
		&lt;span style=&#34;color:#a6e22e&#34;&gt;spew&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Dump&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;result&lt;/span&gt;)
	}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;识别图像大概需要1秒。实际业务中使用，建议异步处理，事后处理，不然太影响正常体验了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ go test -v -bench&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;DetectSafeSearchForFile -benchtime&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;30s

BenchmarkDetectSafeSearchForFile-8            &lt;span style=&#34;color:#ae81ff&#34;&gt;33&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;1011378355&lt;/span&gt; ns/op
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;natural-language-api-文本内容识别&#34;&gt;Natural Language API： 文本内容识别&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.google.com/natural-language/docs/how-to?hl=zh-cn&#34;&gt;https://cloud.google.com/natural-language/docs/how-to?hl=zh-cn&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;内容分类&#34;&gt;内容分类&lt;/h3&gt;
&lt;p&gt;内容分类没有我们关注的敏感内容分类。&lt;/p&gt;
&lt;p&gt;参考：https://cloud.google.com/natural-language/docs/categories?hl=zh-cn&lt;/p&gt;
&lt;p&gt;通过简单的关键字过滤吧。&lt;/p&gt;
- https://xujiahua.github.io/posts/google-vision-api/ - </description>
        </item>
    
    
    
        <item>
        <title>使用 Docker Machine</title>
        <link>https://xujiahua.github.io/posts/use-docker-machine/</link>
        <pubDate>Tue, 31 Mar 2020 09:53:05 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/use-docker-machine/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/use-docker-machine/ -&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;Docker Machine lets you create Docker hosts on your computer, on cloud providers, and inside your own data center. It creates servers, installs Docker on them, then configures the Docker client to talk to them.&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/docker/machine&#34;&gt;https://github.com/docker/machine&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/machine/overview/&#34;&gt;https://docs.docker.com/machine/overview/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;../../images/machine.png&#34; alt=&#34;Docker Machine&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;vs-vagrant&#34;&gt;vs. Vagrant&lt;/h2&gt;
&lt;h3 id=&#34;与vagrant的交集&#34;&gt;与Vagrant的交集&lt;/h3&gt;
&lt;p&gt;目前使用 Vagrant 搭 Docker 环境的步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;vagrant init {box_name}，下载一个基础的虚拟机镜像，比如centos，并创建一个Vagrantfile。&lt;/li&gt;
&lt;li&gt;Vagrantfile中设置虚拟机hostname。&lt;/li&gt;
&lt;li&gt;Vagrantfile中设置Private network，使得几个VM可以互相通信。&lt;/li&gt;
&lt;li&gt;VM内安装docker软件。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果用上了docker-machine，只要一行命令。在这个场景上，docker-machine 比 Vagrant 方便了很多。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker-machine create -d virtualbox {host_name}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;VM的管理，vagrant命令需要在Vagrantfile所在目录执行。而docker-machine可以在任何目录管理VM。&lt;/p&gt;
&lt;h3 id=&#34;其他特色&#34;&gt;其他特色&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;通过其他driver，可以安装管理云主机或是私有数据中心，而不仅仅是virtualbox。&lt;/li&gt;
&lt;li&gt;通过eval &amp;ldquo;$(docker-machine env default)&amp;quot;，覆盖环境变量DOCKER_HOST，使得本地docker client访问VM内的docker daemon。&lt;/li&gt;
&lt;li&gt;更多实用命令，参考 &lt;a href=&#34;https://docs.docker.com/machine/get-started/&#34;&gt;https://docs.docker.com/machine/get-started/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/use-docker-machine/ - </description>
        </item>
    
    
    
        <item>
        <title>Consul调研</title>
        <link>https://xujiahua.github.io/posts/use-consul/</link>
        <pubDate>Thu, 26 Mar 2020 09:01:38 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/use-consul/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/use-consul/ -&lt;h2 id=&#34;consul简介&#34;&gt;Consul简介&lt;/h2&gt;
&lt;p&gt;Consul 是 HashiCorp 公司推出的开源分布式服务发现与配置系统。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务发现。特别是搭配Consul Connect（Service Mesh），可达到一种无侵入式的服务发现和客户端负载均衡。&lt;/li&gt;
&lt;li&gt;Key/Value 存储 作为配置中心。&lt;/li&gt;
&lt;li&gt;使用 Raft 算法来保证一致性。&lt;/li&gt;
&lt;li&gt;支持多数据中心。&lt;/li&gt;
&lt;li&gt;支持健康检查：服务注册的时候可以提供健康检查项，服务发现会过滤掉不健康的service。&lt;/li&gt;
&lt;li&gt;支持 http 和 dns 协议接口。&lt;/li&gt;
&lt;li&gt;Web 管理界面。&lt;/li&gt;
&lt;li&gt;没有长连接，轮询方式可能不够及时。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心概念&#34;&gt;核心概念&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;consul agent server：维护核心状态并参与leader选举。server节点一般建议3个或是5个，测试用1个即可。写压力大的集群，考虑升级服务器实例的配置和低延迟的存储。（&lt;strong&gt;TIP&lt;/strong&gt; For write-heavy clusters, consider scaling vertically with larger machine instances and lower latency storage. &lt;a href=&#34;https://learn.hashicorp.com/consul/datacenter-deploy/reference-architecture&#34;&gt;https://learn.hashicorp.com/consul/datacenter-deploy/reference-architecture&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;consul agent client：与其他agent联通，并消息中转。每个主机都有一个agent的好处是，只要与本地agent通信，不用设置CONSUL_HTTP_ADDR，代码也不用指定这个地址。方便无脑操作。(In a multi-agent Consul datacenter, each service would register with its local Consul client, and the clients would forward the registration to the Consul servers, which maintain the service catalog. &lt;a href=&#34;https://learn.hashicorp.com/consul/getting-started/services&#34;&gt;https://learn.hashicorp.com/consul/getting-started/services&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;node：一般是一个node一个agent。consul DNS name规则：{node_name}.node.consul&lt;/li&gt;
&lt;li&gt;service：一个service对应多个service实例，注册时使用相同的service_name，并使用不同的service_id区分实例。consul DNS name规则： {service_name}.service.consul&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;入门资料&#34;&gt;入门资料&lt;/h2&gt;
&lt;p&gt;此文就不做复读机了。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Getting Started 安装、运行Consul，使用Consul服务发现与配置读写 &lt;a href=&#34;https://learn.hashicorp.com/consul?track=getting-started#getting-started&#34;&gt;https://learn.hashicorp.com/consul?track=getting-started#getting-started&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;consul-服务发现&#34;&gt;Consul 服务发现&lt;/h2&gt;
&lt;h3 id=&#34;微服务与服务发现&#34;&gt;微服务与服务发现&lt;/h3&gt;
&lt;p&gt;从单体应用拆分为微服务，虽然有诸多好处比如不同发布周期的模块拆分平衡了系统稳定性和发布频率，但天下没有免费的午餐。&lt;/p&gt;
&lt;p&gt;以服务发现这个角度看：原来的函数级调用，变成了网络服务级调用。怎么找到网络服务，即其IP+port呢。&lt;/p&gt;
&lt;p&gt;几种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置在静态文件。不建议使用，无法应对动态增减服务实例的场景。&lt;/li&gt;
&lt;li&gt;还是配置在静态文件，但配置的是一个负载均衡器比如nginx的地址。其实就是把动态增减服务实例的问题转嫁到了负载均衡器上。调用方也少了做负载均衡的工作。关于nginx处理动态增减服务实例的解决方案，可以参考下节「实践：基于consul的nginx动态upstream」。&lt;/li&gt;
&lt;li&gt;从某中心服务器取，或是轮询或是被通知的方式知道了最新的服务地址。consul 就是这里的中心服务器（集群）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200326114005444.png&#34; alt=&#34;image-20200326114005444&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;服务注册&#34;&gt;服务注册&lt;/h3&gt;
&lt;p&gt;Consul有2种方式注册服务：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;consul命令&lt;/li&gt;
&lt;li&gt;HTTP请求&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;健康检查&#34;&gt;健康检查&lt;/h3&gt;
&lt;p&gt;DNS解析或是HTTP取的方式服务发现，只返回通过健康检查的实例。也就是没通过check的服务实例，不会出现，不担心拿到”脏“服务。&lt;/p&gt;
&lt;p&gt;如果服务没有加入健康检查项，默认是健康的。加入健康检查是非常有必要的。还可以设置自动注销，一直不通过检查，就注销该服务实例。&lt;/p&gt;
&lt;h3 id=&#34;服务发现&#34;&gt;服务发现&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;DNS解析&lt;/li&gt;
&lt;li&gt;HTTP请求&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;示例代码&#34;&gt;示例代码&lt;/h3&gt;
&lt;p&gt;参考文章：基于consul构建golang系统分布式服务发现机制 &lt;a href=&#34;https://segmentfault.com/a/1190000008471221&#34;&gt;https://segmentfault.com/a/1190000008471221&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;简单介绍下，使用Consul HTTP API（有Golang的封装包），进行服务注册和服务发现。&lt;/p&gt;
&lt;h3 id=&#34;一些问题&#34;&gt;一些问题&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;服务注册、服务发现都在业务代码中。能不能让业务程序无感知？&lt;/li&gt;
&lt;li&gt;对于服务调用方来说，需要自己处理负载均衡。貌似也能通过共享库的方式解决。是否能把这些重复逻辑下沉到基础设施层面？&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Service Discovery  &lt;a href=&#34;https://learn.hashicorp.com/consul/getting-started/services&#34;&gt;https://learn.hashicorp.com/consul/getting-started/services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;基于consul构建golang系统分布式服务发现机制 &lt;a href=&#34;https://segmentfault.com/a/1190000008471221&#34;&gt;https://segmentfault.com/a/1190000008471221&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;实践基于consul的nginx动态upstream&#34;&gt;实践：基于consul的nginx动态upstream&lt;/h2&gt;
&lt;p&gt;以下两种实践参考这个youtube视频：https://www.youtube.com/watch?v=KgTtQnXrnMk。简单提重点。&lt;/p&gt;
&lt;h3 id=&#34;使用-consul-dns接口&#34;&gt;使用 consul DNS接口&lt;/h3&gt;
&lt;p&gt;nginx的resolver关键字指定consul的DNS地址：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/130267C9-FCE9-4543-9152-C0C1F89DCAB3.png&#34; alt=&#34;130267C9-FCE9-4543-9152-C0C1F89DCAB3&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;使用-consul-template--动态生成upstream文件&#34;&gt;使用 consul-template  动态生成upstream文件&lt;/h3&gt;
&lt;p&gt;创建模板：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200326104914256.png&#34; alt=&#34;image-20200326104914256&#34;&gt;&lt;/p&gt;
&lt;p&gt;在模板中定义upstream：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/5A462C56-1A76-4222-8C7A-4041E2775F98.png&#34; alt=&#34;5A462C56-1A76-4222-8C7A-4041E2775F98&#34;&gt;&lt;/p&gt;
&lt;p&gt;根据consul配置信息，刷新nginx配置（然后nginx reload，并自行配置定时刷新周期）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/3C4C8A0F-B629-4215-84FB-2C4D86344FDE.png&#34; alt=&#34;3C4C8A0F-B629-4215-84FB-2C4D86344FDE&#34;&gt;&lt;/p&gt;
&lt;p&gt;业务程序如果也支持动态reload，业务程序的服务发现也能像以上nginx的做法一样。&lt;/p&gt;
&lt;h4 id=&#34;参考-1&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;consul-template &lt;a href=&#34;https://learn.hashicorp.com/consul/developer-configuration/consul-template&#34;&gt;https://learn.hashicorp.com/consul/developer-configuration/consul-template&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Manage local application configuration files using templates and data from etcd or consul 与consul-template的思路是一样的 &lt;a href=&#34;https://github.com/kelseyhightower/confd&#34;&gt;https://github.com/kelseyhightower/conf&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;使用-nginx-module&#34;&gt;使用 nginx module&lt;/h3&gt;
&lt;p&gt;An nginx module for setting backends from Consul services.  &lt;a href=&#34;https://github.com/hashicorp/ngx_http_consul_backend_module&#34;&gt;https://github.com/hashicorp/ngx_http_consul_backend_module&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;service-mesh-简单介绍&#34;&gt;Service Mesh 简单介绍&lt;/h2&gt;
&lt;p&gt;Service Mesh是微服务治理的一种模式。&lt;/p&gt;
&lt;p&gt;核心理念就是将业务逻辑无关的代码下沉到基础设施。&lt;/p&gt;
&lt;p&gt;Service Mesh 的代理实例会完成完整的服务间通信的调用流程，如服务发现、负载均衡等基本功能，熔断、限流、重试等容错功能，以及各种高级路由功能，安全方面的认证、授权、鉴权、加密等，最后将请求发送给目标服务。最终表现为Sidecar模式，实现和传统类库类似甚至比传统类库更完备的功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/service-mesh-generic-topology_social.png&#34; alt=&#34;“Service Mesh”的图片搜索结果&#34;&gt;&lt;/p&gt;
&lt;p&gt;（来源互联网）&lt;/p&gt;
&lt;p&gt;sidecar是一种不侵入代码的方式，sidecar服务劫持了原服务的流量，sidecar服务与原服务之间使用lo网卡通信。 Connect proxies are typically deployed as &amp;ldquo;sidecars&amp;rdquo; that run on the same node as the single service instance that they handle traffic for. They might be on the same VM or running as a separate container in the same network namespace.   &lt;a href=&#34;https://www.consul.io/docs/connect/registration/sidecar-service.html&#34;&gt;https://www.consul.io/docs/connect/registration/sidecar-service.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Service Mesh比较成熟的技术有&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Istio：理论上是平台无关的，但实际上，与Kubernetes绑定比较紧密。&lt;/li&gt;
&lt;li&gt;Consul Connect：与Kubernetes没那么强的绑定了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;consul-connect&#34;&gt;Consul Connect&lt;/h2&gt;
&lt;p&gt;Consul Connect是Service Mesh模式的实现。可以理解为Consul服务发现的升级版。&lt;/p&gt;
&lt;p&gt;服务包括sidecar服务的注册只是个注册，实际的进程需要开发者自己创建的。Sidecar service registrations are only a shorthand for registering multiple services. Consul will not start up or manage the actual proxy processes for you. &lt;a href=&#34;https://www.consul.io/docs/connect/registration/sidecar-service.html&#34;&gt;https://www.consul.io/docs/connect/registration/sidecar-service.html&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;示例-consul-101&#34;&gt;示例 consul-101&lt;/h3&gt;
&lt;p&gt;这个例子。https://github.com/hashicorp/demo-consul-101&lt;/p&gt;
&lt;p&gt;简单说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;consul agent -dev -config-dir=&amp;quot;./demo-config-localhost&amp;quot; -node=laptop&lt;/code&gt; 这里已经完成了service和proxy的注册。这个可以后续脚本化，按需服务注册。&lt;/li&gt;
&lt;li&gt;service本身都不做服务发现和负载均衡。这些事情交给了 sidecar proxy。以dashboard service为例，&lt;code&gt;countingServiceURL = getEnvOrDefault(&amp;quot;COUNTING_SERVICE_URL&amp;quot;, &amp;quot;http://localhost:9001&amp;quot;)&lt;/code&gt;，默认读的是本地的9001端口，也就是proxy的绑定端口。这就是劫持流量。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consul connect proxy -sidecar-for counting-1&lt;/code&gt; 需要手动为service创建proxy。这个可以后续脚本化。&lt;/li&gt;
&lt;li&gt;能看出Consul Connect /Service Mesh的好处了：不再侵入业务代码。重复的事情已下沉到基础设施，sidecar proxy处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;基于-consul-connect-的服务发现思路整理&#34;&gt;基于 Consul Connect 的服务发现思路整理&lt;/h3&gt;
&lt;p&gt;非K8S环境。其中调用方为dashboard，被调用方为counting。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;网络内的所有主机都安装了consul，或是server，或是client。&lt;/li&gt;
&lt;li&gt;基于Consul命令行工具和Consul Connect的能力，让服务注册及服务发现不侵入业务代码。&lt;/li&gt;
&lt;li&gt;counting服务注册流程：准备以下脚本并执行。脚本主要做三件事情。&lt;/li&gt;
&lt;li&gt;1）启动counting服务。counting服务对consul无感知。&lt;strong&gt;这里端口可以是动态的&lt;/strong&gt;，只要让脚本第二步知道即可。&lt;/li&gt;
&lt;li&gt;2）向本地consul注册服务包括sidecar proxy，包括两个服务的健康检查，需要的信息有当前主机IP地址、应用端口等（consul client会转发到consul server的）。&lt;/li&gt;
&lt;li&gt;3）本地创建sidecar proxy服务实例。&lt;/li&gt;
&lt;li&gt;Consul接到counting服务注册后，开始定期健康检查。&lt;/li&gt;
&lt;li&gt;dashboard服务注册流程：与counting服务类似，但是加入了counting proxy upstream部分。比如 &lt;a href=&#34;https://github.com/hashicorp/demo-consul-101/blob/master/demo-config-localhost/dashboard.json#L7&#34;&gt;https://github.com/hashicorp/demo-consul-101/blob/master/demo-config-localhost/dashboard.json#L7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;dashboard服务访问counting服务流程。&lt;/li&gt;
&lt;li&gt;1）dashboard与本地sidecar通信。&lt;/li&gt;
&lt;li&gt;2）dashboard sidecar负载均衡，选择一个counting服务。&lt;/li&gt;
&lt;li&gt;3）dashboard sidecar与counting sidecar通信。&lt;/li&gt;
&lt;li&gt;4）counting sidecar与counting服务通信。&lt;/li&gt;
&lt;li&gt;5）response，同一个通信链路原路返回。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200326120134716.png&#34; alt=&#34;image-20200326120134716&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;consul-connect-with-envoy&#34;&gt;Consul Connect with Envoy&lt;/h2&gt;
&lt;p&gt;生产环境，sidecar proxy使用Envoy。Consul comes with a L4 proxy for testing purposes, and first-class support for Envoy, which you should use for production deployments and layer 7 traffic management.&lt;/p&gt;
&lt;h3 id=&#34;envoy&#34;&gt;Envoy&lt;/h3&gt;
&lt;p&gt;Envoy编译貌似很复杂。可以把envoy编译产物从镜像里copy出来。 Envoy is only distributed as a Docker image.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://learn.hashicorp.com/consul/developer-mesh/connect-services&#34;&gt;https://learn.hashicorp.com/consul/developer-mesh/connect-services&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;demo-todo&#34;&gt;DEMO TODO&lt;/h3&gt;
&lt;h2 id=&#34;配置中心&#34;&gt;配置中心&lt;/h2&gt;
&lt;p&gt;Service Configuratio 配置文件序列化并存入consul kv  &lt;a href=&#34;https://learn.hashicorp.com/consul/getting-started/kv&#34;&gt;https://learn.hashicorp.com/consul/getting-started/kv&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;viper-remote&#34;&gt;viper remote&lt;/h3&gt;
&lt;p&gt;viper支持从consul/etcd取配置信息。 &lt;a href=&#34;https://github.com/spf13/viper#remote-keyvalue-store-support&#34;&gt;https://github.com/spf13/viper#remote-keyvalue-store-support&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;consul/etcd没有长连接啊，没有通知，只能定时轮询。Viper内置的库也是HTTP请求。每5秒，去取下最新的配置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/249E330D-4932-4EC4-BB01-A9E3931D3301.png&#34; alt=&#34;249E330D-4932-4EC4-BB01-A9E3931D3301&#34;&gt;&lt;/p&gt;
- https://xujiahua.github.io/posts/use-consul/ - </description>
        </item>
    
    
    
        <item>
        <title>Docker Network小结</title>
        <link>https://xujiahua.github.io/posts/docker-network/</link>
        <pubDate>Sat, 21 Mar 2020 14:10:40 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/docker-network/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/docker-network/ -&lt;p&gt;Docker网络非常值得学习。对Docker不熟的同学，建议先看一些入门资料。&lt;/p&gt;
&lt;h2 id=&#34;docker-学习资料&#34;&gt;Docker 学习资料&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Docker — 从入门到实践  &lt;a href=&#34;https://www.yuque.com/grasilife/docker&#34;&gt;https://www.yuque.com/grasilife/docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Docker Kubernetes Lab Handbook &lt;a href=&#34;https://docker-k8s-lab.readthedocs.io/en/latest/index.html&#34;&gt;https://docker-k8s-lab.readthedocs.io/en/latest/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;「Docker进阶与实战」华为Docker实践小组&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;单机网络&#34;&gt;单机网络&lt;/h2&gt;
&lt;p&gt;（建议在Linux系统上实验。）&lt;/p&gt;
&lt;p&gt;Docker安装完后，默认有三个（三种）网络。分别是默认的bridge模式，host模式，none模式。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
51cbe7a9bb19        bridge              bridge              local
7182ef9fa8c4        host                host                local
bd80d0dedaa8        none                null                local
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;参考：https://docs.docker.com/network/&lt;/p&gt;
&lt;h3 id=&#34;none模式---netnone&#34;&gt;none模式 &amp;ndash;net=none&lt;/h3&gt;
&lt;p&gt;无网络。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# docker run --net=none --rm -it alpine ip addr show
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;host模式---nethost&#34;&gt;host模式 &amp;ndash;net=host&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;容器共用宿主机的网络。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。&lt;/li&gt;
&lt;li&gt;容器不会申请独立的IP。&lt;/li&gt;
&lt;li&gt;容器申请的端口占用宿主机的端口资源。&lt;/li&gt;
&lt;li&gt;-p等端口映射命令不起作用：WARNING: Published ports are discarded when using host network mode&lt;/li&gt;
&lt;li&gt;性能上比较好，因为没有地址转换。Host mode networking can be useful to optimize performance, and in situations where a container needs to handle a large range of ports, as it does not require network address translation (NAT), and no “userland-proxy” is created for each port.&lt;/li&gt;
&lt;li&gt;Linux ONLY。The host networking driver only works on Linux hosts, and is not supported on Docker Desktop for Mac, Docker Desktop for Windows, or Docker EE for Windows Server.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;../../images/907596-20170517105727775-430532496.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/network/host/&#34;&gt;https://docs.docker.com/network/host/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Networking using the host network &lt;a href=&#34;https://docs.docker.com/network/network-tutorial-host/&#34;&gt;https://docs.docker.com/network/network-tutorial-host/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;实验&#34;&gt;实验&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# docker run --net=host --rm -it alpine ip addr show
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eno1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP qlen 1000
    link/ether 10:7b:44:b0:b1:37 brd ff:ff:ff:ff:ff:ff
    inet 192.168.0.106/24 brd 192.168.0.255 scope global dynamic eno1
       valid_lft 6663sec preferred_lft 6663sec
    inet6 fe80::e0c5:55dc:fba0:549b/64 scope link
       valid_lft forever preferred_lft forever
5: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN
    link/ether 02:42:8c:6e:08:4d brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:8cff:fe6e:84d/64 scope link
       valid_lft forever preferred_lft forever

# ip addr show
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: eno1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 10:7b:44:b0:b1:37 brd ff:ff:ff:ff:ff:ff
    inet 192.168.0.106/24 brd 192.168.0.255 scope global dynamic noprefixroute eno1
       valid_lft 6619sec preferred_lft 6619sec
    inet6 fe80::e0c5:55dc:fba0:549b/64 scope link noprefixroute
       valid_lft forever preferred_lft forever
5: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN group default
    link/ether 02:42:8c:6e:08:4d brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:8cff:fe6e:84d/64 scope link
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;容器只是隔离除了网络之外的资源。因为使用了宿主机的网络，所以容器进程可以与其他主机进程互相通信。需要注意的是端口冲突的问题，以及安全的问题（共用了宿主机的资源）。&lt;/p&gt;
&lt;h3 id=&#34;bridge模式---netname_it_youself&#34;&gt;bridge模式 &amp;ndash;net={name_it_youself}&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Docker默认的网络模式。不加&amp;ndash;net参数，就默认采用这种网络模式。&lt;/li&gt;
&lt;li&gt;一个独立的虚拟网络。&lt;/li&gt;
&lt;li&gt;宿主机网络对容器网络是无感知的，需要让容器的进程端口映射到宿主机的端口上，同样，映射需要注意端口冲突的问题。&lt;/li&gt;
&lt;li&gt;每个Container都有一个独立的IP。&lt;code&gt;docker network inspect bridge&lt;/code&gt; 可查看。&lt;/li&gt;
&lt;li&gt;同一个虚拟网络下的容器可以互相通信。&lt;/li&gt;
&lt;li&gt;容器可与宿主机通信。&lt;/li&gt;
&lt;li&gt;容器可通过宿主机与其他网络通信。只要宿主机能到，容器就能到。有点像是VMWare中的NAT模式。同样叫bridge，VMWare的bridge模式跟Docker bridge完全不同。&lt;/li&gt;
&lt;li&gt;创建一个新的bridge，就是创建了一个新的子网。&lt;code&gt;docker network create -d bridge my_bridge&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;桥接网络只对一个Docker daemon host上的容器管用，多机就不行了，docker-compose也只能在单机上跑，生产没法用。Bridge networks apply to containers running on the &lt;strong&gt;same Docker daemon host&lt;/strong&gt;. For communication among containers running on different Docker daemon hosts, you can either manage routing at the OS level, or you can use an overlay network.&lt;/li&gt;
&lt;li&gt;建议使用自定义的bridge网络。&lt;/li&gt;
&lt;li&gt;最实用的，自定义网络可以通过容器名称而不是IP与其他容器通信，而默认网络只能通过IP。User-defined bridges provide automatic DNS resolution between containers.&lt;/li&gt;
&lt;li&gt;User-defined bridges provide better isolation.&lt;/li&gt;
&lt;li&gt;Containers can be attached and detached from user-defined networks on the fly.&lt;/li&gt;
&lt;li&gt;网络拓扑如下。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;../../images/bridge_network.jpg&#34; alt=&#34;“docker bridge network”的图片搜索结果&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;参考-1&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/network/bridge/&#34;&gt;https://docs.docker.com/network/bridge/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Networking with standalone containers &lt;a href=&#34;https://docs.docker.com/network/network-tutorial-standalone/&#34;&gt;https://docs.docker.com/network/network-tutorial-standalone/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;实验-1&#34;&gt;实验&lt;/h4&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;容器模式---netcontainerbase_container&#34;&gt;容器模式 &amp;ndash;net=container:base_container&lt;/h3&gt;
&lt;p&gt;共用其他容器的网络栈，其他资源容器隔离。这个在Service Mesh的场景下非常有用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/907596-20170517110100869-2022531474.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;实验-2&#34;&gt;实验&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;# docker run -it --name=base_container alpine /bin/ash
/ # ip addr show
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
8: eth0@if9: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
       

# docker run --net=container:base_container --rm -it alpine ip addr show
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
8: eth0@if9: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue state UP
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever

&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;跨主机网络&#34;&gt;跨主机网络&lt;/h2&gt;
&lt;p&gt;github上搜索有关Container networking的项目。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200330115410819.png&#34; alt=&#34;image-20200330115410819&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;docker-overlay&#34;&gt;Docker Overlay&lt;/h3&gt;
&lt;p&gt;官方提供的方案。之前是需要etcd辅助的。Docker Engine 1.12 integrated the control plane state into Docker Engine so that an external store is no longer required.&lt;/p&gt;
&lt;h3 id=&#34;weave&#34;&gt;Weave&lt;/h3&gt;
&lt;p&gt;Weave Net creates a virtual network that connects Docker containers across multiple hosts and enables their automatic discovery.  参考：https://www.weave.works/docs/net/latest/overview/&lt;/p&gt;
&lt;p&gt;原理是所有容器都连入一个虚拟网络 weave network，所有加入这个网络的容器都有一块weave网卡。要求每台宿主机启动weave。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/weave1.png&#34; alt=&#34;使用Weave 实现Docker 多宿主机互联- 运维之美&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;实验-3&#34;&gt;实验&lt;/h4&gt;
&lt;p&gt;实验参考：https://www.weave.works/docs/net/latest/install/using-weave/&lt;/p&gt;
&lt;p&gt;Docker可以通过插件形式来集成其他网络驱动。看说明weave说明，这种只适合Swarm模式。所以我们实验不采用这种方式。Before using the plugin, please keep in mind the plugin works only in Swarm mode and requires Docker version 1.13 or later. &lt;a href=&#34;https://www.weave.works/docs/net/latest/install/plugin/plugin-v2/&#34;&gt;https://www.weave.works/docs/net/latest/install/plugin/plugin-v2/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;虚拟机环境搭建，创建两台虚拟机。注意在同一个网络下。参考：https://www.vagrantup.com/docs/networking/private_network.html&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vagrant init centos/7
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;（快速）安装Docker。参考：https://www.yuque.com/grasilife/docker/install-centos#ccbf609c&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl -fsSL get.docker.com -o get-docker.sh
# sh get-docker.sh --mirror Aliyun
# systemctl enable docker
# systemctl start docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;安装weave。参考：https://www.weave.works/docs/net/latest/install/installing-weave/&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# curl -L git.io/weave -o /usr/bin/weave
# chmod a+x /usr/bin/weave
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;weave网络启动，网络的分配将有weave来处理。&lt;code&gt;eval $(weave env)&lt;/code&gt; 覆盖了 DOCKER_HOST 为 unix:///var/run/weave/weave.sock。相当于劫持了docker客户端与docker daemon的通信。参考：https://www.youtube.com/watch?v=kihQCCT1ykE&amp;amp;feature=youtu.be&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@host2 vagrant]# weave launch
[root@host2 vagrant]# eval $(weave env)

# join host2
[root@host1 vagrant]# weave launch $host2
[root@host1 vagrant]# eval $(weave env)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;连通测试。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# start tcp server on container in host2
[root@host2 vagrant]# docker run --name hello busybox nc -lp 8888

# ping from container in host1 to container in host2
[root@host1 vagrant]# docker run --rm -it busybox ping hello
PING hello (10.32.0.1): 56 data bytes
64 bytes from 10.32.0.1: seq=0 ttl=64 time=3.936 ms
64 bytes from 10.32.0.1: seq=1 ttl=64 time=0.616 ms

# tcp test from container in host1 to container in host2
[root@host1 vagrant]# docker run --rm -it busybox sh
/ # echo &amp;quot;hello world!&amp;quot; | nc hello 8888
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;查看容器网卡，能看到ethwe网卡，与weave有关。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@host2 vagrant]# docker run --rm busybox ip addr
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
41: eth0@if42: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
43: ethwe@if44: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1376 qdisc noqueue
    link/ether ca:97:90:14:18:5e brd ff:ff:ff:ff:ff:ff
    inet 10.32.0.2/12 brd 10.47.255.255 scope global ethwe
       valid_lft forever preferred_lft forever

[root@host1 vagrant]# docker run --rm busybox ip addr
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
29: eth0@if30: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1500 qdisc noqueue
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
31: ethwe@if32: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1376 qdisc noqueue
    link/ether da:f2:40:0a:1e:d7 brd ff:ff:ff:ff:ff:ff
    inet 10.44.0.0/12 brd 10.47.255.255 scope global ethwe
       valid_lft forever preferred_lft forever
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;总结下weave特点&#34;&gt;总结下Weave特点&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;通过劫持Docker client与daemon的方式工作。&lt;/li&gt;
&lt;li&gt;创建容器的请求被劫持，weave为容器注入了weave网络。&lt;/li&gt;
&lt;li&gt;不依赖etcd或是consul等kv数据库。&lt;/li&gt;
&lt;li&gt;集群扩容，增加宿主机，需要将宿主机配置为weave节点。&lt;/li&gt;
&lt;li&gt;容器部署，根据资源利用率，部署到哪个宿主机节点。没有容器编排工具，比如Kubernetes，还是挺不方便的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;flannel&#34;&gt;Flannel&lt;/h3&gt;
&lt;p&gt;Flannel为每个host分配一个subnet，容器从subnet中分配IP，这些IP可以在host间路由，容器间无需使用nat和端口映射即可实现跨主机通信。每个subnet都是从一个更大的IP池中划分的，flannel会在每个主机上运flanneld的agent，负责从池子中分配subnet。&lt;/p&gt;
&lt;p&gt;Flannel使用etcd存放网络配置、已分配的subnet、host的IP等信息，Flannel数据包在主机间转发是由backend实现的，目前已经支持UDP、VxLAN、host-gw、AWS VPC和GCE路由等多种backend。https://www.cnblogs.com/itzgr/p/10172004.html&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/docker-flannel.png&#34; alt=&#34;../_images/docker-flannel.png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;实验-4&#34;&gt;实验&lt;/h4&gt;
&lt;p&gt;使用docker-machine创建了三台虚拟机。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;节点&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;etcd&lt;/td&gt;
&lt;td&gt;192.168.99.105&lt;/td&gt;
&lt;td&gt;安装etcd&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node01&lt;/td&gt;
&lt;td&gt;192.168.99.108&lt;/td&gt;
&lt;td&gt;安装docker, flannel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node02&lt;/td&gt;
&lt;td&gt;192.168.99.109&lt;/td&gt;
&lt;td&gt;安装docker, flannel&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multi-Host Networking Overlay with Flannel &lt;a href=&#34;https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html&#34;&gt;https://docker-k8s-lab.readthedocs.io/en/latest/docker/docker-flannel.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Running flannel &lt;a href=&#34;https://github.com/coreos/flannel/blob/master/Documentation/running.md&#34;&gt;https://github.com/coreos/flannel/blob/master/Documentation/running.md&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;etcd集群搭建，需要兼容etcd2，因为flannel依赖etcd2。https://github.com/coreos/flannel/issues/1191&lt;/p&gt;
&lt;p&gt;配置一个网段，写入etcd。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker@etcd01:~$ etcd -listen-client-urls=&amp;quot;http://0.0.0.0:2379&amp;quot; --advertise-client-urls=&amp;quot;http://192.168.99.105:2379&amp;quot; --enable-v2

docker@etcd01:~$ ETCDCTL_API=2 etcdctl set /coreos.com/network/config &#39;{ &amp;quot;Network&amp;quot;: &amp;quot;10.5.0.0/16&amp;quot;, &amp;quot;Backend&amp;quot;: {&amp;quot;Type&amp;quot;: &amp;quot;vxlan&amp;quot;}}&#39;

docker@etcd01:~$ ETCDCTL_API=2 etcdctl get /coreos.com/network/config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;flanneld会读取etcd配置，并为该主机分配子网段。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@node01:~# ./flanneld-amd64 -etcd-endpoints=&amp;quot;http://192.168.99.105:2379&amp;quot; -iface=192.168.99.108
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;root@node02:~# ./flanneld-amd64 -etcd-endpoints=&amp;quot;http://192.168.99.105:2379&amp;quot; -iface=192.168.99.109
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以看到，主机上有了新网卡，子网段也会写入etcd。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker@etcd01:~$ ETCDCTL_API=2 etcdctl ls /coreos.com/network/subnets
/coreos.com/network/subnets/10.5.94.0-24
/coreos.com/network/subnets/10.5.90.0-24
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置docker daemon参数，boot2docker linux配置如下：参考 &lt;a href=&#34;https://github.com/boot2docker/boot2docker/issues/508&#34;&gt;https://github.com/boot2docker/boot2docker/issues/508&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;node01重新配置docker daemon：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@node01:~# /etc/init.d/docker stop
Stopping dockerd (5350)

root@node01:~# source /run/flannel/subnet.env

root@node01:~# echo EXTRA_ARGS=\&amp;quot;--bip=${FLANNEL_SUBNET} --mtu=${FLANNEL_MTU}\&amp;quot; &amp;gt;&amp;gt; /var/lib/boot2docker/profile
root@node01:~# cat /var/lib/boot2docker/profile

EXTRA_ARGS=&#39;
--label provider=virtualbox

&#39;
CACERT=/var/lib/boot2docker/ca.pem
DOCKER_HOST=&#39;-H tcp://0.0.0.0:2376&#39;
DOCKER_STORAGE=overlay2
DOCKER_TLS=auto
SERVERKEY=/var/lib/boot2docker/server-key.pem
SERVERCERT=/var/lib/boot2docker/server.pem

EXTRA_ARGS=&amp;quot;--bip=10.5.94.1/24 --mtu=1450&amp;quot;

root@node01:~# /etc/init.d/docker start
Starting dockerd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;node02重新配置docker daemon：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@node02:~# /etc/init.d/docker stop
Stopping dockerd (2624)

root@node02:~# source /run/flannel/subnet.env

root@node02:~# echo EXTRA_ARGS=\&amp;quot;--bip=${FLANNEL_SUBNET} --mtu=${FLANNEL_MTU}\&amp;quot; &amp;gt;&amp;gt; /var/lib/boot2docker/profile
root@node02:~# cat /var/lib/boot2docker/profile

EXTRA_ARGS=&#39;
--label provider=virtualbox

&#39;
CACERT=/var/lib/boot2docker/ca.pem
DOCKER_HOST=&#39;-H tcp://0.0.0.0:2376&#39;
DOCKER_STORAGE=overlay2
DOCKER_TLS=auto
SERVERKEY=/var/lib/boot2docker/server-key.pem
SERVERCERT=/var/lib/boot2docker/server.pem


EXTRA_ARGS=&amp;quot;--bip=10.5.90.1/24 --mtu=1450&amp;quot;

root@node02:~# /etc/init.d/docker start
Starting dockerd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;连通测试：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@node01:~# docker run -it busybox
/ # ip a
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: sit0@NONE: &amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
10: eth0@if11: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1450 qdisc noqueue
    link/ether 02:42:0a:05:5e:02 brd ff:ff:ff:ff:ff:ff
    inet 10.5.94.2/24 brd 10.5.94.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # nc -lp 8888

root@node02:~# docker run -it busybox
/ # ip a
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
2: sit0@NONE: &amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop qlen 1000
    link/sit 0.0.0.0 brd 0.0.0.0
10: eth0@if11: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&amp;gt; mtu 1450 qdisc noqueue
    link/ether 02:42:0a:05:5a:02 brd ff:ff:ff:ff:ff:ff
    inet 10.5.90.2/24 brd 10.5.90.255 scope global eth0
       valid_lft forever preferred_lft forever
/ # echo &amp;quot;hello world!&amp;quot; | nc 10.5.94.2 8888
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;总结flannel特点&#34;&gt;总结Flannel特点&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;依赖etcd2，在Kubernetes环境里依赖Kubernetes API（封装etcd）。存储网段与路由表？&lt;/li&gt;
&lt;li&gt;不侵入docker容器。这是比weave优雅的地方。&lt;/li&gt;
&lt;li&gt;整体思路，先划分一个大的网段，为每台加入的主机从大的网段里分配小的网段，为docker容器从小网段里分配IP。&lt;/li&gt;
&lt;/ol&gt;
- https://xujiahua.github.io/posts/docker-network/ - </description>
        </item>
    
    
    
        <item>
        <title>Go Web 项目框架</title>
        <link>https://xujiahua.github.io/posts/go-web-project/</link>
        <pubDate>Fri, 20 Mar 2020 15:24:22 +0800</pubDate>
        
        <guid>https://xujiahua.github.io/posts/go-web-project/</guid>
        <description>许嘉华的博客 https://xujiahua.github.io/posts/go-web-project/ -&lt;h2 id=&#34;常用开源库&#34;&gt;常用开源库&lt;/h2&gt;
&lt;h3 id=&#34;依赖包管理-go-modules&#34;&gt;依赖包管理 Go Modules&lt;/h3&gt;
&lt;p&gt;Go Modules。Go 从1.11版本开始支持，Go 1.14被认为是生产可用了。个人用过最方便的Go依赖包管理工具了。&lt;/p&gt;
&lt;p&gt;版本管理中维护 &lt;code&gt;go.mod&lt;/code&gt;/&lt;code&gt;go.sum&lt;/code&gt; 两个文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200320152954581.png&#34; alt=&#34;image-20200320152954581&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Using Go Modules &lt;a href=&#34;https://blog.golang.org/using-go-modules&#34;&gt;https://blog.golang.org/using-go-modules&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;命令行框架-corba&#34;&gt;命令行框架 Corba&lt;/h3&gt;
&lt;p&gt;Corba。第一次看到，是在翻看 Hyperledger Fabric 的时候。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/ad566232-814f-11e5-9cd0-aa101788c117.png&#34; alt=&#34;cobra logo&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;子命令，嵌套的子命令。&lt;/li&gt;
&lt;li&gt;增强版本的flags。&lt;/li&gt;
&lt;li&gt;项目模板的生成工具。&lt;/li&gt;
&lt;li&gt;生成工具也自动引入了Viper这个包。Corba与Viper由一个作者开发，两个项目配合使用非常方便。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;建议使用Cobra命令行工具生成项目模板。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  ▾ appName/
    ▾ cmd/
        add.go
        your.go
        commands.go
        here.go
      main.go
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;参考-1&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;A Commander for modern Go CLI interactions &lt;a href=&#34;https://github.com/spf13/cobra&#34;&gt;https://github.com/spf13/cobra&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cobra Generator &lt;a href=&#34;https://github.com/spf13/cobra/blob/master/cobra/README.md&#34;&gt;https://github.com/spf13/cobra/blob/master/cobra/README.md&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;配置管理-viper&#34;&gt;配置管理 Viper&lt;/h3&gt;
&lt;p&gt;Viper。常常与Corba搭配使用。抄一段官方简介：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/998df88a-8151-11e5-9448-4736db51020d.png&#34; alt=&#34;viper logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;Viper is a complete configuration solution for Go applications including 12-Factor apps. It is designed to work within an application, and can handle all types of configuration needs and formats. It supports:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;setting defaults 设置默认值。示例：&lt;code&gt;viper.SetDefault(&amp;quot;subject&amp;quot;, &amp;quot;World&amp;quot;)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;reading from JSON, TOML, YAML, HCL, envfile and Java properties config files 支持各种配置文件格式，TOML比较合我口味。在使用viper之前的配置文件读取方式，一般都是配置文件对应一个Go的model，通过反序列化读入程序。现在看来非常粗糙。&lt;/li&gt;
&lt;li&gt;live watching and re-reading of config files (optional)&lt;/li&gt;
&lt;li&gt;reading from environment variables 读取环境变量。代码和配置严格分离，配置文件算是一种不错的选择，12-Factor更推荐将应用的配置存储于环境变量中，参考：https://12factor.net/zh_cn/config&lt;/li&gt;
&lt;li&gt;reading from remote config systems (etcd or Consul), and watching changes 读配置中心。&lt;/li&gt;
&lt;li&gt;reading from command line flags 示例：&lt;code&gt;viper.BindPFlag(&amp;quot;subject&amp;quot;, helloCmd.Flags().Lookup(&amp;quot;subject&amp;quot;))&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;reading from buffer&lt;/li&gt;
&lt;li&gt;setting explicit values&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Viper can be thought of as a registry for all of your applications configuration needs.&lt;/p&gt;
&lt;h4 id=&#34;关于读环境变量&#34;&gt;关于读环境变量&lt;/h4&gt;
&lt;p&gt;AutomaticEnv is a powerful helper especially when combined with SetEnvPrefix. When called, Viper will check for an environment variable any time a viper.Get request is made. &lt;strong&gt;It will apply the following rules. It will check for a environment variable with a name matching the key uppercased&lt;/strong&gt; and prefixed with the EnvPrefix if set.&lt;/p&gt;
&lt;p&gt;环境变量名是有要求的，默认是大写+下划线组合。如果设置了EnvPrefix，环境变量名需要加上前缀加下划线。&lt;/p&gt;
&lt;p&gt;vip.GetXXX(var) 这里的var倒是大小写随意的，因为viper内部统一小写处理。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200321181144230.png&#34; alt=&#34;image-20200321181144230&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果环境变量名并不满足组合怎么办呢。使用BindEnv，绑定key与环境变量名之间的关系，而不是使用默认的约定。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;BindEnv&lt;/code&gt; takes one or two parameters. The first parameter is the key name, the second is the name of the environment variable. The name of the environment variable is case sensitive. If the ENV variable name is not provided, then Viper will automatically assume that the ENV variable matches the following format: prefix + &amp;ldquo;_&amp;rdquo; + the key name in ALL CAPS. &lt;strong&gt;When you explicitly provide the ENV variable name (the second parameter), it does not automatically add the prefix.&lt;/strong&gt; For example if the second parameter is &amp;ldquo;id&amp;rdquo;, Viper will look for the ENV variable &amp;ldquo;ID&amp;rdquo;.&lt;/p&gt;
&lt;h4 id=&#34;参考-2&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Go configuration with fangs &lt;a href=&#34;https://github.com/spf13/viper&#34;&gt;https://github.com/spf13/viper&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;日志-logrus&#34;&gt;日志 logrus&lt;/h3&gt;
&lt;p&gt;Logrus提供的日志功能很丰富。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/687474703a2f2f692e696d6775722e636f6d2f68546556776d4a2e706e67.png&#34; alt=&#34;:walrus:&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;JSON、TEXT格式输出。JSON很方便解析，配合ES存储日志。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;参考-3&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Structured, pluggable logging for Go. &lt;a href=&#34;https://github.com/sirupsen/logrus&#34;&gt;https://github.com/sirupsen/logrus&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;路由库--grollia-mux&#34;&gt;路由库  grollia mux&lt;/h3&gt;
&lt;p&gt;摘抄官方：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/68747470733a2f2f636c6f75642d63646e2e7175657374696f6e61626c652e73657276696365732f676f72696c6c612d69636f6e2d36342e706e67.png&#34; alt=&#34;Gorilla Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;Package &lt;code&gt;gorilla/mux&lt;/code&gt; implements a request router and dispatcher for matching incoming requests to their respective handler.&lt;/p&gt;
&lt;p&gt;The name mux stands for &amp;ldquo;HTTP request multiplexer&amp;rdquo;. Like the standard &lt;code&gt;http.ServeMux&lt;/code&gt;, &lt;code&gt;mux.Router&lt;/code&gt; matches incoming requests against a list of registered routes and calls a handler for the route that matches the URL or other conditions. The main features are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It implements the &lt;code&gt;http.Handler&lt;/code&gt; interface so it is compatible with the standard &lt;code&gt;http.ServeMux&lt;/code&gt;. Go 提供的http.Handler 接口太具有扩展性了。&lt;/li&gt;
&lt;li&gt;Requests can be matched based on URL host, path, path prefix, schemes, header and query values, HTTP methods or using custom matchers. 丰富的路由匹配规则，host、path、header、query string都可以。&lt;/li&gt;
&lt;li&gt;URL hosts, paths and query values can have variables with an optional regular expression.&lt;/li&gt;
&lt;li&gt;Registered URLs can be built, or &amp;ldquo;reversed&amp;rdquo;, which helps maintaining references to resources.&lt;/li&gt;
&lt;li&gt;Routes can be used as subrouters: nested routes are only tested if the parent route matches. This is useful to define groups of routes that share common conditions like a host, a path prefix or other repeated attributes. As a bonus, this optimizes request matching. 分组功能，RESTful接口按照实体分组，很实用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以搭配同系列的middleware项目使用：https://github.com/gorilla/handlers。&lt;/p&gt;
&lt;h4 id=&#34;参考-4&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;A powerful HTTP router and URL matcher for building Go web servers &lt;a href=&#34;https://github.com/gorilla/mux&#34;&gt;https://github.com/gorilla/mux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A collection of useful middleware for Go HTTP services &amp;amp; web applications &lt;a href=&#34;https://github.com/gorilla/handlers&#34;&gt;https://github.com/gorilla/handlers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Web Server Graceful Shutdown &lt;a href=&#34;https://github.com/gorilla/mux#graceful-shutdown&#34;&gt;https://github.com/gorilla/mux#graceful-shutdown&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;orm-gorm&#34;&gt;ORM gorm&lt;/h3&gt;
&lt;p&gt;文档很丰富。功能很实用。摘抄官方文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Full-Featured ORM (almost)&lt;/li&gt;
&lt;li&gt;Associations (Has One, Has Many, Belongs To, Many To Many, Polymorphism)&lt;/li&gt;
&lt;li&gt;Hooks (Before/After Create/Save/Update/Delete/Find)&lt;/li&gt;
&lt;li&gt;Preloading (eager loading)&lt;/li&gt;
&lt;li&gt;Transactions&lt;/li&gt;
&lt;li&gt;Composite Primary Key&lt;/li&gt;
&lt;li&gt;SQL Builder&lt;/li&gt;
&lt;li&gt;Auto Migrations 自动创建表结构。&lt;/li&gt;
&lt;li&gt;Logger&lt;/li&gt;
&lt;li&gt;Extendable, write Plugins based on GORM callbacks&lt;/li&gt;
&lt;li&gt;Every feature comes with tests&lt;/li&gt;
&lt;li&gt;Developer Friendly&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;参考-5&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;GORM Guides &lt;a href=&#34;https://gorm.io/docs/&#34;&gt;https://gorm.io/docs/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;http-client-grequests&#34;&gt;HTTP client grequests&lt;/h3&gt;
&lt;p&gt;号称 Python Requests 的Go clone。用着不错。&lt;/p&gt;
&lt;h4 id=&#34;参考-6&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;A Go &amp;ldquo;clone&amp;rdquo; of the great and famous Requests library &lt;a href=&#34;https://github.com/levigross/grequests&#34;&gt;https://github.com/levigross/grequests&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;errors-githubcompkgerrors&#34;&gt;Errors github.com/pkg/errors&lt;/h3&gt;
&lt;p&gt;内置的errors太弱了。返回了error，但是呢，没有返回上下文信息。这个库解决的是这个问题。&lt;/p&gt;
&lt;h4 id=&#34;参考-7&#34;&gt;参考&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Simple error handling primitives &lt;a href=&#34;https://github.com/pkg/errors&#34;&gt;https://github.com/pkg/errors&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;依赖注入框架-wire&#34;&gt;依赖注入框架 wire&lt;/h3&gt;
&lt;p&gt;基于代码生成的依赖注入框架。小项目没必要使用。&lt;/p&gt;
&lt;h3 id=&#34;rpc框架-grpc&#34;&gt;RPC框架 gRPC&lt;/h3&gt;
&lt;p&gt;跨进程，跨语言通信。&lt;/p&gt;
&lt;h2 id=&#34;常用工具&#34;&gt;常用工具&lt;/h2&gt;
&lt;h3 id=&#34;makefile&#34;&gt;Makefile&lt;/h3&gt;
&lt;p&gt;将常用的命令放在Makefile里管理。比如格式化代码 ，编译，打包，开发环境运行等等，并维护好依赖关系。&lt;/p&gt;
&lt;p&gt;不要写一堆.sh脚本了。&lt;/p&gt;
&lt;h3 id=&#34;docker&#34;&gt;Docker&lt;/h3&gt;
&lt;p&gt;维护一份Dockerfile，项目交付物通过制作成Docker镜像分发。比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Dockerfile
FROM alpine:latest
WORKDIR /app
COPY ./dist .
ENTRYPOINT [&amp;quot;./app&amp;quot;, &amp;quot;serve&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可以通过Docker来构建Go项目（一个两阶段的Dockerfile）。也可以像我这样，在宿主机就构建好，Dockerfile只需要COPY编译产物即可。&lt;/p&gt;
&lt;h3 id=&#34;swagger&#34;&gt;Swagger&lt;/h3&gt;
&lt;p&gt;目前没有方便的生成方法，得手写注释！&lt;/p&gt;
&lt;h2 id=&#34;项目结构&#34;&gt;项目结构&lt;/h2&gt;
&lt;p&gt;Go web项目结构没有定式，每个人的风格都不一样。参考了这个系列文章，觉得不错，特别是第二篇。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go Web Application Structure - Part 1 &lt;a href=&#34;https://aaf.engineering/go-web-application-structure-pt-1/&#34;&gt;https://aaf.engineering/go-web-application-structure-pt-1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Go Web Application Structure - Part 2 - Routing/Serving&lt;/strong&gt; &lt;a href=&#34;https://aaf.engineering/go-web-application-structure-part-2/&#34;&gt;https://aaf.engineering/go-web-application-structure-part-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go Web Application Structure - Part 3 - The Database &lt;a href=&#34;https://aaf.engineering/go-web-application-structure-part-3/&#34;&gt;https://aaf.engineering/go-web-application-structure-part-3/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Go Web Application Structure - Part 4 - Database Migrations &amp;amp; Business Logic &lt;a href=&#34;https://aaf.engineering/go-web-application-structure-part-4/&#34;&gt;https://aaf.engineering/go-web-application-structure-part-4/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;code &lt;a href=&#34;https://github.com/theaaf/todos&#34;&gt;https://github.com/theaaf/todos&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;层级调用链：cmd -&amp;gt; api -&amp;gt; app -&amp;gt; db。model/config横切，其它层共享之。&lt;/p&gt;
&lt;h3 id=&#34;model-database-models&#34;&gt;model: database models&lt;/h3&gt;
&lt;p&gt;模型实体，通过分析需求建模，合理的建模便于后期维护。&lt;/p&gt;
&lt;p&gt;横切层。其他每层都会用到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200320170405357.png&#34; alt=&#34;image-20200320170405357&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;config&#34;&gt;config&lt;/h3&gt;
&lt;p&gt;横切层。&lt;/p&gt;
&lt;p&gt;并没有自己独立的包，而是其他每层都可以根据需要，有一个自己独立的Config结构体。通过一个全局的Viper变量，取出该层关心的配置变量（或是从配置文件，或是从环境变量）。&lt;/p&gt;
&lt;p&gt;比如数据层的config：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200320170301550.png&#34; alt=&#34;image-20200320170301550&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;db-database-operations&#34;&gt;db: database operations&lt;/h3&gt;
&lt;p&gt;数据持久化层，底层。CRUD操作的封装。通过“构造函数”做依赖注入，方便单元测试。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200320170627650.png&#34; alt=&#34;image-20200320170627650&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;app-business-logic&#34;&gt;app: business logic&lt;/h3&gt;
&lt;p&gt;业务逻辑层，中层，核心层。调用数据层，及其他底层服务，比如S3云存储等。&lt;/p&gt;
&lt;h4 id=&#34;三类错误&#34;&gt;三类错误&lt;/h4&gt;
&lt;p&gt;该层方法返回的错误可以分三类。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ValidationError 输入不正确，校验不通过，比如手机号长度不对。对应的HTTP状态码：400。&lt;/li&gt;
&lt;li&gt;UserError 认证错误，比如用户登录失败，用户没有权限。对应的HTTP状态码：401, 403。&lt;/li&gt;
&lt;li&gt;ServerError 系统错误，比如数据库连不上，也不需要特别定义ServerError：只要error不是ValidationError，UserError，就是ServerError。对应的HTTP状态码：500。&lt;/li&gt;
&lt;li&gt;没有错误，那么对应的HTTP状态码就是200。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;api-api-controllers&#34;&gt;api: api controllers&lt;/h3&gt;
&lt;p&gt;接口层。尽可能轻量，尽可能没有业务逻辑，只负责转译。通过调用业务逻辑层完成任务。将上述三分类错误映射到合适的状态码。&lt;/p&gt;
&lt;h4 id=&#34;application-state-vs-request-state&#34;&gt;Application State vs. Request State&lt;/h4&gt;
&lt;p&gt;请求入口函数需要为每个请求创建一个context（上下文）。context包含如下，摘抄原文。包含的字段需满足完成request的所需。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../images/image-20200320181127465.png&#34; alt=&#34;image-20200320181127465&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;request-context-请求上下文信息&#34;&gt;(Request) Context 请求上下文信息&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Remote IP地址，显示于access log。使用logrus.WithField()。&lt;/li&gt;
&lt;li&gt;Request ID，显示于access log。使用logrus.WithField()。&lt;/li&gt;
&lt;li&gt;User，用于后续鉴权。如果有认证头信息（Auth Token），从数据库取出用户。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;cmd-command-line-methods&#34;&gt;cmd: command line methods&lt;/h3&gt;
&lt;p&gt;使用Cobra生成子命令。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;app serve &lt;/code&gt;&lt;/p&gt;
&lt;p&gt;启动web server，并加入web server优雅退出的功能。&lt;/p&gt;
- https://xujiahua.github.io/posts/go-web-project/ - </description>
        </item>
    
    
  </channel>
</rss> 